{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoope70/daytrading-with-ml/blob/main/multi_ticker_deep_sarsa_walkforward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall \\\n",
        "    dask==2024.11.2 \\\n",
        "    rapids-dask-dependency==24.12.0 \\\n",
        "    cudf-cu12==24.12.0 \\\n",
        "    cuml-cu12==24.12.0 \\\n",
        "    pylibraft-cu12==24.12.0 \\\n",
        "    pylibcudf-cu12==24.12.0 \\\n",
        "    numba==0.61.0 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG31VMJKsMcp",
        "outputId": "f594720f-a944-4ea3-bf87-e485bbb4f77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.5/244.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.8/457.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m916.0/916.0 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.9/28.9 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.7/424.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for cuml-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pylibraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cuvs-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for raft-dask-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for distributed-ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ucx-py-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for libucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\n",
            "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "langchain-core 0.3.52 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Install Stable Baselines3 and Trading Libraries\n",
        "!pip install stable-baselines3[extra] gymnasium gym-anytrading yfinance xgboost joblib\n"
      ],
      "metadata": {
        "id": "KqLB5JTZfdV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8456d1f-2b10-4296-b00c-5c3de9721f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Collecting gym-anytrading\n",
            "  Downloading gym_anytrading-2.0.0-py3-none-any.whl.metadata (292 bytes)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.1.3)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (14.0.0)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading gym_anytrading-2.0.0-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, gym-anytrading, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-anytrading-2.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Clean install of TensorFlow compatible with Colab's GPU (CUDA 11.8 + cuDNN 8.x)\n",
        "!pip install tensorflow==2.12.0\n",
        "\n",
        "# ⚠️ Restart runtime after this!\n",
        "!pip install numpy==1.24.4 --force-reinstall"
      ],
      "metadata": {
        "id": "LDGtMjeQthIr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fecfbc3c-1546-409d-b05f-d43a9d8499cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m128.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.3\n",
            "    Uninstalling numpy-2.1.3:\n",
            "      Successfully uninstalled numpy-2.1.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.6 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "dc10ff7f32b84330b919d3115b139ade"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b7a0b9bd81c546a9a551c9359f5d5d3b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cudf\n",
        "import cuml\n",
        "import dask\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import lightgbm as lgb\n",
        "import gymnasium as gym\n",
        "import stable_baselines3\n",
        "\n",
        "#=========================\n",
        "#Version Checks\n",
        "#=========================\n",
        "print(\" Library Versions\")\n",
        "print(\"--------------------\")\n",
        "print(\" PyTorch:\", torch.__version__)\n",
        "print(\" CUDA:\", torch.version.cuda)\n",
        "print(\" cuDF:\", cudf.__version__)\n",
        "print(\" cuML:\", cuml.__version__)\n",
        "print(\" Dask:\", dask.__version__)\n",
        "print(\" Pandas:\", pd.__version__)\n",
        "print(\" NumPy:\", np.__version__)\n",
        "print(\" SciPy:\", scipy.__version__)\n",
        "print(\" LightGBM:\", lgb.__version__)\n",
        "print(\" Gymnasium:\", gym.__version__)\n",
        "print(\" Stable Baselines3:\", stable_baselines3.__version__)\n",
        "\n",
        "#=========================\n",
        "# GPU Check (Torch + NVIDIA)\n",
        "#=========================\n",
        "print(\"\\n GPU Availability\")\n",
        "print(\"--------------------\")\n",
        "print(\" PyTorch GPU Available:\", torch.cuda.is_available())\n",
        "print(\" GPU Count:\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print(\" GPU Name:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "n0P_KzkQbeAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78420309-9b64-467e-d3e0-22fa663696ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Library Versions\n",
            "--------------------\n",
            " PyTorch: 2.6.0+cu124\n",
            " CUDA: 12.4\n",
            " cuDF: 24.12.00\n",
            " cuML: 24.12.00\n",
            " Dask: 2024.11.2\n",
            " Pandas: 2.2.3\n",
            " NumPy: 1.24.4\n",
            " SciPy: 1.15.2\n",
            " LightGBM: 4.5.0\n",
            " Gymnasium: 1.1.1\n",
            " Stable Baselines3: 2.6.0\n",
            "\n",
            " GPU Availability\n",
            "--------------------\n",
            " PyTorch GPU Available: True\n",
            " GPU Count: 1\n",
            " GPU Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Clean install of TensorFlow compatible with Colab's GPU (CUDA 11.8 + cuDNN 8.x)\n",
        "!pip uninstall -y tensorflow keras\n",
        "!pip install tensorflow==2.12.0\n",
        "\n",
        "# ⚠️ Restart runtime after this!\n",
        "!pip install numpy==1.24.4 --force-reinstall"
      ],
      "metadata": {
        "id": "_3Rokalw8Q9o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12a1517c-e1e9-4719-eb2a-6c0405816e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Successfully uninstalled tensorflow-2.12.0\n",
            "Found existing installation: keras 2.12.0\n",
            "Uninstalling keras-2.12.0:\n",
            "  Successfully uninstalled keras-2.12.0\n",
            "Collecting tensorflow==2.12.0\n",
            "  Using cached tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Using cached keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Using cached tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy, keras, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.12.0 numpy-1.23.5 tensorflow-2.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "numpy",
                  "tensorflow"
                ]
              },
              "id": "a1e8d68389d944c0836b94f7c3ec4aeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b4fa9363cc9e448eb0f6d491199a9b0f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Core & System Utilities\n",
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "# ✅ Data Science Essentials\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numba\n",
        "\n",
        "# ✅ Financial Data\n",
        "import yfinance as yf\n",
        "\n",
        "# ✅ Machine Learning & Preprocessing\n",
        "import joblib\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# ✅ Deep Learning (TensorFlow/Keras)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import Input, backend as K\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# ✅ Visualization & Display\n",
        "import IPython.display as display\n",
        "\n",
        "# ✅ RAPIDS Libraries (for GPU-accelerated ML, optional)\n",
        "import cupy as cp\n",
        "\n",
        "# ✅ Reinforcement Learning (Stable Baselines3)\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import A2C, DDPG, DQN, PPO, SAC, TD3\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.logger import configure\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "\n",
        "# ✅ Gym & Trading Environments\n",
        "import gym\n",
        "import gymnasium as gym\n",
        "import gym_anytrading\n",
        "from gym.spaces import Box\n",
        "from gymnasium.spaces import Box as GymBox, Discrete\n",
        "from gymnasium.wrappers import TimeLimit\n",
        "\n",
        "# ✅ CUDA (Optional Paths - for manual GPU configuration)\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-11.8'\n",
        "os.environ['PATH'] += ':/usr/local/cuda-11.8/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda-11.8/lib64'\n",
        "\n",
        "# ✅ GPU Check (Colab only)\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "dHValAhTfoPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468f65fd-63cd-471b-d49a-f3108da8941e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 21 01:19:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required for TensorFlow compatibility (GPU + cuDNN)\n",
        "!pip uninstall -y tensorflow keras -q\n",
        "!pip install tensorflow==2.12.0 -q\n",
        "\n",
        "# Fix protobuf compatibility\n",
        "!pip install protobuf==3.20.3 -q\n",
        "\n",
        "# Essential packages\n",
        "!pip install numpy==1.24.4 pandas joblib yfinance scikit-learn matplotlib -q\n"
      ],
      "metadata": {
        "id": "W2LAK2iMwDX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e999445e-be6e-4832-fb7f-afbfec8cb486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"✅ Google Drive is already mounted.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lBi93dMiyXnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a8e78c-faf5-4644-fc85-6871fc32c9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Downgrade NumPy to a compatible version\n",
        "!pip install numpy==1.24.4 --force-reinstall\n",
        "\n",
        "# ✅ Reinstall LightGBM after fixing NumPy\n",
        "!pip install lightgbm --force-reinstall --no-cache-dir\n"
      ],
      "metadata": {
        "id": "Yz6kPzPmTSDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "daeef58f-2700-4ffe-ebe3-d64b9297dfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "8407c4fbbd1d40968ed5c1539c5b094b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting numpy>=1.17.0 (from lightgbm)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy (from lightgbm)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m206.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, lightgbm\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.5.0\n",
            "    Uninstalling lightgbm-4.5.0:\n",
            "      Successfully uninstalled lightgbm-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lightgbm-4.6.0 numpy-2.2.5 scipy-1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn==1.3.2 --quiet\n"
      ],
      "metadata": {
        "id": "aLMWemm2UsKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c99473-a1ca-4a11-f3b3-db0d550c1f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "id": "y2ypei7yz2B2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf0456d-fa62-4355-feff-65aaa3734c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Imports\n",
        "import os, gc, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datetime import datetime\n",
        "\n",
        "# ✅ Config\n",
        "TICKERS = [\"AAPL\", \"TSLA\", \"MSFT\", \"GOOG\", \"AMZN\", \"NVDA\", \"META\", \"JPM\", \"BAC\", \"WMT\",\n",
        "               \"UNH\", \"V\", \"PG\", \"HD\", \"MA\", \"DIS\", \"PEP\", \"KO\", \"CSCO\", \"ADBE\", \"CRM\", \"NFLX\",\n",
        "               \"PFE\", \"MRK\", \"T\", \"ORCL\", \"ABBV\", \"CVX\", \"XOM\", \"ABT\", \"COST\", \"QCOM\", \"INTC\",\n",
        "               \"MCD\", \"NKE\", \"DHR\", \"LLY\", \"MDT\", \"TMO\", \"TXN\", \"PM\", \"AVGO\", \"NEE\", \"ACN\", \"UPS\",\n",
        "               \"HON\", \"LIN\", \"GS\", \"IBM\"]\n",
        "\n",
        "SEQUENCE_LENGTH = 60\n",
        "SAVE_DIR = \"/content/drive/MyDrive/DeepSARSA_Models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Feature Engineering\n",
        "def compute_technical_indicators(df):\n",
        "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
        "    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
        "    delta = df['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(window=14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(window=14).mean()\n",
        "    rs = gain / (loss + 1e-6)\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "    df['MACD'] = df['Close'].ewm(span=12, adjust=False).mean() - df['Close'].ewm(span=26, adjust=False).mean()\n",
        "    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "    df['ATR'] = df['High'].rolling(window=14).max() - df['Low'].rolling(window=14).min()\n",
        "    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "# ✅ Deep SARSA Model\n",
        "class DQNNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQNNet, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, 64, batch_first=True)\n",
        "        self.fc1 = nn.Linear(64, 32)\n",
        "        self.out = nn.Linear(32, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, _ = self.lstm(x)\n",
        "        h = h[:, -1, :]  # last hidden state\n",
        "        x = torch.relu(self.fc1(h))\n",
        "        return self.out(x)\n",
        "\n",
        "class DeepSARSAAgent:\n",
        "    def __init__(self, input_dim, action_dim, lr=1e-3, gamma=0.99):\n",
        "        self.gamma = gamma\n",
        "        self.model = DQNNet(input_dim, action_dim).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def select_action(self, state, epsilon):\n",
        "        if random.random() < epsilon:\n",
        "            return random.randint(0, 2)\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return torch.argmax(q_values).item()\n",
        "\n",
        "    def update(self, state, action, reward, next_state, next_action, done):\n",
        "        q_values = self.model(state)\n",
        "        next_q_values = self.model(next_state)\n",
        "        target = reward + self.gamma * next_q_values[0, next_action] * (1 - int(done))\n",
        "        loss = self.criterion(q_values[0, action], target.detach())\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "# ✅ Training Loop\n",
        "def train_agent_on_stock(ticker, episodes=10):\n",
        "    print(f\"\\n🔁 Training Deep SARSA on {ticker}\")\n",
        "    df = yf.download(ticker, period=\"720d\", interval=\"1h\", progress=False)\n",
        "    if df.empty:\n",
        "        print(f\"⚠️ No data for {ticker}, skipping.\")\n",
        "        return\n",
        "\n",
        "    df = compute_technical_indicators(df)\n",
        "    features = ['Close', 'SMA_50', 'EMA_20', 'RSI', 'MACD', 'Signal_Line', 'ATR', 'OBV']\n",
        "    df = df[features].copy()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(df)\n",
        "\n",
        "    # Create sequences\n",
        "    X = []\n",
        "    for i in range(SEQUENCE_LENGTH, len(scaled)):\n",
        "        X.append(scaled[i-SEQUENCE_LENGTH:i])\n",
        "    X = np.array(X)\n",
        "\n",
        "    state_dim = X.shape[2]\n",
        "    agent = DeepSARSAAgent(state_dim, 3)\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        state_idx = random.randint(0, len(X) - 2)\n",
        "        state = torch.tensor(X[state_idx][None], dtype=torch.float32).to(device)\n",
        "        action = agent.select_action(state, epsilon=1.0 - ep/episodes)\n",
        "        total_reward = 0\n",
        "\n",
        "        for t in range(state_idx, len(X) - 1):\n",
        "            next_state = torch.tensor(X[t+1][None], dtype=torch.float32).to(device)\n",
        "            # ✅ FIXED: Use last timestep and first feature (assumed 'Close')\n",
        "            reward = float(X[t+1, -1, 0] - X[t, -1, 0])\n",
        "            done = t + 2 == len(X)\n",
        "            next_action = agent.select_action(next_state, epsilon=1.0 - ep/episodes)\n",
        "            agent.update(state, action, reward, next_state, next_action, done)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "            state, action = next_state, next_action\n",
        "\n",
        "        print(f\"✅ Episode {ep+1}: Total Reward = {total_reward:.4f}\")\n",
        "\n",
        "    # Save model\n",
        "    model_path = f\"{SAVE_DIR}/deep_sarsa_{ticker}.pth\"\n",
        "    torch.save(agent.model.state_dict(), model_path)\n",
        "    print(f\"✅ Saved model to {model_path}\")\n",
        "\n",
        "# ✅ Train on All Tickers\n",
        "for ticker in TICKERS:\n",
        "    train_agent_on_stock(ticker, episodes=5)\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrRJSTKjRilA",
        "outputId": "69dd9351-2615-479d-ffa0-620712036a0a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Training Deep SARSA on AAPL\n",
            "YF.download() has changed argument auto_adjust default to True\n",
            "✅ Episode 1: Total Reward = -0.1594\n",
            "✅ Episode 2: Total Reward = 0.1105\n",
            "✅ Episode 3: Total Reward = 0.3787\n",
            "✅ Episode 4: Total Reward = -0.2323\n",
            "✅ Episode 5: Total Reward = -0.2322\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AAPL.pth\n",
            "\n",
            "🔁 Training Deep SARSA on TSLA\n",
            "✅ Episode 1: Total Reward = 0.1066\n",
            "✅ Episode 2: Total Reward = -0.0117\n",
            "✅ Episode 3: Total Reward = 0.0513\n",
            "✅ Episode 4: Total Reward = 0.1679\n",
            "✅ Episode 5: Total Reward = 0.0008\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TSLA.pth\n",
            "\n",
            "🔁 Training Deep SARSA on MSFT\n",
            "✅ Episode 1: Total Reward = -0.0093\n",
            "✅ Episode 2: Total Reward = -0.2198\n",
            "✅ Episode 3: Total Reward = -0.1545\n",
            "✅ Episode 4: Total Reward = 0.1225\n",
            "✅ Episode 5: Total Reward = 0.0880\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MSFT.pth\n",
            "\n",
            "🔁 Training Deep SARSA on GOOG\n",
            "✅ Episode 1: Total Reward = 0.3515\n",
            "✅ Episode 2: Total Reward = 0.1055\n",
            "✅ Episode 3: Total Reward = -0.1268\n",
            "✅ Episode 4: Total Reward = 0.2271\n",
            "✅ Episode 5: Total Reward = 0.4398\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_GOOG.pth\n",
            "\n",
            "🔁 Training Deep SARSA on AMZN\n",
            "✅ Episode 1: Total Reward = -0.0522\n",
            "✅ Episode 2: Total Reward = -0.0893\n",
            "✅ Episode 3: Total Reward = -0.1068\n",
            "✅ Episode 4: Total Reward = 0.2385\n",
            "✅ Episode 5: Total Reward = -0.1025\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AMZN.pth\n",
            "\n",
            "🔁 Training Deep SARSA on NVDA\n",
            "✅ Episode 1: Total Reward = 0.6177\n",
            "✅ Episode 2: Total Reward = 0.5927\n",
            "✅ Episode 3: Total Reward = 0.5880\n",
            "✅ Episode 4: Total Reward = 0.5328\n",
            "✅ Episode 5: Total Reward = 0.2838\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NVDA.pth\n",
            "\n",
            "🔁 Training Deep SARSA on META\n",
            "✅ Episode 1: Total Reward = 0.3452\n",
            "✅ Episode 2: Total Reward = 0.3098\n",
            "✅ Episode 3: Total Reward = 0.0236\n",
            "✅ Episode 4: Total Reward = 0.3112\n",
            "✅ Episode 5: Total Reward = 0.4065\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_META.pth\n",
            "\n",
            "🔁 Training Deep SARSA on JPM\n",
            "✅ Episode 1: Total Reward = 0.6622\n",
            "✅ Episode 2: Total Reward = 0.5150\n",
            "✅ Episode 3: Total Reward = 0.6207\n",
            "✅ Episode 4: Total Reward = 0.4397\n",
            "✅ Episode 5: Total Reward = 0.6538\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_JPM.pth\n",
            "\n",
            "🔁 Training Deep SARSA on BAC\n",
            "✅ Episode 1: Total Reward = -0.0169\n",
            "✅ Episode 2: Total Reward = -0.0250\n",
            "✅ Episode 3: Total Reward = 0.0861\n",
            "✅ Episode 4: Total Reward = 0.3571\n",
            "✅ Episode 5: Total Reward = 0.2375\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_BAC.pth\n",
            "\n",
            "🔁 Training Deep SARSA on WMT\n",
            "✅ Episode 1: Total Reward = -0.0094\n",
            "✅ Episode 2: Total Reward = 0.5573\n",
            "✅ Episode 3: Total Reward = 0.6642\n",
            "✅ Episode 4: Total Reward = 0.6886\n",
            "✅ Episode 5: Total Reward = 0.3399\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_WMT.pth\n",
            "\n",
            "🔁 Training Deep SARSA on UNH\n",
            "✅ Episode 1: Total Reward = -0.8160\n",
            "✅ Episode 2: Total Reward = -0.1951\n",
            "✅ Episode 3: Total Reward = -0.3379\n",
            "✅ Episode 4: Total Reward = -0.3621\n",
            "✅ Episode 5: Total Reward = -0.4801\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_UNH.pth\n",
            "\n",
            "🔁 Training Deep SARSA on V\n",
            "✅ Episode 1: Total Reward = 0.3791\n",
            "✅ Episode 2: Total Reward = 0.6411\n",
            "✅ Episode 3: Total Reward = 0.5365\n",
            "✅ Episode 4: Total Reward = 0.8051\n",
            "✅ Episode 5: Total Reward = -0.0242\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_V.pth\n",
            "\n",
            "🔁 Training Deep SARSA on PG\n",
            "✅ Episode 1: Total Reward = 0.0495\n",
            "✅ Episode 2: Total Reward = 0.5323\n",
            "✅ Episode 3: Total Reward = 0.4884\n",
            "✅ Episode 4: Total Reward = 0.3031\n",
            "✅ Episode 5: Total Reward = 0.4587\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PG.pth\n",
            "\n",
            "🔁 Training Deep SARSA on HD\n",
            "✅ Episode 1: Total Reward = 0.3745\n",
            "✅ Episode 2: Total Reward = 0.1709\n",
            "✅ Episode 3: Total Reward = -0.1658\n",
            "✅ Episode 4: Total Reward = 0.2588\n",
            "✅ Episode 5: Total Reward = 0.2417\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_HD.pth\n",
            "\n",
            "🔁 Training Deep SARSA on MA\n",
            "✅ Episode 1: Total Reward = 0.3191\n",
            "✅ Episode 2: Total Reward = 0.5245\n",
            "✅ Episode 3: Total Reward = 0.2071\n",
            "✅ Episode 4: Total Reward = 0.6602\n",
            "✅ Episode 5: Total Reward = 0.1436\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MA.pth\n",
            "\n",
            "🔁 Training Deep SARSA on DIS\n",
            "✅ Episode 1: Total Reward = -0.2245\n",
            "✅ Episode 2: Total Reward = -0.1759\n",
            "✅ Episode 3: Total Reward = -0.1280\n",
            "✅ Episode 4: Total Reward = -0.0846\n",
            "✅ Episode 5: Total Reward = -0.2660\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_DIS.pth\n",
            "\n",
            "🔁 Training Deep SARSA on PEP\n",
            "✅ Episode 1: Total Reward = -0.6845\n",
            "✅ Episode 2: Total Reward = -0.4669\n",
            "✅ Episode 3: Total Reward = -0.3405\n",
            "✅ Episode 4: Total Reward = -0.5145\n",
            "✅ Episode 5: Total Reward = -0.3723\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PEP.pth\n",
            "\n",
            "🔁 Training Deep SARSA on KO\n",
            "✅ Episode 1: Total Reward = 0.5719\n",
            "✅ Episode 2: Total Reward = 0.6514\n",
            "✅ Episode 3: Total Reward = 0.6303\n",
            "✅ Episode 4: Total Reward = 0.4853\n",
            "✅ Episode 5: Total Reward = 0.3511\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_KO.pth\n",
            "\n",
            "🔁 Training Deep SARSA on CSCO\n",
            "✅ Episode 1: Total Reward = 0.4747\n",
            "✅ Episode 2: Total Reward = 0.3573\n",
            "✅ Episode 3: Total Reward = 0.3095\n",
            "✅ Episode 4: Total Reward = 0.3570\n",
            "✅ Episode 5: Total Reward = 0.3109\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CSCO.pth\n",
            "\n",
            "🔁 Training Deep SARSA on ADBE\n",
            "✅ Episode 1: Total Reward = 0.0548\n",
            "✅ Episode 2: Total Reward = -0.5761\n",
            "✅ Episode 3: Total Reward = -0.7145\n",
            "✅ Episode 4: Total Reward = 0.0641\n",
            "✅ Episode 5: Total Reward = -0.4706\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ADBE.pth\n",
            "\n",
            "🔁 Training Deep SARSA on CRM\n",
            "✅ Episode 1: Total Reward = -0.4399\n",
            "✅ Episode 2: Total Reward = 0.2430\n",
            "✅ Episode 3: Total Reward = 0.3890\n",
            "✅ Episode 4: Total Reward = 0.3723\n",
            "✅ Episode 5: Total Reward = 0.0026\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CRM.pth\n",
            "\n",
            "🔁 Training Deep SARSA on NFLX\n",
            "✅ Episode 1: Total Reward = 0.6009\n",
            "✅ Episode 2: Total Reward = 0.0341\n",
            "✅ Episode 3: Total Reward = 0.7251\n",
            "✅ Episode 4: Total Reward = 0.3791\n",
            "✅ Episode 5: Total Reward = 0.3926\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NFLX.pth\n",
            "\n",
            "🔁 Training Deep SARSA on PFE\n",
            "✅ Episode 1: Total Reward = -0.4005\n",
            "✅ Episode 2: Total Reward = -0.6320\n",
            "✅ Episode 3: Total Reward = -0.1692\n",
            "✅ Episode 4: Total Reward = -0.1098\n",
            "✅ Episode 5: Total Reward = -0.5363\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PFE.pth\n",
            "\n",
            "🔁 Training Deep SARSA on MRK\n",
            "✅ Episode 1: Total Reward = -0.0647\n",
            "✅ Episode 2: Total Reward = -0.4787\n",
            "✅ Episode 3: Total Reward = -0.7107\n",
            "✅ Episode 4: Total Reward = -0.4921\n",
            "✅ Episode 5: Total Reward = -0.8165\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MRK.pth\n",
            "\n",
            "🔁 Training Deep SARSA on T\n",
            "✅ Episode 1: Total Reward = 0.5761\n",
            "✅ Episode 2: Total Reward = 0.7799\n",
            "✅ Episode 3: Total Reward = 0.2780\n",
            "✅ Episode 4: Total Reward = 0.3553\n",
            "✅ Episode 5: Total Reward = 0.6684\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_T.pth\n",
            "\n",
            "🔁 Training Deep SARSA on ORCL\n",
            "✅ Episode 1: Total Reward = 0.3026\n",
            "✅ Episode 2: Total Reward = 0.4061\n",
            "✅ Episode 3: Total Reward = -0.3352\n",
            "✅ Episode 4: Total Reward = 0.1885\n",
            "✅ Episode 5: Total Reward = -0.3389\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ORCL.pth\n",
            "\n",
            "🔁 Training Deep SARSA on ABBV\n",
            "✅ Episode 1: Total Reward = 0.2442\n",
            "✅ Episode 2: Total Reward = -0.2098\n",
            "✅ Episode 3: Total Reward = 0.4027\n",
            "✅ Episode 4: Total Reward = 0.4358\n",
            "✅ Episode 5: Total Reward = -0.2315\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ABBV.pth\n",
            "\n",
            "🔁 Training Deep SARSA on CVX\n",
            "✅ Episode 1: Total Reward = -0.2108\n",
            "✅ Episode 2: Total Reward = -0.1482\n",
            "✅ Episode 3: Total Reward = -0.1020\n",
            "✅ Episode 4: Total Reward = -0.3681\n",
            "✅ Episode 5: Total Reward = -0.4263\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CVX.pth\n",
            "\n",
            "🔁 Training Deep SARSA on XOM\n",
            "✅ Episode 1: Total Reward = -0.2389\n",
            "✅ Episode 2: Total Reward = -0.0122\n",
            "✅ Episode 3: Total Reward = 0.0759\n",
            "✅ Episode 4: Total Reward = -0.1585\n",
            "✅ Episode 5: Total Reward = -0.1897\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_XOM.pth\n",
            "\n",
            "🔁 Training Deep SARSA on ABT\n",
            "✅ Episode 1: Total Reward = 0.4218\n",
            "✅ Episode 2: Total Reward = 0.2049\n",
            "✅ Episode 3: Total Reward = 0.4248\n",
            "✅ Episode 4: Total Reward = 0.4250\n",
            "✅ Episode 5: Total Reward = 0.5267\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ABT.pth\n",
            "\n",
            "🔁 Training Deep SARSA on COST\n",
            "✅ Episode 1: Total Reward = 0.7835\n",
            "✅ Episode 2: Total Reward = 0.4175\n",
            "✅ Episode 3: Total Reward = 0.0849\n",
            "✅ Episode 4: Total Reward = 0.1911\n",
            "✅ Episode 5: Total Reward = 0.8354\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_COST.pth\n",
            "\n",
            "🔁 Training Deep SARSA on QCOM\n",
            "✅ Episode 1: Total Reward = 0.0586\n",
            "✅ Episode 2: Total Reward = -0.2537\n",
            "✅ Episode 3: Total Reward = 0.2108\n",
            "✅ Episode 4: Total Reward = 0.0576\n",
            "✅ Episode 5: Total Reward = 0.0326\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_QCOM.pth\n",
            "\n",
            "🔁 Training Deep SARSA on INTC\n",
            "✅ Episode 1: Total Reward = -0.5831\n",
            "✅ Episode 2: Total Reward = -0.0905\n",
            "✅ Episode 3: Total Reward = -0.2658\n",
            "✅ Episode 4: Total Reward = -0.3578\n",
            "✅ Episode 5: Total Reward = -0.3409\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_INTC.pth\n",
            "\n",
            "🔁 Training Deep SARSA on MCD\n",
            "✅ Episode 1: Total Reward = 0.3127\n",
            "✅ Episode 2: Total Reward = 0.1992\n",
            "✅ Episode 3: Total Reward = 0.4906\n",
            "✅ Episode 4: Total Reward = 0.4472\n",
            "✅ Episode 5: Total Reward = 0.4770\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MCD.pth\n",
            "\n",
            "🔁 Training Deep SARSA on NKE\n",
            "✅ Episode 1: Total Reward = -0.8249\n",
            "✅ Episode 2: Total Reward = -0.6901\n",
            "✅ Episode 3: Total Reward = -0.2766\n",
            "✅ Episode 4: Total Reward = 0.0202\n",
            "✅ Episode 5: Total Reward = -0.5075\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NKE.pth\n",
            "\n",
            "🔁 Training Deep SARSA on DHR\n",
            "✅ Episode 1: Total Reward = -0.7096\n",
            "✅ Episode 2: Total Reward = -0.5810\n",
            "✅ Episode 3: Total Reward = -0.5687\n",
            "✅ Episode 4: Total Reward = -0.2214\n",
            "✅ Episode 5: Total Reward = -0.8655\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_DHR.pth\n",
            "\n",
            "🔁 Training Deep SARSA on LLY\n",
            "✅ Episode 1: Total Reward = 0.0040\n",
            "✅ Episode 2: Total Reward = 0.4325\n",
            "✅ Episode 3: Total Reward = 0.7401\n",
            "✅ Episode 4: Total Reward = 0.0706\n",
            "✅ Episode 5: Total Reward = -0.1020\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_LLY.pth\n",
            "\n",
            "🔁 Training Deep SARSA on MDT\n",
            "✅ Episode 1: Total Reward = 0.1308\n",
            "✅ Episode 2: Total Reward = 0.0974\n",
            "✅ Episode 3: Total Reward = -0.2709\n",
            "✅ Episode 4: Total Reward = 0.1352\n",
            "✅ Episode 5: Total Reward = -0.2723\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MDT.pth\n",
            "\n",
            "🔁 Training Deep SARSA on TMO\n",
            "✅ Episode 1: Total Reward = -0.4619\n",
            "✅ Episode 2: Total Reward = -0.7595\n",
            "✅ Episode 3: Total Reward = -0.5026\n",
            "✅ Episode 4: Total Reward = -0.5670\n",
            "✅ Episode 5: Total Reward = -0.8348\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TMO.pth\n",
            "\n",
            "🔁 Training Deep SARSA on TXN\n",
            "✅ Episode 1: Total Reward = -0.2989\n",
            "✅ Episode 2: Total Reward = -0.6487\n",
            "✅ Episode 3: Total Reward = -0.6869\n",
            "✅ Episode 4: Total Reward = -0.2050\n",
            "✅ Episode 5: Total Reward = -0.1261\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TXN.pth\n",
            "\n",
            "🔁 Training Deep SARSA on PM\n",
            "✅ Episode 1: Total Reward = 0.8305\n",
            "✅ Episode 2: Total Reward = 0.5343\n",
            "✅ Episode 3: Total Reward = 0.8056\n",
            "✅ Episode 4: Total Reward = 0.8388\n",
            "✅ Episode 5: Total Reward = 0.9079\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PM.pth\n",
            "\n",
            "🔁 Training Deep SARSA on AVGO\n",
            "✅ Episode 1: Total Reward = 0.4186\n",
            "✅ Episode 2: Total Reward = 0.4195\n",
            "✅ Episode 3: Total Reward = 0.5380\n",
            "✅ Episode 4: Total Reward = 0.5726\n",
            "✅ Episode 5: Total Reward = 0.5806\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AVGO.pth\n",
            "\n",
            "🔁 Training Deep SARSA on NEE\n",
            "✅ Episode 1: Total Reward = -0.1091\n",
            "✅ Episode 2: Total Reward = -0.4429\n",
            "✅ Episode 3: Total Reward = -0.1457\n",
            "✅ Episode 4: Total Reward = 0.1335\n",
            "✅ Episode 5: Total Reward = -0.3404\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NEE.pth\n",
            "\n",
            "🔁 Training Deep SARSA on ACN\n",
            "✅ Episode 1: Total Reward = 0.0144\n",
            "✅ Episode 2: Total Reward = -0.0879\n",
            "✅ Episode 3: Total Reward = -0.2987\n",
            "✅ Episode 4: Total Reward = -0.5043\n",
            "✅ Episode 5: Total Reward = 0.0878\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ACN.pth\n",
            "\n",
            "🔁 Training Deep SARSA on UPS\n",
            "✅ Episode 1: Total Reward = -0.5158\n",
            "✅ Episode 2: Total Reward = -0.9099\n",
            "✅ Episode 3: Total Reward = -0.5121\n",
            "✅ Episode 4: Total Reward = -0.5183\n",
            "✅ Episode 5: Total Reward = -0.5606\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_UPS.pth\n",
            "\n",
            "🔁 Training Deep SARSA on HON\n",
            "✅ Episode 1: Total Reward = -0.0578\n",
            "✅ Episode 2: Total Reward = -0.2002\n",
            "✅ Episode 3: Total Reward = -0.0461\n",
            "✅ Episode 4: Total Reward = -0.1255\n",
            "✅ Episode 5: Total Reward = 0.0553\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_HON.pth\n",
            "\n",
            "🔁 Training Deep SARSA on LIN\n",
            "✅ Episode 1: Total Reward = 0.3596\n",
            "✅ Episode 2: Total Reward = 0.6340\n",
            "✅ Episode 3: Total Reward = 0.7487\n",
            "✅ Episode 4: Total Reward = 0.5091\n",
            "✅ Episode 5: Total Reward = 0.1819\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_LIN.pth\n",
            "\n",
            "🔁 Training Deep SARSA on GS\n",
            "✅ Episode 1: Total Reward = -0.2610\n",
            "✅ Episode 2: Total Reward = 0.2517\n",
            "✅ Episode 3: Total Reward = -0.1949\n",
            "✅ Episode 4: Total Reward = 0.3757\n",
            "✅ Episode 5: Total Reward = 0.4651\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_GS.pth\n",
            "\n",
            "🔁 Training Deep SARSA on IBM\n",
            "✅ Episode 1: Total Reward = -0.1438\n",
            "✅ Episode 2: Total Reward = 0.6301\n",
            "✅ Episode 3: Total Reward = 0.6745\n",
            "✅ Episode 4: Total Reward = 0.6676\n",
            "✅ Episode 5: Total Reward = 0.1527\n",
            "✅ Saved model to /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_IBM.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Imports\n",
        "import os, gc, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ✅ Walkforward Utilities\n",
        "def get_walkforward_splits(data, sequence_length, n_splits=3):\n",
        "    total_len = len(data)\n",
        "    fold_size = (total_len - sequence_length) // (n_splits + 1)\n",
        "    splits = []\n",
        "    for i in range(n_splits):\n",
        "        train_start = 0\n",
        "        train_end = sequence_length + fold_size * (i + 1)\n",
        "        test_start = train_end\n",
        "        test_end = test_start + fold_size\n",
        "        if test_end > total_len:\n",
        "            break\n",
        "        splits.append((train_start, train_end, test_start, test_end))\n",
        "    return splits\n",
        "\n",
        "def train_agent_on_split(X, train_start, train_end, test_start, test_end, episodes=5):\n",
        "    state_dim = X.shape[2]\n",
        "    agent = DeepSARSAAgent(state_dim, 3)\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        state_idx = random.randint(train_start, train_end - 2)\n",
        "        state = torch.tensor(X[state_idx][None], dtype=torch.float32).to(device)\n",
        "        action = agent.select_action(state, epsilon=1.0 - ep/episodes)\n",
        "\n",
        "        for t in range(state_idx, train_end - 1):\n",
        "            next_state = torch.tensor(X[t+1][None], dtype=torch.float32).to(device)\n",
        "            reward = float(X[t+1, -1, 0] - X[t, -1, 0])\n",
        "            done = t + 2 == train_end\n",
        "            next_action = agent.select_action(next_state, epsilon=1.0 - ep/episodes)\n",
        "            agent.update(state, action, reward, next_state, next_action, done)\n",
        "            if done:\n",
        "                break\n",
        "            state, action = next_state, next_action\n",
        "\n",
        "    test_rewards = []\n",
        "    for t in range(test_start, test_end - 1):\n",
        "        state = torch.tensor(X[t][None], dtype=torch.float32).to(device)\n",
        "        action = agent.select_action(state, epsilon=0.0)\n",
        "        next_state = torch.tensor(X[t+1][None], dtype=torch.float32).to(device)\n",
        "        reward = float(X[t+1, -1, 0] - X[t, -1, 0])\n",
        "        test_rewards.append(reward)\n",
        "\n",
        "    return np.sum(test_rewards), agent\n",
        "\n",
        "def walkforward_train_on_stock(ticker, episodes=5, n_splits=3):\n",
        "    print(f\"📈 Walkforward SARSA on {ticker}\")\n",
        "    df = yf.download(ticker, period=\"720d\", interval=\"1h\", progress=False)\n",
        "    if df.empty:\n",
        "        print(f\"⚠️ No data for {ticker}, skipping.\")\n",
        "        return []\n",
        "\n",
        "    df = compute_technical_indicators(df)\n",
        "    features = ['Close', 'SMA_50', 'EMA_20', 'RSI', 'MACD', 'Signal_Line', 'ATR', 'OBV']\n",
        "    df = df[features].copy()\n",
        "    scaled = MinMaxScaler().fit_transform(df)\n",
        "\n",
        "    X = []\n",
        "    for i in range(SEQUENCE_LENGTH, len(scaled)):\n",
        "        X.append(scaled[i-SEQUENCE_LENGTH:i])\n",
        "    X = np.array(X)\n",
        "\n",
        "    splits = get_walkforward_splits(X, SEQUENCE_LENGTH, n_splits=n_splits)\n",
        "    fold_rewards = []\n",
        "\n",
        "    for i, (tr_start, tr_end, te_start, te_end) in enumerate(splits):\n",
        "        print(f\"🔁 Fold {i+1}: Train {tr_start}-{tr_end}, Test {te_start}-{te_end}\")\n",
        "        total_reward, agent = train_agent_on_split(X, tr_start, tr_end, te_start, te_end, episodes)\n",
        "        fold_rewards.append(total_reward)\n",
        "        model_path = f\"{SAVE_DIR}/deep_sarsa_{ticker}_fold{i+1}.pth\"\n",
        "        torch.save(agent.model.state_dict(), model_path)\n",
        "        print(f\"✅ Fold {i+1} Reward: {total_reward:.4f} | Saved: {model_path}\")\n",
        "        del agent\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # ✅ Final print and return are now correctly inside the function\n",
        "    print(f\"🎯 Rewards for {ticker}: {fold_rewards}\")\n",
        "    return fold_rewards\n",
        "\n",
        "# ✅ Run Walkforward for All Tickers\n",
        "all_rewards = {}\n",
        "for ticker in TICKERS:\n",
        "    rewards = walkforward_train_on_stock(ticker, episodes=5, n_splits=3)\n",
        "    all_rewards[ticker] = rewards\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# ✅ Summary Plot\n",
        "summary = []\n",
        "initial_cash = 100000\n",
        "\n",
        "for symbol, rewards in all_rewards.items():\n",
        "    if len(rewards) == 0:\n",
        "        continue\n",
        "    avg_return = np.mean(rewards)\n",
        "    final_value = initial_cash * (1 + avg_return)\n",
        "    summary.append({\"Symbol\": symbol, \"Avg Reward\": avg_return, \"Portfolio Value\": final_value})\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "top5 = df_summary.sort_values(by=\"Portfolio Value\", ascending=False).head(5)\n",
        "bottom5 = df_summary.sort_values(by=\"Portfolio Value\", ascending=True).head(5)\n",
        "\n",
        "print(\"📈 Top 5 by Portfolio Value:\")\n",
        "print(top5)\n",
        "\n",
        "print(\"\\n📉 Bottom 5 by Portfolio Value:\")\n",
        "print(bottom5)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(top5['Symbol'], top5['Portfolio Value'], color='green', label='Top 5')\n",
        "plt.bar(bottom5['Symbol'], bottom5['Portfolio Value'], color='red', label='Bottom 5', alpha=0.6)\n",
        "plt.axhline(initial_cash, linestyle='--', color='gray', label='Initial Investment')\n",
        "plt.ylabel(\"Portfolio Value ($)\")\n",
        "plt.title(\"Deep SARSA - Top vs Bottom 5 by Walkforward Portfolio Return\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# ✅ Save SARSA Summary to CSV\n",
        "os.makedirs(\"results/sarsa_walkforward\", exist_ok=True)\n",
        "df_summary.to_csv(\"results/sarsa_walkforward/summary.csv\", index=False)\n",
        "print(\"\\n📁 SARSA walkforward summary saved to results/sarsa_walkforward/summary.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zk45jDkH_V9f",
        "outputId": "e93f2320-8281-42f1-d017-9730a1fceec9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Walkforward SARSA on AAPL\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.2419 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AAPL_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1733 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AAPL_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.1099 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AAPL_fold3.pth\n",
            "🎯 Rewards for AAPL: [np.float64(0.24185160559530572), np.float64(0.17333142418876735), np.float64(-0.10985592101812225)]\n",
            "📈 Walkforward SARSA on TSLA\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1427 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TSLA_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.1008 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TSLA_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.1163 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TSLA_fold3.pth\n",
            "🎯 Rewards for TSLA: [np.float64(0.14265235579695684), np.float64(-0.10079424732139664), np.float64(0.11632116265231757)]\n",
            "📈 Walkforward SARSA on MSFT\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.4262 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MSFT_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1114 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MSFT_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.1298 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MSFT_fold3.pth\n",
            "🎯 Rewards for MSFT: [np.float64(0.4262392223775371), np.float64(0.11136046685074596), np.float64(-0.12981590710977553)]\n",
            "📈 Walkforward SARSA on GOOG\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.2908 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_GOOG_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1988 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_GOOG_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.0721 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_GOOG_fold3.pth\n",
            "🎯 Rewards for GOOG: [np.float64(0.2908183822797653), np.float64(0.19884129219734614), np.float64(-0.07210112622439757)]\n",
            "📈 Walkforward SARSA on AMZN\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.3197 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AMZN_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1114 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AMZN_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0530 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AMZN_fold3.pth\n",
            "🎯 Rewards for AMZN: [np.float64(0.319730175020299), np.float64(0.111381036156878), np.float64(0.052982891837734414)]\n",
            "📈 Walkforward SARSA on NVDA\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1595 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NVDA_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.4017 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NVDA_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.0182 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NVDA_fold3.pth\n",
            "🎯 Rewards for NVDA: [np.float64(0.159514667397123), np.float64(0.4017442156254136), np.float64(-0.01823090596198007)]\n",
            "📈 Walkforward SARSA on META\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.2136 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_META_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2467 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_META_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0108 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_META_fold3.pth\n",
            "🎯 Rewards for META: [np.float64(0.21359268699627265), np.float64(0.24671328064258896), np.float64(0.010801913478196257)]\n",
            "📈 Walkforward SARSA on JPM\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1482 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_JPM_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2817 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_JPM_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.1756 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_JPM_fold3.pth\n",
            "🎯 Rewards for JPM: [np.float64(0.14822411960922433), np.float64(0.2817356830003578), np.float64(0.1755894261467561)]\n",
            "📈 Walkforward SARSA on BAC\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0797 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_BAC_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.3685 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_BAC_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.0004 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_BAC_fold3.pth\n",
            "🎯 Rewards for BAC: [np.float64(0.07967832358367288), np.float64(0.36853967940038235), np.float64(-0.00043892521432775666)]\n",
            "📈 Walkforward SARSA on WMT\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0848 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_WMT_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2325 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_WMT_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.3927 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_WMT_fold3.pth\n",
            "🎯 Rewards for WMT: [np.float64(0.08477488982650927), np.float64(0.23253492388182262), np.float64(0.3926739737887419)]\n",
            "📈 Walkforward SARSA on UNH\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.3539 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_UNH_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1273 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_UNH_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.6176 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_UNH_fold3.pth\n",
            "🎯 Rewards for UNH: [np.float64(0.3538745426956167), np.float64(0.12727749446489334), np.float64(-0.6176442439125012)]\n",
            "📈 Walkforward SARSA on V\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1846 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_V_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.0392 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_V_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.3933 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_V_fold3.pth\n",
            "🎯 Rewards for V: [np.float64(0.18464315932828002), np.float64(0.039187689981348584), np.float64(0.39325486765318796)]\n",
            "📈 Walkforward SARSA on PG\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1201 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PG_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.3463 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PG_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0010 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PG_fold3.pth\n",
            "🎯 Rewards for PG: [np.float64(0.12008695122587154), np.float64(0.34634802064952286), np.float64(0.0010434359400788296)]\n",
            "📈 Walkforward SARSA on HD\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1405 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_HD_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2435 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_HD_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0398 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_HD_fold3.pth\n",
            "🎯 Rewards for HD: [np.float64(0.1405301958125924), np.float64(0.2435166939204525), np.float64(0.039818051681832056)]\n",
            "📈 Walkforward SARSA on MA\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1992 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MA_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1548 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MA_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.2159 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MA_fold3.pth\n",
            "🎯 Rewards for MA: [np.float64(0.1992239104087672), np.float64(0.1548398706414813), np.float64(0.2158717447609595)]\n",
            "📈 Walkforward SARSA on DIS\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0293 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_DIS_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.1397 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_DIS_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.0482 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_DIS_fold3.pth\n",
            "🎯 Rewards for DIS: [np.float64(0.029340715662748762), np.float64(-0.13965715943565749), np.float64(-0.048217390174103425)]\n",
            "📈 Walkforward SARSA on PEP\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.1511 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PEP_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.0990 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PEP_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.5576 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PEP_fold3.pth\n",
            "🎯 Rewards for PEP: [np.float64(-0.15113661213453433), np.float64(0.09895007241347686), np.float64(-0.5576052057394665)]\n",
            "📈 Walkforward SARSA on KO\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.0843 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_KO_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.4792 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_KO_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.1808 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_KO_fold3.pth\n",
            "🎯 Rewards for KO: [np.float64(-0.08426071286236603), np.float64(0.47921869314342125), np.float64(0.18078598534074963)]\n",
            "📈 Walkforward SARSA on CSCO\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.1077 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CSCO_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.0846 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CSCO_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.4056 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CSCO_fold3.pth\n",
            "🎯 Rewards for CSCO: [np.float64(-0.10769524375604589), np.float64(-0.0845904280736105), np.float64(0.4055757083085674)]\n",
            "📈 Walkforward SARSA on ADBE\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.7118 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ADBE_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.2617 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ADBE_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.4854 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ADBE_fold3.pth\n",
            "🎯 Rewards for ADBE: [np.float64(0.7117642606025898), np.float64(-0.2616635356425081), np.float64(-0.48537410189228714)]\n",
            "📈 Walkforward SARSA on CRM\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1692 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CRM_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.0803 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CRM_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0249 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CRM_fold3.pth\n",
            "🎯 Rewards for CRM: [np.float64(0.16916949266426418), np.float64(0.08031195633325339), np.float64(0.024869369646372652)]\n",
            "📈 Walkforward SARSA on NFLX\n",
            "🔁 Fold 1: Train 0-1270, Test 1270-2480\n",
            "✅ Fold 1 Reward: 0.1932 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NFLX_fold1.pth\n",
            "🔁 Fold 2: Train 0-2480, Test 2480-3690\n",
            "✅ Fold 2 Reward: 0.1542 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NFLX_fold2.pth\n",
            "🔁 Fold 3: Train 0-3690, Test 3690-4900\n",
            "✅ Fold 3 Reward: 0.4038 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NFLX_fold3.pth\n",
            "🎯 Rewards for NFLX: [np.float64(0.19316968978679055), np.float64(0.15417106322531415), np.float64(0.40384090164256387)]\n",
            "📈 Walkforward SARSA on PFE\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.3133 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PFE_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.0191 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PFE_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.2026 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PFE_fold3.pth\n",
            "🎯 Rewards for PFE: [np.float64(-0.31331939688229216), np.float64(-0.01907030284443867), np.float64(-0.2025655315745185)]\n",
            "📈 Walkforward SARSA on MRK\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.0856 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MRK_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1726 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MRK_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.5620 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MRK_fold3.pth\n",
            "🎯 Rewards for MRK: [np.float64(-0.08564049773820948), np.float64(0.17257097303826185), np.float64(-0.5619947576949287)]\n",
            "📈 Walkforward SARSA on T\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.1454 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_T_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2113 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_T_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.5143 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_T_fold3.pth\n",
            "🎯 Rewards for T: [np.float64(-0.14544860176030405), np.float64(0.21131339244584524), np.float64(0.5143042775393145)]\n",
            "📈 Walkforward SARSA on ORCL\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.2149 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ORCL_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.0922 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ORCL_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0155 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ORCL_fold3.pth\n",
            "🎯 Rewards for ORCL: [np.float64(0.21491705846971498), np.float64(0.0922111779219838), np.float64(0.015473722003542578)]\n",
            "📈 Walkforward SARSA on ABBV\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.2061 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ABBV_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.5714 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ABBV_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.1497 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ABBV_fold3.pth\n",
            "🎯 Rewards for ABBV: [np.float64(-0.20614618697127618), np.float64(0.5713873692993017), np.float64(-0.14966154961283884)]\n",
            "📈 Walkforward SARSA on CVX\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.2124 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CVX_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.0316 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CVX_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.0896 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_CVX_fold3.pth\n",
            "🎯 Rewards for CVX: [np.float64(-0.21242701494924), np.float64(0.031598583301279515), np.float64(-0.08956281360341922)]\n",
            "📈 Walkforward SARSA on XOM\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0337 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_XOM_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2916 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_XOM_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.1918 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_XOM_fold3.pth\n",
            "🎯 Rewards for XOM: [np.float64(0.03374830691671127), np.float64(0.29164778783618184), np.float64(-0.1918054253550796)]\n",
            "📈 Walkforward SARSA on ABT\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0903 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ABT_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1729 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ABT_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.4055 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ABT_fold3.pth\n",
            "🎯 Rewards for ABT: [np.float64(0.09028331253157962), np.float64(0.17289521243525163), np.float64(0.40548788128398927)]\n",
            "📈 Walkforward SARSA on COST\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1731 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_COST_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.3698 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_COST_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.2618 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_COST_fold3.pth\n",
            "🎯 Rewards for COST: [np.float64(0.1731464113650354), np.float64(0.36976137213202454), np.float64(0.2617745020187241)]\n",
            "📈 Walkforward SARSA on QCOM\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0542 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_QCOM_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2594 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_QCOM_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.1793 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_QCOM_fold3.pth\n",
            "🎯 Rewards for QCOM: [np.float64(0.05419908512662286), np.float64(0.2594121687462312), np.float64(-0.1792874516100389)]\n",
            "📈 Walkforward SARSA on INTC\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.4633 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_INTC_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.7367 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_INTC_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.0395 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_INTC_fold3.pth\n",
            "🎯 Rewards for INTC: [np.float64(0.46328806745730833), np.float64(-0.7366782868090904), np.float64(-0.03953594975011432)]\n",
            "📈 Walkforward SARSA on MCD\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1317 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MCD_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.1103 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MCD_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.4257 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MCD_fold3.pth\n",
            "🎯 Rewards for MCD: [np.float64(0.13172364630658961), np.float64(-0.11032646937205204), np.float64(0.4257302985275442)]\n",
            "📈 Walkforward SARSA on NKE\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.1542 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NKE_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.4316 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NKE_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.2444 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NKE_fold3.pth\n",
            "🎯 Rewards for NKE: [np.float64(-0.1542035926903269), np.float64(-0.43161639405277663), np.float64(-0.244369153418605)]\n",
            "📈 Walkforward SARSA on DHR\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0294 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_DHR_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.4772 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_DHR_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.7549 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_DHR_fold3.pth\n",
            "🎯 Rewards for DHR: [np.float64(0.029444280281984092), np.float64(0.4771717837816869), np.float64(-0.7549417971187777)]\n",
            "📈 Walkforward SARSA on LLY\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.3835 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_LLY_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2671 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_LLY_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.1220 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_LLY_fold3.pth\n",
            "🎯 Rewards for LLY: [np.float64(0.3835430012094746), np.float64(0.267144864682197), np.float64(0.1219510123028198)]\n",
            "📈 Walkforward SARSA on MDT\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.0156 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MDT_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1181 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MDT_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0354 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_MDT_fold3.pth\n",
            "🎯 Rewards for MDT: [np.float64(-0.015619187127976275), np.float64(0.11814458937872008), np.float64(0.03542858305431551)]\n",
            "📈 Walkforward SARSA on TMO\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.2819 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TMO_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.5211 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TMO_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.7837 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TMO_fold3.pth\n",
            "🎯 Rewards for TMO: [np.float64(-0.2818503634918996), np.float64(0.5211226492021268), np.float64(-0.7836907957804273)]\n",
            "📈 Walkforward SARSA on TXN\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.3279 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TXN_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.4741 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TXN_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.5021 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_TXN_fold3.pth\n",
            "🎯 Rewards for TXN: [np.float64(-0.32787701688400905), np.float64(0.47414435639566355), np.float64(-0.5021082068406075)]\n",
            "📈 Walkforward SARSA on PM\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.0284 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PM_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2738 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PM_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.5769 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_PM_fold3.pth\n",
            "🎯 Rewards for PM: [np.float64(-0.02839753548378865), np.float64(0.2737721594304736), np.float64(0.5769255299073761)]\n",
            "📈 Walkforward SARSA on AVGO\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.1522 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AVGO_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2402 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AVGO_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.1372 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_AVGO_fold3.pth\n",
            "🎯 Rewards for AVGO: [np.float64(0.1522031054030142), np.float64(0.24024967804446296), np.float64(0.13717246052660326)]\n",
            "📈 Walkforward SARSA on NEE\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.4179 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NEE_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.4814 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NEE_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.2582 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_NEE_fold3.pth\n",
            "🎯 Rewards for NEE: [np.float64(-0.41787976965085183), np.float64(0.48137540025905845), np.float64(-0.2581890517785408)]\n",
            "📈 Walkforward SARSA on ACN\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.5255 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ACN_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.0658 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ACN_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.2362 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_ACN_fold3.pth\n",
            "🎯 Rewards for ACN: [np.float64(0.5255152011595214), np.float64(-0.06581941678349912), np.float64(-0.23623480146908116)]\n",
            "📈 Walkforward SARSA on UPS\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: -0.2800 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_UPS_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: -0.2006 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_UPS_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.2507 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_UPS_fold3.pth\n",
            "🎯 Rewards for UPS: [np.float64(-0.28000352090780445), np.float64(-0.20064150209391585), np.float64(-0.250673497593209)]\n",
            "📈 Walkforward SARSA on HON\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0606 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_HON_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1388 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_HON_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: -0.0636 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_HON_fold3.pth\n",
            "🎯 Rewards for HON: [np.float64(0.06063174228395152), np.float64(0.13881969864105947), np.float64(-0.06359270478394885)]\n",
            "📈 Walkforward SARSA on LIN\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.3292 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_LIN_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.1606 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_LIN_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0268 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_LIN_fold3.pth\n",
            "🎯 Rewards for LIN: [np.float64(0.3291830338395858), np.float64(0.16055991588220886), np.float64(0.026808445023796423)]\n",
            "📈 Walkforward SARSA on GS\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.0739 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_GS_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.3663 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_GS_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.0790 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_GS_fold3.pth\n",
            "🎯 Rewards for GS: [np.float64(0.07392245982000956), np.float64(0.3662555595150587), np.float64(0.0789839155872536)]\n",
            "📈 Walkforward SARSA on IBM\n",
            "🔁 Fold 1: Train 0-1271, Test 1271-2482\n",
            "✅ Fold 1 Reward: 0.2086 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_IBM_fold1.pth\n",
            "🔁 Fold 2: Train 0-2482, Test 2482-3693\n",
            "✅ Fold 2 Reward: 0.2271 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_IBM_fold2.pth\n",
            "🔁 Fold 3: Train 0-3693, Test 3693-4904\n",
            "✅ Fold 3 Reward: 0.3506 | Saved: /content/drive/MyDrive/DeepSARSA_Models/deep_sarsa_IBM_fold3.pth\n",
            "🎯 Rewards for IBM: [np.float64(0.2086316243905849), np.float64(0.22705048473139522), np.float64(0.3506011201080297)]\n",
            "📈 Top 5 by Portfolio Value:\n",
            "   Symbol  Avg Reward  Portfolio Value\n",
            "40     PM    0.274100    127410.005128\n",
            "30   COST    0.268227    126822.742851\n",
            "48    IBM    0.262094    126209.440974\n",
            "36    LLY    0.257546    125754.629273\n",
            "21   NFLX    0.250394    125039.388488\n",
            "\n",
            "📉 Bottom 5 by Portfolio Value:\n",
            "   Symbol  Avg Reward  Portfolio Value\n",
            "34    NKE   -0.276730     72327.028661\n",
            "44    UPS   -0.243773     75622.715980\n",
            "16    PEP   -0.203264     79673.608485\n",
            "38    TMO   -0.181473     81852.716331\n",
            "22    PFE   -0.178318     82168.158957\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlBRJREFUeJzs3Xd4FOX39/HPJqQDCS0JwQARkN4ERDoIErqxgCBKkWIBEVBQLFQB6UVQBH8UNShiQVAMhN57R0BQmkLoISShpMzzB0/mmyWFBDabJbxf15ULdubs7Jk9u7Obk7nvsRiGYQgAAAAAAACwI6fsTgAAAAAAAAAPH5pSAAAAAAAAsDuaUgAAAAAAALA7mlIAAAAAAACwO5pSAAAAAAAAsDuaUgAAAAAAALA7mlIAAAAAAACwO5pSAAAAAAAAsDuaUgAAAAAAALA7mlIAAAA52IkTJ2SxWDR+/PjsTsUmGjZsqIYNG5q316xZI4vFoh9//PGu992+fbtq164tLy8vWSwW7dmzJ+sSzUZJz8maNWuyO5UMuZ+6zJ07VxaLRSdOnDCX3fkaAQA4LppSAJADJX1JT/pxd3dXQECAgoODNXXqVF27di27U8yQEydOqGvXripRooTc3d3l7++v+vXra8iQIWneZ+DAgbJYLHrxxRfT3Gby58bJyUn58+dX8+bNtXnz5lTvs2HDBjVv3lxFihSRu7u7ihYtqtatW2v+/Plp5vHEE0/IYrHoiy++yNxOZ0CXLl2s9iGtny5dutj8se2tePHiKV7LpUqV0oABA3T58uV72uamTZs0dOhQRUZGplg3atQoLVq06P6SzgJp1bxMmTLZnZok6YcffpDFYtEvv/ySYl3lypVlsVi0evXqFOuKFi2q2rVr2yNFxcXFqW3btrp8+bImTZqkb775RsWKFbPLYzuq1D4rHnvsMfXu3Vvnzp2z6WOl9d56EOrSsGFDq+fJw8NDlSpV0uTJk5WYmHhP25w/f74mT55s20QB4AGUK7sTAABkneHDhysoKEhxcXGKiIjQmjVr1LdvX02cOFGLFy9WpUqVsjvFNB07dkw1atSQh4eHXn31VRUvXlxnz57Vrl27NGbMGA0bNizFfQzD0HfffafixYtryZIlunbtmvLkyZPq9jt06KAWLVooISFBf/31lz7//HM1atRI27dvV8WKFc24hQsX6sUXX1SVKlX09ttvK1++fDp+/LjWrVunWbNm6aWXXkqx7aNHj2r79u0qXry4QkND9cYbb9juiZH02muvqUmTJubt48ePa/DgwerZs6fq1atnLi9RooRNHze7VKlSRe+8844k6caNG9q5c6cmT56stWvXatu2bZne3qZNmzRs2DB16dJFPj4+VutGjRqlF154QSEhITbI3Lbc3Nz01VdfWS3z9vbOpmys1a1bV9LtBu6zzz5rLo+KitKBAweUK1cubdy4UY0aNTLXnT59WqdPn1b79u3tkuPff/+tkydPatasWerevbtdHvNBkfRZcePGDW3YsEFffPGFli5dqgMHDsjT09Mmj5HWeysr6rJ8+XKbbCe5Rx55RKNHj5YkXbx4UfPnz1e/fv104cIFjRw5MtPbmz9/vg4cOKC+ffvaOFMAeLDQlAKAHKx58+aqXr26eXvQoEFatWqVWrVqpTZt2ujQoUPy8PDIxgzTNmnSJEVHR2vPnj0p/mp+/vz5VO+zZs0a/fvvv1q1apWCg4P1888/q3PnzqnGPv7443r55ZfN2/Xq1VPz5s31xRdf6PPPPzeXDx06VOXKldOWLVvk6uqaoTy+/fZb+fr6asKECXrhhRd04sQJFS9ePCO7nSG1atVSrVq1zNs7duzQ4MGDVatWLat9yimKFClitV/du3dX7ty5NX78eB09elSlSpXKxuzsJ1euXA5b34CAAAUFBWnDhg1Wyzdv3izDMNS2bdsU65JuJzW0slrS+/XORuT9iImJkZeXl822l1GGYejGjRs2O34n/6zo3r27ChQooIkTJ+rXX39Vhw4dsjTPrKjLncdqW/D29rZ6/73++usqU6aMPvvsMw0fPlzOzs42f8x7ERsba7NGIgDYA8P3AOAh89RTT+njjz/WyZMn9e2331qtO3z4sF544QXlz59f7u7uql69uhYvXpxiG5GRkerbt68CAwPl5uamkiVLasyYMVbDGJLPYzNp0iQVK1ZMHh4eatCggQ4cOHDXPP/++2898sgjqQ7j8PX1TfU+oaGhKleunBo1aqQmTZooNDT0ro+TJOkMo7///jtFHjVq1Ej1l5y08pg/f75eeOEFtWrVSt7e3ukO88tKCxcuVLVq1eTh4aGCBQvq5Zdf1n///WcV06VLF+XOnVv//POPgoOD5eXlpYCAAA0fPlyGYaS7/VatWunRRx9NdV2tWrWsGqLh4eGqW7eufHx8lDt3bpUuXVoffPDBPe+bv7+/pNuNmuRWrVqlevXqycvLSz4+PnrmmWd06NAhc/3QoUM1YMAASVJQUJA5HCfp9RoTE6N58+alOgRy9+7dat68ufLmzavcuXOrcePG2rJli9XjJw2H2rBhg/r06aNChQrJx8dHr732mm7duqXIyEh16tRJ+fLlU758+TRw4MC7Ps/JJSQkKCoqKrNPlym99+KcOXNksVi0e/fuFPcbNWqUnJ2dU7x+kqtbt652796t69evm8s2btyo8uXLq3nz5tqyZYvVMWLjxo2yWCyqU6eO+fhPPfWUfH195ebmpnLlyt3z8NebN2+a779NmzapS5cuatCggSSpbdu2slgsVnMO3e11I91+7VgsFv3555966aWXlC9fPtWtW1eLFy+WxWLRvn37zNiffvpJFotFzz33nNU2ypYtazW0OKP7XLx4cbVq1UrLli1T9erV5eHhoS+//FKS9O+//yokJEReXl7y9fVVv379dPPmzXt63pI89dRTkm6fhSlJ8fHxGjFihEqUKCE3NzcVL15cH3zwQYrHSSvPtN5btqhLalKbU+r8+fPq1q2b/Pz85O7ursqVK2vevHn3/By5u7urRo0aunbtWoo/UHz77bfmsTd//vxq3769Tp8+bZXf77//rpMnT5rPR9IfLlKbI0tKfZ6whg0bqkKFCtq5c6fq168vT09PffDBB1afvzNnzjTrVqNGDW3fvv2e9xkAsgJnSgHAQ+iVV17RBx98oOXLl6tHjx6SpIMHD6pOnToqUqSI3n//fXl5eemHH35QSEiIfvrpJ3NITmxsrBo0aKD//vtPr732mooWLapNmzZp0KBBOnv2bIo5Mr7++mtdu3ZNvXr10o0bNzRlyhQ99dRT2r9/v/z8/NLMsVixYlqxYoVWrVpl/oKUnps3b+qnn34yh3l16NBBXbt2VUREhNnASE/SLwD58uVLkcfKlSv177//6pFHHrnrdrZu3apjx45pzpw5cnV11XPPPafQ0ND7asDci7lz56pr166qUaOGRo8erXPnzmnKlCnauHGjdu/ebXVWQkJCgpo1a6Ynn3xSY8eOVVhYmIYMGaL4+HgNHz48zcd48cUX1alTJ23fvl01atQwl588eVJbtmzRuHHjJN1+bbVq1UqVKlXS8OHD5ebmpmPHjmnjxo0Z2pe4uDhdvHhR0u3he7t379bEiRNVv359BQUFmXErVqxQ8+bN9eijj2ro0KG6fv26PvvsM9WpU0e7du1S8eLF9dxzz+mvv/7Sd999p0mTJqlgwYKSpEKFCumbb75R9+7d9cQTT6hnz56S/jcE8uDBg6pXr57y5s2rgQMHysXFRV9++aUaNmyotWvXqmbNmlY5v/XWW/L399ewYcO0ZcsWzZw5Uz4+Ptq0aZOKFi2qUaNGaenSpRo3bpwqVKigTp063fV5iI2NVd68eRUbG6t8+fKpQ4cOGjNmjHLnzp2h5/Fu78UXXnhBvXr1UmhoqKpWrWp139DQUDVs2FBFihRJc/t169bVN998o61bt5oNgY0bN6p27dqqXbu2rl69qgMHDpjDhjdu3KgyZcqoQIECkqQvvvhC5cuXV5s2bZQrVy4tWbJEb775phITE9WrV68M7aMkXb9+Xc8884x27NihFStWqEaNGrJYLCpSpIhGjRqlPn36qEaNGubxJyOvm+Tatm2rUqVKadSoUTIMQ3Xr1pXFYtG6devMfVu/fr2cnJyszg67cOGCDh8+rN69e5vLMrPPR44cUYcOHfTaa6+pR48eKl26tK5fv67GjRvr1KlT6tOnjwICAvTNN99o1apVGX6+UpPUnE+qTffu3TVv3jy98MILeuedd7R161aNHj1ahw4dSjGPWGp5pvfeslVd0nP9+nU1bNhQx44dU+/evRUUFKSFCxeqS5cuioyM1Ntvv31Pz1NS8yf58XTkyJH6+OOP1a5dO3Xv3l0XLlzQZ599pvr165vH3g8//FBXr17Vv//+q0mTJklSht/Hd7p06ZKaN2+u9u3b6+WXX7b6XJ0/f76uXbum1157TRaLRWPHjtVzzz2nf/75Ry4uLvf0eABgcwYAIMeZM2eOIcnYvn17mjHe3t5G1apVzduNGzc2KlasaNy4ccNclpiYaNSuXdsoVaqUuWzEiBGGl5eX8ddff1lt7/333zecnZ2NU6dOGYZhGMePHzckGR4eHsa///5rxm3dutWQZPTr1y/dfThw4IDh4eFhSDKqVKlivP3228aiRYuMmJiYVON//PFHQ5Jx9OhRwzAMIyoqynB3dzcmTZpkFZeU17Bhw4wLFy4YERERxvr1640aNWoYkoyFCxdaxf/f//2fIclwdXU1GjVqZHz88cfG+vXrjYSEhFTz6N27txEYGGgkJiYahmEYy5cvNyQZu3fvTnd/78f27dsNScacOXMMwzCMW7duGb6+vkaFChWM69evm3G//fabIckYPHiwuaxz586GJOOtt94ylyUmJhotW7Y0XF1djQsXLqT5uFevXjXc3NyMd955x2r52LFjDYvFYpw8edIwDMOYNGmSISndbaWlWLFihqQUP3Xq1DEuXrxoFVulShXD19fXuHTpkrls7969hpOTk9GpUydz2bhx4wxJxvHjx1M8npeXl9G5c+cUy0NCQgxXV1fj77//NpedOXPGyJMnj1G/fn1zWdJ7Lzg42HwNGIZh1KpVy7BYLMbrr79uLouPjzceeeQRo0GDBnd9Ht5//33jvffeMxYsWGB89913Zt3q1KljxMXFpXvfzLwXO3ToYAQEBFi9vnft2mX1+krLwYMHDUnGiBEjDMMwjLi4OMPLy8uYN2+eYRiG4efnZ0yfPt0wjNvvT2dnZ6NHjx7m/WNjY1NsMzg42Hj00UetljVo0MDqOVu9erX53r127ZrRoEEDo2DBginec8njksvo62bIkCGGJKNDhw4p8ixfvrzRrl078/bjjz9utG3b1pBkHDp0yDAMw/j5558NScbevXszvc9J74OwsDCr5ZMnTzYkGT/88IO5LCYmxihZsqQhyVi9enWK7SeX9HpdsWKFceHCBeP06dPG999/bxQoUMB8vezZs8eQZHTv3t3qvu+++64hyVi1atVd8zSMtN9b91uXpH1I/n6+8zWS9Dx9++235rJbt24ZtWrVMnLnzm1ERUWl+zw1aNDAKFOmjHHhwgXjwoULxuHDh40BAwYYkoyWLVuacSdOnDCcnZ2NkSNHWt1///79Rq5cuayWt2zZ0ihWrFiKx0ptf5I/T8lr2qBBA0OSMWPGDKvYpPd8gQIFjMuXL5vLf/31V0OSsWTJknT3FwDsieF7APCQyp07t3kVvsuXL2vVqlVq166drl27posXL+rixYu6dOmSgoODdfToUXPYzsKFC1WvXj3ly5fPjLt48aKaNGmihIQErVu3zupxQkJCrM6ueOKJJ1SzZk0tXbo03fzKly+vPXv26OWXX9aJEyc0ZcoUhYSEyM/PT7NmzUoRHxoaqurVq6tkyZKSpDx58qhly5ZpDuEbMmSIChUqJH9/f9WrV0+HDh0y54BK7tVXX1VYWJgaNmyoDRs2aMSIEapXr55KlSqlTZs2WcXGx8drwYIFevHFF2WxWCTJHJqTmaGE92vHjh06f/683nzzTbm7u5vLW7ZsqTJlyuj3339PcZ/kZ29YLBb17t1bt27d0ooVK9J8nLx586p58+b64YcfrIagLViwQE8++aSKFi0q6X9zxfz666/3dKWqmjVrKjw8XOHh4frtt980cuRIHTx4UG3atDGHip09e1Z79uxRly5dlD9/fvO+lSpV0tNPP33X11t6EhIStHz5coWEhFgNVyxcuLBeeuklbdiwIcWQum7dupmvgaR9MAxD3bp1M5c5OzurevXq+ueff+6aw+jRo/Xpp5+qXbt2at++vebOnauRI0dq48aN+vHHHzO0Hxl5L3bq1ElnzpyxulJeaGioPDw89Pzzz6e7/bJly6pAgQLm2UF79+5VTEyMeXW92rVrm2fHbd68WQkJCVbzSSWfd+jq1au6ePGiGjRooH/++UdXr1696/5dvXpVTZs21eHDh7VmzRpVqVLlrve5l9fN66+/nmJZvXr1tH79eknStWvXtHfvXvXs2VMFCxY0l69fv14+Pj6qUKHCPe1zUFCQgoODrZYtXbpUhQsXtjpueXp6mmcjZVSTJk1UqFAhBQYGqn379sqdO7d++eUXFSlSxHwO+vfvb3WfpLNS7zyepJZnZtn6/bx06VL5+/tbzY/l4uKiPn36KDo6WmvXrr3rNg4fPqxChQqpUKFCKlOmjMaNG6c2bdpo7ty5ZszPP/+sxMREtWvXzurz0d/fX6VKlUr1CpT3y83NTV27dk113Ysvvmh19m/SMPWMHHMAwF5oSgHAQyo6Otq8Mt2xY8dkGIY+/vhj80t30s+QIUMk/W8y2qNHjyosLCxFXNLV4O6cWyO1Sagfe+yxFPNlpOaxxx7TN998o4sXL2rfvn0aNWqUcuXKpZ49e1o1SyIjI7V06VI1aNBAx44dM3/q1KmjHTt26K+//kqx7Z49eyo8PFxLlixRv379dP36dSUkJKSaR3BwsJYtW6bIyEitW7dOvXr10smTJ9WqVSur/V2+fLkuXLigJ554wszh+PHjatSokb777ru7NmQiIiKsfpLPzZMZJ0+elCSVLl06xboyZcqY65M4OTmlmBvqsccek6S71unFF1/U6dOntXnzZkm3h/3s3LnTat6cF198UXXq1FH37t3l5+en9u3b64cffshwg6pgwYJq0qSJmjRpopYtW+qDDz7QV199pU2bNplXo0tvn8uWLauLFy8qJiYmQ493pwsXLig2NjbNbScmJlrNFyPJbMglSbpKXmBgYIrlV65cuae8+vXrJycnp3Qbh8ll5L349NNPq3DhwmYTNTExUd99952eeeaZNK9kmcRisah27drm3FEbN26Ur6+v2ShO3pRK+jd5U2rjxo1q0qSJOX9QoUKFzGGvGWlK9e3bV9u3b9eKFStUvnz5u8ZL9/a6ST5kNEm9evV09uxZHTt2TJs2bZLFYlGtWrWsmlXr169XnTp15OT0v6/fmdnn1B735MmTKlmypFUDNK39Sc/06dMVHh6u1atX688//zTnmEt6DCcnJ7OOSfz9/eXj45PieJJanpll6/fzyZMnVapUKavnPmlbyR8vPcWLF1d4eLiWLVumzz//XEWKFNGFCxesGv9Hjx6VYRgqVapUis/IQ4cOpXlxjPtRpEiRNCd2v/M4lNSgutdjDgBkBeaUAoCH0L///qurV6+av2QkNQfefffdNP/CnTz26aef1sCBA1ONS2pm2JKzs7MqVqyoihUrqlatWmrUqJFCQ0PNRtjChQt18+ZNTZgwQRMmTEhx/9DQUA0bNsxqWalSpcz7t2rVSs7Oznr//ffVqFEjqwm6k/P09FS9evVUr149FSxYUMOGDdMff/xhXuEv6Rf5du3apXr/tWvXqlGjRmnuZ+HCha1uz5kzx2qibUfUunVreXp66ocfflDt2rX1ww8/yMnJSW3btjVjPDw8tG7dOq1evVq///67wsLCtGDBAj311FNavnz5PV21qnHjxpKkdevW6a233rLZ/thKWvuU2nIjExOdJ+fh4aECBQro8uXL93T/1Dg7O+ull17SrFmz9Pnnn2vjxo06c+ZMhq/6V7duXS1ZskT79+8355NKUrt2bQ0YMED//fefNmzYoICAALMZ+vfff6tx48YqU6aMJk6cqMDAQLm6umrp0qWaNGlShhqYzzzzjL7//nt9+umn+vrrr1M0IGwltSvJJTXX1q1bp3/++UePP/64vLy8VK9ePU2dOlXR0dHavXu3Ro4cad4ns/uclVdKfeKJJ9I87iW5s/GVFke9ouv98vLyMj8zJKlOnTp6/PHH9cEHH2jq1KmSbn8+WiwW/fHHH6m+1zMyb1Raz3NafzRJ7/lO6zh0r8ccAMgKNKUA4CH0zTffSJLZgEr6xdDFxcXqS3dqSpQooejo6LvGJTl69GiKZX/99VemJqlNLukXp7Nnz5rLQkNDVaFCBfOsruS+/PJLzZ8/P0VT6k4ffvihZs2apY8++khhYWGZziMmJka//vqrXnzxxRRDACWpT58+Cg0NTbcpFR4ebnU7o2d73CnpioVHjhxJMUn8kSNHUlzRMDExUf/8849VQzHp7LK71cnLy0utWrXSwoULNXHiRC1YsED16tVTQECAVZyTk5MaN26sxo0ba+LEiRo1apQ+/PBDrV69OsOvpeTi4+Ml3T7j7859vtPhw4dVsGBBeXl5SUr/l+vU1hUqVEienp5pbtvJySnFGVD2kDTUtlChQhmKz+h7sVOnTpowYYKWLFmiP/74Q4UKFcrwcKyk5syGDRu0ceNG9e3b11xXrVo1ubm5ac2aNdq6datatGhhrluyZIlu3rypxYsXW53dkZnhTiEhIWratKm6dOmiPHnyZOjKfZl53aSnaNGiKlq0qNavX69//vnHHCZVv3599e/fXwsXLlRCQoLq169v3scW+1ysWDEdOHBAhmFYvXZT2597VaxYMSUmJuro0aPmmUWSdO7cOUVGRqZ6hdTUZLSplfSY0v3XJfn29u3bp8TERKtm5eHDh60eLzMqVaqkl19+WV9++aXeffddFS1aVCVKlJBhGAoKCrrrH2jSej6SzmaKjIy0Wp6Rs7kA4EHE8D0AeMisWrVKI0aMUFBQkDp27ChJ8vX1VcOGDfXll19aNXuSXLhwwfx/u3bttHnzZi1btixFXGRkpNksSLJo0SKry8hv27ZNW7duVfPmzdPNc/369YqLi0uxPGkukaRhHadPn9a6devUrl07vfDCCyl+unbtqmPHjmnr1q3pPp6Pj49ee+01LVu2THv27DGXr1y5MtX4O/P45ZdfFBMTo169eqWaR6tWrfTTTz+le6n2pCFqST93njmVUdWrV5evr69mzJhh9Xh//PGHDh06pJYtW6a4z7Rp08z/G4ahadOmycXFxTwjKT0vvviizpw5o6+++kp79+61GronKdUzeZLm+7nXS9cvWbJEklS5cmVJt88yq1KliubNm2f1y9yBAwe0fPlyqwZI0i+zd/7Sl7TuzuXOzs5q2rSpfv31V6uhbufOndP8+fNVt25d5c2b9572IyNu3Lhhzv+W3IgRI2QYhpo1a5ah7WT0vVipUiVVqlRJX331lX766Se1b99euXJl7O+Y1atXl7u7u0JDQ/Xff/9ZnSnl5uamxx9/XNOnT1dMTIzV0L2kMzqSn8Fx9epVzZkzJ0OPm6RTp06aOnWqZsyYoffee++u8Zl53dxNvXr1tGrVKm3bts1sSlWpUkV58uTRp59+Kg8PD1WrVs2Mt8U+t2jRQmfOnLGaVyw2NlYzZ87M8DYy8hiSUlxZdeLEiZKU6vEkNam9t9Jiy7pIt/chIiJCCxYsMJfFx8frs88+U+7cudWgQYNMbS/JwIEDFRcXZz4Xzz33nJydnTVs2LAUZyMZhqFLly6Zt728vFIdlpp0VcLk8zMmJCTYtKYA4Eg4UwoAcrA//vhDhw8fVnx8vM6dO6dVq1YpPDxcxYoV0+LFi63mwpg+fbrq1q2rihUrqkePHnr00Ud17tw5bd68Wf/++6/27t0rSRowYIAWL16sVq1aqUuXLqpWrZpiYmK0f/9+/fjjjzpx4oQKFixobrdkyZKqW7eu3njjDd28eVOTJ09WgQIF0hz+l2TMmDHauXOnnnvuOfMy67t27dLXX3+t/Pnzm2dgzJ8/X4ZhqE2bNqlup0WLFsqVK5dCQ0NVs2bNdB/z7bff1uTJk/Xpp5/q+++/l3R7SFBQUJBat26tEiVKKCYmRitWrNCSJUtUo0YNtW7dWtLts7UKFChg9Ut4cm3atNGsWbP0+++/67nnnks3j/vl4uKiMWPGqGvXrmrQoIE6dOigc+fOacqUKSpevLj69etnFe/u7q6wsDB17txZNWvW1B9//KHff/9dH3zwQYbOwmnRooXy5Mmjd999V87OzikmxB4+fLjWrVunli1bqlixYjp//rw+//xzPfLII1aNibT8999/+vbbbyVJt27d0t69e/Xll1+qYMGCVkP3xo0bp+bNm6tWrVrq1q2beQl5b29vDR061IxLagx8+OGHat++vVxcXNS6dWt5eXmpWrVqWrFihSZOnKiAgAAFBQWpZs2a+uSTTxQeHq66devqzTffVK5cufTll1/q5s2bGjt27F334X5ERESoatWq6tChg8qUKSNJWrZsmZYuXapmzZrpmWeeydB2MvNe7NSpk959911JyvDQPUlydXVVjRo1tH79erm5uVk1YaTbQ/iShtgmr33Tpk3l6uqq1q1b67XXXlN0dLRmzZolX1/fVBvl6endu7eioqL04Ycfytvb25yjKS0Zfd3cTb169RQaGiqLxWLum7Ozs2rXrq1ly5apYcOGVnP/2GKfe/TooWnTpqlTp07auXOnChcurG+++Uaenp4ZzvtuKleurM6dO2vmzJmKjIxUgwYNtG3bNs2bN08hISHpnv2ZXFrvrbTYqi7S7TkEv/zyS3Xp0kU7d+5U8eLF9eOPP2rjxo2aPHnyXedLS0u5cuXUokULffXVV/r4449VokQJffLJJxo0aJBOnDihkJAQ5cmTR8ePH9cvv/yinj17mu+ratWqacGCBerfv79q1Kih3Llzq3Xr1ipfvryefPJJDRo0SJcvX1b+/Pn1/fffp/iDDwDkGNlwxT8AQBZLuqR00o+rq6vh7+9vPP3008aUKVPSvPz133//bXTq1Mnw9/c3XFxcjCJFihitWrUyfvzxR6u4a9euGYMGDTJKlixpuLq6GgULFjRq165tjB8/3rh165ZhGP+7JPW4ceOMCRMmGIGBgYabm5tRr149q0uip2Xjxo1Gr169jAoVKhje3t6Gi4uLUbRoUaNLly7G33//bcZVrFjRKFq0aLrbatiwoeHr62vExcVZ5ZWaLl26GM7OzsaxY8cMwzCM7777zmjfvr1RokQJw8PDw3B3dzfKlStnfPjhh+bzeO7cOSNXrlzGK6+8kmYOsbGxhqenp/Hss8/edd8za/v27YYkY86cOVbLFyxYYFStWtVwc3Mz8ufPb3Ts2NH4999/rWI6d+5seHl5GX///bfRtGlTw9PT0/Dz8zOGDBliJCQkZDiHjh07GpKMJk2apFi3cuVK45lnnjECAgIMV1dXIyAgwOjQoYPx119/3XW7SZeYT/pxcnIyfH19jQ4dOpg1Sm7FihVGnTp1DA8PDyNv3rxG69atjT///DNF3IgRI4wiRYoYTk5OVpdfP3z4sFG/fn3Dw8PDkGR1Cftdu3YZwcHBRu7cuQ1PT0+jUaNGxqZNm6y2m/Te2759u9XyIUOGGJKMCxcuWC1Pev7Tc+XKFePll182SpYsaXh6ehpubm5G+fLljVGjRpnvt/Tcy3vx7NmzhrOzs/HYY4/ddft3GjRokCHJqF27dop1P//8syHJyJMnjxEfH2+1bvHixUalSpUMd3d3o3jx4saYMWOM2bNnW9XHMAyjQYMGRoMGDczbq1evNiQZCxcutNrewIEDDUnGtGnT0o0zjIy9btKqYZKDBw8akoyyZctaLf/kk08MScbHH3+c4j4Z3edixYoZLVu2TPVxT548abRp08bw9PQ0ChYsaLz99ttGWFiYIclYvXp1qvdJktbr9U5xcXHGsGHDjKCgIMPFxcUIDAw0Bg0aZNy4ccMqLr0803pv3W9dkvYhvdeIYdw+Tnft2tUoWLCg4erqalSsWDHFMTMtDRo0MMqXL5/qujVr1hiSjCFDhpjLfvrpJ6Nu3bqGl5eX4eXlZZQpU8bo1auXceTIETMmOjraeOmllwwfHx9DklGsWDFz3d9//200adLEcHNzM/z8/IwPPvjACA8PT1HTtPJK73PuzlwBILtZDIOZ7gAAtnfixAkFBQVp3Lhx5l+G4Xi6dOmiH3/80ZybCZCkixcvqnDhwho8eLA+/vjj7E4HAADkUMwpBQAAACtz585VQkKCXnnllexOBQAA5GDMKQUAAABJty+E8Oeff2rkyJEKCQm556tkAgAAZARNKQAAAEi6PSn9pk2bVKdOHX322WfZnQ4AAMjhmFMKAAAAAAAAdsecUgAAAAAAALA7mlIAAAAAAACwO+aUsqPExESdOXNGefLkkcViye50AAAAAAAAbM4wDF27dk0BAQFyckr7fCiaUnZ05swZBQYGZncaAAAAAAAAWe706dN65JFH0lxPU8qO8uTJI+l2UfLmzZvN2eRccXFxWr58uZo2bSoXF5fsTgeiJo6ImjgeauJYqIfjoSaOh5o4HmrieKiJ46Em9hEVFaXAwECzD5IWmlJ2lDRkL2/evDSlslBcXJw8PT2VN29eDjIOgpo4HmrieKiJY6EejoeaOB5q4nioieOhJo6HmtjX3aYuYqJzAAAAAAAA2B1NKQAAAAAAANgdTSkAAAAAAADYHXNKAQAAAADggBISEhQXF5fdaeQocXFxypUrl27cuKGEhITsTueB5eLiImdn5/veDk0pAAAAAAAciGEYioiIUGRkZHankuMYhiF/f3+dPn36rpNwI30+Pj7y9/e/r+eRphQAAAAAAA4kqSHl6+srT09Pmic2lJiYqOjoaOXOnVtOTsxodC8Mw1BsbKzOnz8vSSpcuPA9b4umFAAAAAAADiIhIcFsSBUoUCC708lxEhMTdevWLbm7u9OUug8eHh6SpPPnz8vX1/eeh/JRAQAAAAAAHETSHFKenp7ZnAmQvqTX6P3Me0ZTCgAAAAAAB8OQPTg6W7xGaUoBAAAAAADA7mhKAQAAAAAAu7NYLFq0aFG6MV26dFFISEiGt3nixAlZLBbt2bPnvnKDfdCUAgAAAAAA9yWzzSNJOnv2rJo3by4p7WbSlClTNHfuXNsk+f+1atVK/fr1s+k278eaNWtksVgUGRmZ3amYMtIwtAWuvgcAAAAAAOzO39//rjHe3t52yATZhTOlAAAAAACATTVs2FB9+vTRwIEDlT9/fvn7+2vo0KFWMcnPxgkKCpIkVa1aVRaLRQ0bNpSU8gyssLAw1a1bVz4+PipQoIBatWqlv//++75yLV68uEaNGqVXX31VefLkUdGiRTVz5kxzfe3atfXee+9Z3efChQtycXHRunXrJEk3b97Uu+++qyJFisjLy0s1a9bUmjVrzPiTJ0+qdevWypcvn7y8vFS+fHktXbpUJ06cUKNGjSRJ+fLlk8ViUZcuXczn8K233lLfvn2VL18++fn5adasWYqJiVHXrl2VJ08elSxZUn/88YdVbgcOHFDz5s2VO3du+fn56ZVXXtHFixfN9XerTfHixSVJzz77rCwWi3k7K9CUAgAAAADAwd26dSvNn/j4+AzHxsXFZSjWFubNmycvLy9t3bpVY8eO1fDhwxUeHp5q7LZt2yRJK1as0NmzZ/Xzzz+nGhcTE6P+/ftrx44dWrlypZycnPTss88qMTHxvnKdMGGCqlevrt27d+vNN9/UG2+8oSNHjkiSOnbsqO+//16GYZjxCxYsUEBAgOrVqydJ6t27tzZv3qzvv/9e+/btU9u2bdWsWTMdPXpUktSrVy/dvHlT69at0/79+zVmzBjlzp1bgYGB+umnnyRJR44c0dmzZzVlyhSr57BgwYLatm2b3nrrLb3xxhtq27atateurV27dqlp06Z65ZVXFBsbK0mKjIzUU089papVq2rHjh0KCwvTuXPn1K5dO6v9Ta8227dvlyTNmTNHZ8+eNW9nBYbvAQAAAADg4EaPHp3mulKlSumll14yb48fPz5F8ylJsWLFzDNxpNtzNiU1NJIbMmTIvSf7/1WqVMncTqlSpTRt2jStXLlSTz/9dIrYQoUKSZIKFCiQ7rC+559/3ur27NmzVahQIf3555+qUKHCPefaokULvfnmm5Kk9957T5MmTdLq1atVunRptWvXTn379tWGDRvMJtT8+fPVoUMHWSwWnTp1SnPmzNGpU6cUEBAgSXr33XcVFhamOXPmaNSoUTp16pSef/55VaxYUZL06KOPmo+dP39+SZKvr698fHys8qpcubI++ugjSdKgQYP06aefqmDBgurRo4ckafDgwfriiy+0b98+Pfnkk5o2bZqqVq2qUaNGWT1HgYGB+uuvv/TYY49JSr82SbXw8fHJ0BDL+8GZUgAAAAAAwOYqVapkdbtw4cI6f/78fW3z6NGj6tChgx599FHlzZvXHFp26tSp+9pu8lwtFov8/f3NXAsVKqSmTZsqNDRUknT8+HFt3rxZHTt2lCTt379fCQkJeuyxx5Q7d27zZ+3atebQwj59+uiTTz5RnTp1NGTIEO3bty/TeTk7O6tAgQJmY0uS/Pz8JMnMde/evVq9erVVHmXKlJEkq2GOWVGbe8GZUgAAAAAAOLhBgwaluc7Jyfp8k3fffTfNWIvFYnX77bffvr/E0uHi4pLise93mF3r1q1VrFgxzZo1SwEBAUpMTFSFChXue8jh3XLt2LGj+vTpo88++0zz589XxYoVzeZQdHS0nJ2dtXPnTjk7O1ttJ3fu3JKk7t27Kzg4WL///ruWL1+u0aNHa8KECXrrrbcynVfyZUn1TMo1OjparVu31pgxY1Jsq3DhwhneX3uhKQUAAAAAgINzdXXN9tislJRHQkJCmjGXLl3SkSNHNGvWLHMY3YYNG+yS3zPPPKOePXsqLCxM8+fPV6dOncx1VatWVUJCgs6fP2/mlZrAwEC9/vrrev311zVo0CDNmjVLb731Vob2PaMef/xx/fTTTypevLhy5br3lo+Li4tN8rkbhu8BAAAAAIBs5evrKw8PD3Ni7qtXr6aIyZcvnwoUKKCZM2fq2LFjWrVqlfr372+X/Ly8vBQSEqKPP/5Yhw4dUocOHcx1jz32mDp27KhOnTrp559/1vHjx7Vt2zaNHj1av//+uySpb9++WrZsmY4fP65du3Zp9erVKlu2rKTb83xZLBb99ttvunDhgqKjo+85z169euny5cvq0KGDtm/frr///lvLli1T165dM9VkKl68uFauXKmIiAhduXLlnvO5G5pSAAAAAAAgW+XKlUtTp07Vl19+qYCAAD3zzDMpYpycnPT9999r586dqlChgvr166dx48bZLceOHTtq7969qlevnooWLWq1bs6cOerUqZPeeecdlS5dWiEhIdq+fbsZl5CQoF69eqls2bJq1qyZHnvsMX3++eeSpCJFimjYsGF6//335efnp969e99zjgEBAdq4caMSEhLUtGlTVaxYUX379pWPj0+KYZ7pmTBhgsLDwxUYGKiqVavecz53YzGSX9MQWSoqKkre3t66evWq8ubNm93p5FhxcXFaunSpWrRokWKcLLIHNXE81MTxUBPHQj0cDzVxPNTE8VATx3MvNblx44aOHz+uoKAgubu7Z3GGD5/ExERFRUUpb968mWrSIKX0XqsZ7X8wpxQyzTLMcvegbOTh5KHvKn0n70+9dT3xenankypjCL1gAAAAAMDDjbYgAAAAAAAA7I6mFAAAAAAAAOyO4XtADsCQyvvHkEoAAAAAsC/OlAIAAAAAAIDdcaYUAGQBzl67f5y9BgAAAORsnCkFAAAAAAAAu+NMKQDAQ4Gz1+4fZ68BAADAljhTCgAAAAAAAHZHUwoAAAAAAAB2x/A9AACQLRx5SOWDMJxSYkglADxM7P25mZnPGIsl/dyGDBmioUOH3mdG1rp06aJ58+ZZLQsODlZYWJhNHwdZi6YUAAAAAAC4Z2fPnjX/v2DBAg0ePFhHjhwxl+XOnTtLHrdZs2aaM2eOedvNzS1LHgdZh+F7AAAAAADgnvn7+5s/3t7eslgs5m1fX19NnDhRjzzyiNzc3FSlShWrs5lOnDghi8Wi77//XrVr15a7u7sqVKigtWvX3vVx3dzcrB47X758WbmbyAI0pQAAAAAAQJaYMmWKJkyYoPHjx2vfvn0KDg5WmzZtdPToUau4AQMG6J133tHu3btVq1YttW7dWpcuXUp322vWrJGvr69Kly6tN954467xcDw0pQAAAAAAQJYYP3683nvvPbVv316lS5fWmDFjVKVKFU2ePNkqrnfv3nr++edVtmxZffHFF/L29tb//d//pbndZs2a6euvv9bKlSs1ZswYrV27Vs2bN1dCQkIW7xFsiTmlAAAAAACAzUVFRenMmTOqU6eO1fI6depo7969Vstq1apl/j9XrlyqXr26Dh06lOa227dvb/6/YsWKqlSpkkqUKKE1a9aocePGNtoDZDXOlAIAAAAAAA+0Rx99VAULFtSxY8eyOxVkAk0pAAAAAABgc3nz5lVAQIA2btxotXzjxo0qV66c1bItW7aY/4+Pj9fOnTtVtmzZDD/Wv//+q0uXLqlw4cL3lzTsiuF7AAAAAAAgSwwYMEBDhgxRiRIlVKVKFc2ZM0d79uxRaGioVdz06dNVqlQplS1bVpMmTdKVK1f06quvprrN6OhoDRs2TM8//7z8/f31999/a+DAgSpZsqSCg4PtsVuwEZpSAAAAAAAgS/Tp00dXr17VO++8o/Pnz6tcuXJavHixSpUqZRX36aef6tNPP9WePXtUsmRJLV68WAULFkx1m87Oztq3b5/mzZunyMhIBQQEqGnTphoxYoTc3NzssVuwEZpSAAAAAAA4OGOIkd0pZEiXLl3UpUsX87aTk5OGDBmiIUOGpHu/smXLauvWrRl6DA8PDy1btux+0oSDYE4pAAAAAAAA2B1NKQAAAAAAANgdw/cAAAAAAEC2KF68uAzjwRiaCNvjTCkAAAAAAADYXbY2pdatW6fWrVsrICBAFotFixYtMtfFxcXpvffeU8WKFeXl5aWAgAB16tRJZ86csdrG5cuX1bFjR+XNm1c+Pj7q1q2boqOjrWL27dunevXqyd3dXYGBgRo7dmyKXBYuXKgyZcrI3d1dFStW1NKlS63WG4ahwYMHq3DhwvLw8FCTJk109OhR2z0ZAAAAAAAAD5FsbUrFxMSocuXKmj59eop1sbGx2rVrlz7++GPt2rVLP//8s44cOaI2bdpYxXXs2FEHDx5UeHi4fvvtN61bt049e/Y010dFRalp06YqVqyYdu7cqXHjxmno0KGaOXOmGbNp0yZ16NBB3bp10+7duxUSEqKQkBAdOHDAjBk7dqymTp2qGTNmaOvWrfLy8lJwcLBu3LiRBc8MAAAAAABAzpatc0o1b95czZs3T3Wdt7e3wsPDrZZNmzZNTzzxhE6dOqWiRYvq0KFDCgsL0/bt21W9enVJ0meffaYWLVpo/PjxCggIUGhoqG7duqXZs2fL1dVV5cuX1549ezRx4kSzeTVlyhQ1a9ZMAwYMkCSNGDFC4eHhmjZtmmbMmCHDMDR58mR99NFHeuaZZyRJX3/9tfz8/LRo0SK1b98+q54iAAAAAACAHOmBmuj86tWrslgs8vHxkSRt3rxZPj4+ZkNKkpo0aSInJydt3bpVzz77rDZv3qz69evL1dXVjAkODtaYMWN05coV5cuXT5s3b1b//v2tHis4ONgcTnj8+HFFRESoSZMm5npvb2/VrFlTmzdvTrMpdfPmTd28edO8HRUVJen20MS4uLj7ei6yk4eTR3ankK6k/Bw5T1vX35H3VaImjoiaOB5q4lgehHpItq+JI0va14dpnx0dNXE81MTx3EtN4uLiZBiGEhMTlZiYmFWpPbSSJlVPeo5x7xITE2UYhuLi4uTs7Gy1LqOv+QemKXXjxg2999576tChg/LmzStJioiIkK+vr1Vcrly5lD9/fkVERJgxQUFBVjF+fn7munz58ikiIsJcljwm+TaS3y+1mNSMHj1aw4YNS7F8+fLl8vT0vOs+O6rvKn2X3SlkyOwKs7M7hTTdOWfZ/aIm94+aOB5q4ngexpo4cj0k29fkQXDnmfTIftTE8VATx5OZmuTKlUv+/v6Kjo7WrVu3sjCrh9u1a9eyO4UH3q1bt3T9+nWtW7dO8fHxVutiY2MztI0HoikVFxendu3ayTAMffHFF9mdToYNGjTI6gysqKgoBQYGqmnTpmZj7UHk/al3dqeQLg8nD82uMFuvHnhV1xOvZ3c6qbr6/lWbbo+a3D9q4nioieN5mGryINRDsn1NHFlcXJzCw8P19NNPy8XFJbvTgaiJI6ImjudeanLjxg2dPn1auXPnlru7exZn+PAxDEPXrl1Tnjx5ZLFYsjudB9qNGzfk4eGh+vXrp3itJo0UuxuHb0olNaROnjypVatWWTVz/P39df78eav4+Ph4Xb58Wf7+/mbMuXPnrGKSbt8tJvn6pGWFCxe2iqlSpUqaubu5ucnNzS3FchcXlwf6Q8KRv5wndz3xusPmauv6O+p+3omaOB5q4nioiWNx5HpItq/Jg+BB/x6VE1ETx0NNHE9mapKQkCCLxSInJyc5OSW7Ntlrr2VRdmn48stMhXfp0kXz5s0zb+fPn181atTQ2LFjValSpUxtJzIy0pxOR5JOnDihoKAg7d69O93fwTMiache0nOcUak1sL777ruHeo5pJycnWSyWVF/fGX29Z+vV9+4mqSF19OhRrVixQgUKFLBaX6tWLUVGRmrnzp3mslWrVikxMVE1a9Y0Y9atW2c1njE8PFylS5dWvnz5zJiVK1dabTs8PFy1atWSJAUFBcnf398qJioqSlu3bjVjAAAAAAB4mDVr1kxnz57V2bNntXLlSuXKlUutWrXK7rRsZs6cOeb+nT17ViEhIdmd0gMvW5tS0dHR2rNnj/bs2SPp9oTie/bs0alTpxQXF6cXXnhBO3bsUGhoqBISEhQREaGIiAhzXG3ZsmXVrFkz9ejRQ9u2bdPGjRvVu3dvtW/fXgEBAZKkl156Sa6ururWrZsOHjyoBQsWaMqUKVbD6t5++22FhYVpwoQJOnz4sIYOHaodO3aod+/ekm53RPv27atPPvlEixcv1v79+9WpUycFBATwIgQAAAAAQLdHC/n7+8vf319VqlTR+++/r9OnT+vChQtmzP79+/XUU0/Jw8NDBQoUUM+ePRUdHS1JGjp0qObNm6dff/1VFotFFotFa9asMeeJrlq1qiwWixo2bCjp9llPw4cP1yOPPCI3NzdVqVJFYWFh5mOdOHFCFotFP/zwg+rVqycPDw/VrFlTx44d0/bt21W9enXlzp1bzZs3t8oxLT4+Pub++fv7M7zSBrK1KbVjxw5VrVpVVatWlST1799fVatW1eDBg/Xff/9p8eLF+vfff1WlShUVLlzY/Nm0aZO5jdDQUJUpU0aNGzdWixYtVLduXc2cOdNc7+3treXLl+v48eOqVq2a3nnnHQ0ePFg9e/Y0Y2rXrq358+dr5syZqly5sn788UctWrRIFSpUMGMGDhyot956Sz179lSNGjUUHR2tsLAwXoQAAAAAANwhOjpa3377rUqWLGmOeoqJiVFwcLDy5cun7du3a+HChVqxYoV5Qsi7776rdu3aWZ1xVbt2bW3btk2StGLFCp09e1Y///yzJGnKlCmaMGGCxo8fr3379ik4OFht2rTR0aNHrXIZMmSIPvroI+3atUu5cuVSjx499P7772vKlClav369jh07psGDB991n3r16qWCBQvqiSee0OzZs80r+eHeZeucUg0bNky3iBkpcP78+TV//vx0YypVqqT169enG9O2bVu1bds2zfUWi0XDhw/X8OHD75oTAAAAAAAPm99++025c+eWdLsBVbhwYf3222/m3E3z58/XjRs39PXXX8vLy0uSNG3aNLVu3VpjxoyRn5+fPDw8dPPmTXNuZ0kqVKiQJKlAgQJWy8ePH6/33nvPnNdpzJgxWr16tSZPnqzp06ebce+++66Cg4MlSW+99ZY6duyo8PBw1alTR5LUrVs3zZ07N919Gz58uJ566il5enpq+fLlevPNNxUdHa0+ffrcz1P20HP4ic4BAAAAAIDja9Sokb744gtJ0pUrV/T555+refPm2rZtm4oVK6ZDhw6pcuXKZkNKkurUqaPExEQdOXJEfn5+GX6sqKgonTlzxmwsJd/e3r17rZYln2g96TEqVqxotezOi6jd6eOPPzb/X7VqVcXExGjcuHE0pe6TQ090DgAAAAAAHgxeXl4qWbKkSpYsqRo1auirr75STEyMZs2ala15Jb8SXNJV9O5clnRVvoyqWbOm/v33X928edM2ST6kaEoBAAAAAACbs1gscnJy0vXr1yXdvljZ3r17FRMTY8Zs3LhRTk5OKl26tCTJ1dVVCQkJVttxdXWVJKvlefPmVUBAgDZu3GgVu3HjRpUrVy5L9ie5PXv2KF++fHJzc8vyx8rJGL4HAAAAAADu282bNxURESHp9vC9adOmKTo6Wq1bt5YkdezYUUOGDFHnzp01dOhQXbhwQW+99ZZeeeUVc1hd8eLFtWzZMh05ckQFChSQt7e3fH195eHhobCwMD3yyCNyd3eXt7e3BgwYoCFDhqhEiRKqUqWK5syZoz179ig0NNSm+7VkyRKdO3dOTz75pNzd3RUeHq5Ro0bp3XfftenjPIxoSgEAAAAAgPsWFhamwoULS5Ly5MmjMmXKaOHChWrYsKEkydPTU8uWLdPbb7+tGjVqyNPTU88//7wmTpxobqNHjx5as2aNqlevrujoaK1evVoNGzbU1KlTNXz4cA0ePFj16tXTmjVr1KdPH129elXvvPOOzp8/r3Llymnx4sUqVaqUTffLxcVF06dPV79+/WQYhkqWLKmJEyeqR48eNn2chxFNKQAAAAAAHN2XX2Z3BumaO3fuXa9gJ92eYHzVqlVpri9UqJCWL1+eYnn37t3VvXt3q2VOTk4aMmSIhgwZkuq2ihcvLsMwrJY1bNhQV65cUd68ec1lXbp0UZcuXdLMqVmzZmrWrFma63HvmFMKAAAAAAAAdkdTCgAAAAAAAHZHUwoAAAAAAAB2R1MKAAAAAAAAdkdTCgAAAAAAB3PnBN2Ao7HFa5SmFAAAAAAADsLFxUWSFBsbm82ZAOlLeo0mvWbvRS5bJQMAAAAAAO6Ps7OzfHx8dP78eUmSp6enLBZLNmeVcyQmJurWrVu6ceOGnJw4T+deGIah2NhYnT9/Xj4+PnJ2dr7nbdGUAgAAAADAgfj7+0uS2ZiC7RiGoevXr8vDw4Nm333y8fExX6v3iqYUAAAAAAAOxGKxqHDhwvL19VVcXFx2p5OjxMXFad26dapfv/59DTt72Lm4uNzXGVJJaEoBAAAAAOCAnJ2dbfKLP/7H2dlZ8fHxcnd3pynlABhACQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7oykFAAAAAAAAu8vWptS6devUunVrBQQEyGKxaNGiRVbrDcPQ4MGDVbhwYXl4eKhJkyY6evSoVczly5fVsWNH5c2bVz4+PurWrZuio6OtYvbt26d69erJ3d1dgYGBGjt2bIpcFi5cqDJlysjd3V0VK1bU0qVLM50LAAAAAAAAMiZbm1IxMTGqXLmypk+fnur6sWPHaurUqZoxY4a2bt0qLy8vBQcH68aNG2ZMx44ddfDgQYWHh+u3337TunXr1LNnT3N9VFSUmjZtqmLFimnnzp0aN26chg4dqpkzZ5oxmzZtUocOHdStWzft3r1bISEhCgkJ0YEDBzKVCwAAAAAAADImV3Y+ePPmzdW8efNU1xmGocmTJ+ujjz7SM888I0n6+uuv5efnp0WLFql9+/Y6dOiQwsLCtH37dlWvXl2S9Nlnn6lFixYaP368AgICFBoaqlu3bmn27NlydXVV+fLltWfPHk2cONFsXk2ZMkXNmjXTgAEDJEkjRoxQeHi4pk2bphkzZmQoFwAAAAAAAGRctjal0nP8+HFFRESoSZMm5jJvb2/VrFlTmzdvVvv27bV582b5+PiYDSlJatKkiZycnLR161Y9++yz2rx5s+rXry9XV1czJjg4WGPGjNGVK1eUL18+bd68Wf3797d6/ODgYHM4YUZyyYxbt27p1q1bKZY7OTkpV65cVnFpsVgscnFxuafYuLg4GYZxz7EuSrZeceb/cymXLLKkmYe9Yl0MFyUkJMjFcFG84tOMdZaznNI5WTAzsfGKlyEjw7FJEhISlJCQkGZsrly55OTkdNdYF7lY5eAkJznLOc3tJihBiUq0W2xqNUkea5FFudI5HCUqUQlKyNJYwzAUFxeXZmzy92dGYpNL/p65kyHD6jVhr9jkNYlTXIa3K1m/NzITm9n3cnrHteTH9Pj4eCUmJmYoNjM52PsYkVQTJTvk2vrYc7/HiNRqkvw4lZiYqPj4+BQx5v44O8vZ2dmMTe/1k93HCBfDxep1lZntSum/NzITe7f3cvKaPCjfI+4lNik+o7H3eoy4W6yLi4uZR1bF3u27QWZiM/o94n5iDcPQrVu30qzH/Rwjsjv2bp/3mYnN7PeIe4mVbr+XExISUq1JTj9GJH8vO9IxIi4uLtWaPCzHiMzE2ut9f2dNHrZjhC1iM3KMSO/+yTlsUyoiIkKS5OfnZ7Xcz8/PXBcRESFfX1+r9bly5VL+/PmtYoKCglJsI2ldvnz5FBERcdfHuVsuqbl586Zu3rxp3o6KipIkTZgwQe7u7iniS5QooRdffNG8PX78+DRfYEWLFtXLL79s3p48ebKuX7+eamzhwoXVtWtX8/b06dN19erVVGMLFixoNfxx5syZunjxolXMh/pQknRVVzXDaYa5vFNiJxVW4VS3G6tYfeb0mXm7Q2IHFVXRVGNv6ZYmOU0yb7+Q+IJKqESqsZI0xmmM+f9nEp9RGaOM9u/fr/7qnyJ2omWi4iy3n9MWiS1UURXT3O5Uy1Rdt9x+Tp9OfFqP6/E0Y7+wfKEoy+36NkxsqJqqmWbs/1n+z6zrunXrtGHDhjRju3TpooCAAEnSli1btGrVqlTjPtSHmm+Zr9OW05KkqkZVNTWaprndhZaF+sfyjySpglFBLY2WacYusizSEcsRSVJpo7RCjJA0Y3+3/K4DltvDXh81HlVbo+3tFYZS1GS5Zbl2W3ZLkgKNQL1kvJTmdldbVmubZZskyd/wV2ejc5qxG7RBG502SpIKGgXVzeiWZuxWbdUapzWSpIsXL+rzzz9PM/bxxx9Xs2bNJN0eejxlypQ0YytWrCgPJw9Jt3+x7W+kfC0mOazD+tXpV/P2e4nvpRn7t/7Wj04/mrf7JfaTq1xTjT2lU/rO6Tvz9luJb8lTnv8LSFaTszqrr52+Nle9nvi6vOWd6nYv6qL+z+n/zNvdErupoAqmGnu/x4jRo0enGuvi4mKe2SpJCxYs0N9//51qrCR98MEHkiQPJ4/bxwiVSTM2W48R/78mRZyL6D/jP0lSncQ6qqu6aW53nmWeIiy3P4eeMJ5QI6NRmrG2OEakVpNnn31WZcuWlSQdOnRIv/zyS5rbbdWqlSpVqiRJOnbsmPl5kppsP0YY0tmzZ833cl4jr94w3khzu7u0S+FO4ZIkD8NDfYw+acbu134tdbo9d+X9HiOS1+RB+R6RxNvbW7169TJvz5kzR2fPnk011sPDQ71795Z0+5eJBQsW6NSpU6nG3usxQpJ+/vlnHT58OM3Yd9991/wFdcmSJdq/f3+asW+//ba8vLwkSWFhYdq1a1easW+++aZ8fHwkSStXrtTWrVvTjO3Ro4cKFSokyXbfI6TbU2IUK1ZMkrRjxw4tX748zdh27dqpZMmSiouL0+XLlzV+/Pg0Y+/nGPHDDz+kGdu0aVPzD9MnT55UaGhomrFPPfWUnnzySUnSmTNnNHfu3DRj69atq/r160uSLly4oFmzZqUZW7NmTTVu3FiSFBkZadPvEa1bt5Z0+5e69J7fMmXK6LnnnjNvJ8Wm9trM6ceIfv36mbe//fZbhztG3FmTh+EYId2e3/m3335LMzY7jxFJNXmYjhFpfb+WbH+MyOhURw7blMoJRo8erWHDhmU4/sKFC1YTrKfXUb506ZJVbHpdyMjISKvY2NjYNGOjo6OtYu+cND65gi4F9V35//3Se+TIkTQ/rPI459F3Ff8Xe/ToUcXExKQa6+7kru8q/S/2n3/+MRt6qUkee/z48TQ/BCVpToU5Zrf65MmTunLlSpqxM8vPNDvF//77b5ofmJI0tcxUubm5SZL+++8/XbhwIc3YsY+NNZ/jtD5Yk2zatEmenrcbCefPn0839uNHP1aePHkk3X4t/ffff2nGDiw+UN7et5sOly5d0unTp9OM7Vusr/khGBkZqRMnTqQZ+/ojr6tAgQKSpKtXr+r48eNpxnYN6KqBhQZKkq5du5bul4GOhTuqn+/tLxqxsbH666+/0ox93u959S58+xeX69ev68iRI2nGtirUSq8VeU2StHr16jTjJOnUqVNm3dL764l0+/WS9LpMSEhI95eWmt411T7of2db7tmzJ83Yqnmr6vlHnzdv79u3L82/qpX1KqvvSv3vvbF///40jymPejyq70r/L/bgwYNpfgA94v6Ivivzv9jDhw+n+YGTVceIhIQEq+NUeu83SWbsd5W+eyCOESNKjpCHx+1GyNmzZ3Xu3Lk0Y0eWGml1jDhz5kyasVl1jNi9e7f5Xo+MjEwzTpL27t2rf//9V5LSrYPkGMcISZpdYbak239oOnToUJpxTQs21auPvCrp9jEi+byUd6qfr75eKfaKJNseIx607xGxsbFWsem9fm7duqXw8NtNv/DwcF26dCnN2Hs9Rkh3/1xetmyZeYxIei2nZeXKlVbHiPSsXr3a6hiRnnXr1lkdI9KTme8RW7Zs0cGDByXd/Tnbvn17uu+z5LLqGHHw4EFzn65du5Zu7OHDh3X58mVJ6b9+pdufP0mv27Q+s5L8888/5h+gk/8hOjWZ/R6RFJve+1i6/Rq48wJNacnpx4jksRwjHOcYkV4tJI4RSXLyMeJuLEZ65zXakcVi0S+//KKQkBBJtwtYokQJ7d69W1WqVDHjGjRooCpVqmjKlCmaPXu23nnnHatfGuLj4+Xu7q6FCxfq2WefVadOnRQVFWV1Zb/Vq1frqaee0uXLl5UvXz4VLVpU/fv3V9++fc2YIUOGaNGiRdq7d2+GcklNamdKBQYG6syZM8qbN2+K+AfllNqACbe76YYMxVv+94bJZdxlWIwl7p5inY27DKG5I9bTyVNflPtCb/z5hm4kWv+yHKc4JT3sXbd7j7FORvrDYuIUp6uDbh9EbXXqa8CEgNtDcyxGhnK411iLkf7wlQQlKNGSmCLW3ck9RU3Sis3Mdu8WKyP9YTHJYyPfi7TpabIFxhfIUA6JSlSCJdkwHsM2sXe+P++MTV6T64nXM/xezsz7/n6PEWffSfuL1L2cdu/9qXeWve9tcYxIqkmPP3vounE93dgk9njfJ489807Kptf9nHbvO8Y3zdjsPka4O7lrRvkZ6v5nd11PvJ6593JWxSrlezl5TR6U7xH3EpsUHx4erqefflqSHGZojq1jH6ShOXFxcVq+fLkaNmxoVcu0tusIQ/Jy+tCcmJgYrVq1Sk899VSKmuT0Y4QjD99LrSYPwzEis7H2HL6XvCYP0zHCnsP3oqKiFBAQoKtXr6ba/0jisGdKBQUFyd/fXytXrjQbQVFRUdq6daveeOP26fO1atVSZGSkdu7cqWrVqkmSVq1apcTERNWsWdOM+fDDDxUXF2c+aeHh4SpdurTy5ctnxqxcudKqKRUeHq5atWplOJfUuLm5mR3t5Ly8vMxTNdOT1od7dsdGGcnOWspMS9NOsQlGgpydnXXNuGb+YpcdeaQn6Xm1Vd3MmjjAvqUWG2fEpV4TO+RwXen/BSMp1tXV1epLx93cLfZ64v8eN6M52DM2RU0c8LWTkeOklPH3UfKaZCYPe8Um1eS6cT3judo4h7vFZqQmqX3upcXq8ySDOdg6Nq33UZwRJycnJ11P/F89HPG9nF5NHPV7xL3GJn3pdnFxeSDyfVhiLRaLvLy8MnyfzBwjHCHWlt8N7BHr5eUlZ2fnDNXEEV4/D0NsXFzcXWviSPlmZ6xkn/f93WqSk48R9qzz3c7iSpL2n3XtIDo6Wnv27DFPRT9+/Lj27NmjU6dOyWKxqG/fvvrkk0+0ePFi7d+/X506dVJAQIB5NlXZsmXVrFkz9ejRQ9u2bdPGjRvVu3dvtW/f3hwb+9JLL8nV1VXdunXTwYMHtWDBAk2ZMsVqYvO3335bYWFhmjBhgg4fPqyhQ4dqx44d5twFGckFAAAAAAAAGZetZ0rt2LFDjRr9b1LWpEZR586dNXfuXA0cOFAxMTHq2bOnIiMjVbduXYWFhVlNEh4aGqrevXurcePGcnJy0vPPP6+pU6ea6729vbV8+XL16tVL1apVU8GCBTV48GCrCfZq166t+fPn66OPPtIHH3ygUqVKadGiRapQoYIZk5FcAAAAAAAAkDHZ2pRq2LDhXecOGD58uIYPH55mTP78+TV//vx0H6dSpUpav359ujFt27ZV27Zt7ysXAAAAAAAAZEy2Dt8DAAAAAADAw4mmFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsLldmgiMjI/XLL79o/fr1OnnypGJjY1WoUCFVrVpVwcHBql27dlblCQAAAAAAHgSvvZbdGaQtVy6paVOpb18pPj67s0nbl19mdwZ2kaEzpc6cOaPu3burcOHC+uSTT3T9+nVVqVJFjRs31iOPPKLVq1fr6aefVrly5bRgwYKszhkAAAAAAAAPuAydKVW1alV17txZO3fuVLly5VKNuX79uhYtWqTJkyfr9OnTevfdd22aKAAAAAAAKXBWzv17SM7KgePJUFPqzz//VIECBdKN8fDwUIcOHdShQwddunTJJskBAAAAAAAgZ8rQ8L27NaTuNz4tCQkJ+vjjjxUUFCQPDw+VKFFCI0aMkGEYZoxhGBo8eLAKFy4sDw8PNWnSREePHrXazuXLl9WxY0flzZtXPj4+6tatm6Kjo61i9u3bp3r16snd3V2BgYEaO3ZsinwWLlyoMmXKyN3dXRUrVtTSpUttsp8AAAAAAAAPm/u++t6hQ4c0Z84c7dmzxwbpWBszZoy++OILTZs2TYcOHdKYMWM0duxYffbZZ2bM2LFjNXXqVM2YMUNbt26Vl5eXgoODdePGDTOmY8eOOnjwoMLDw/Xbb79p3bp16tmzp7k+KipKTZs2VbFixbRz506NGzdOQ4cO1cyZM82YTZs2qUOHDurWrZt2796tkJAQhYSE6MCBAzbfbwAAAAAAgJwuU1ffGz58uDw8PDRgwABJ0urVq9WsWTPlyZNHV69e1dy5c9WxY0ebJbdp0yY988wzatmypSSpePHi+u6777Rt2zZJt8+Smjx5sj766CM988wzkqSvv/5afn5+WrRokdq3b69Dhw4pLCxM27dvV/Xq1SVJn332mVq0aKHx48crICBAoaGhunXrlmbPni1XV1eVL19ee/bs0cSJE83m1ZQpU9SsWTNz30eMGKHw8HBNmzZNM2bMsNk+AwAAAAAAPAwydabUjz/+aDXR+ciRI9WnTx9dvHhR06ZN06hRo2yaXO3atbVy5Ur99ddfkqS9e/dqw4YNat68uSTp+PHjioiIUJMmTcz7eHt7q2bNmtq8ebMkafPmzfLx8TEbUpLUpEkTOTk5aevWrWZM/fr15erqasYEBwfryJEjunLlihmT/HGSYpIeBwAAAAAAABmXoTOlvv76axmGoRMnTmjPnj26dOmSDMPQxo0bVa9ePX399ddKTEzUP//8o6+//lqS1KlTp/tO7v3331dUVJTKlCkjZ2dnJSQkaOTIkebZWBEREZIkPz8/q/v5+fmZ6yIiIuTr62u1PleuXMqfP79VTFBQUIptJK3Lly+fIiIi0n2c1Ny8eVM3b940b0dFRUmS4uLiFBcXl7EnwQF5OHlkdwrpSsrPkfO0df0deV8lauKIqInjoSaO5UGoh2T7mjiypH19mPbZ0VETx/PQ1iRXpgYA2VWcs7PVvw7L1q8ZanL/HvD3cUaPQxl6pRQrVkyS5OrqKj8/PxUrVkx79uxR3rx51ahRIxmGoZs3b8pisah48eJWE5Hfjx9++EGhoaGaP3++OaSub9++CggIUOfOnW3yGFlp9OjRGjZsWIrly5cvl6enZzZkZBvfVfouu1PIkNkVZmd3Cmmy9ST51OT+URPHQ00cz8NYE0euh2T7mjwIwsPDszsF3IGaOJ6HriZNm2Z3BncV3rhxdqeQPlt/nlCT+/eAf8bHxsZmKC5DTakGDRpIkh5//HH99ttveu+99xQWFqYWLVqofv36kqT9+/crMDDQvG0LAwYM0Pvvv6/27dtLkipWrKiTJ09q9OjR6ty5s/z9/SVJ586dU+HChc37nTt3TlWqVJEk+fv76/z581bbjY+P1+XLl837+/v769y5c1YxSbfvFpO0PjWDBg1S//79zdtRUVEKDAxU06ZNlTdv3gw/D47G+1Pv7E4hXR5OHppdYbZePfCqridez+50UnX1/as23R41uX/UxPFQE8fzMNXkQaiHZPuaOLK4uDiFh4fr6aeflouLS3anAz3ENenbN7szSFOcs7PCGzfW0ytXyiUhIbvTSdvkybbdHjW5f9TE8di6JnaWNFLsbjJ1Tt24ceP0zDPPqE6dOipTpozV1enmzp2rZs2aZS7Lu4iNjZWTk/W0V87OzkpMTJQkBQUFyd/fXytXrjSbUFFRUdq6daveeOMNSVKtWrUUGRmpnTt3qlq1apKkVatWKTExUTVr1jRjPvzwQ8XFxZkfqOHh4SpdurTy5ctnxqxcuVJ9k725wsPDVatWrTTzd3Nzk5ubW4rlLi4uD/QHtyN/OU/ueuJ1h83V1vV31P28EzVxPNTE8VATx+LI9ZBsX5MHwYP+PSoneuhqEh+f3RnclUtCglwcOU9bv14ceV//P2rieB66mthZRj8XMtWUqly5sk6cOKFLly6pQIECVuveffddm5/907p1a40cOVJFixZV+fLltXv3bk2cOFGvvvqqJMlisahv37765JNPVKpUKQUFBenjjz9WQECAQkJCJElly5ZVs2bN1KNHD82YMUNxcXHq3bu32rdvr4CAAEnSSy+9pGHDhqlbt2567733dODAAU2ZMkWTJk0yc3n77bfVoEEDTZgwQS1bttT333+vHTt2WDXmAAAAAAAAkDH3NPvYnQ0pSVbD52zls88+08cff6w333xT58+fV0BAgF577TUNHjzYjBk4cKBiYmLUs2dPRUZGqm7dugoLC5O7u7sZExoaqt69e6tx48ZycnLS888/r6lTp5rrvb29tXz5cvXq1UvVqlVTwYIFNXjwYPXs2dOMqV27tubPn6+PPvpIH3zwgUqVKqVFixapQoUKNt9vAAAAAACAnC5DTanvv//enNfpbk6fPq1Tp06pTp0695WYJOXJk0eTJ0/W5HTGUlosFg0fPlzDhw9PMyZ//vyaP39+uo9VqVIlrV+/Pt2Ytm3bqm3btunGAAAAAAAA4O6c7h4iffHFFypbtqzGjh2rQ4cOpVh/9epVLV26VC+99JIef/xxXbp0yeaJAgAAAAAAIOfI0JlSa9eu1eLFi/XZZ59p0KBB8vLykp+fn9zd3XXlyhVFRESoYMGC6tKliw4cOCA/P7+szhsAAAAAAAAPsAzPKdWmTRu1adNGFy9e1IYNG3Ty5Eldv35dBQsWVNWqVVW1atUUV8oDAAAAAAAAUpPpic4LFixoXtkOAAAAAAAAuBec2gQAAAAAAAC7oykFAAAAAAAAu6MpBQAAAAAAALujKQUAAAAAAAC7u+em1K1bt3TkyBHFx8fbMh8AAAAAAAA8BDLdlIqNjVW3bt3k6emp8uXL69SpU5Kkt956S59++qnNEwQAAAAAAEDOk+mm1KBBg7R3716tWbNG7u7u5vImTZpowYIFNk0OAAAAAAAAOVOuzN5h0aJFWrBggZ588klZLBZzefny5fX333/bNDkAAADgofbaa9mdQdpy5ZKaNpX69pUceUqPL7/M7gwAAGnI9JlSFy5ckK+vb4rlMTExVk0qAAAAAAAAIC2ZbkpVr15dv//+u3k7qRH11VdfqVatWrbLDAAAAAAAADlWpofvjRo1Ss2bN9eff/6p+Ph4TZkyRX/++ac2bdqktWvXZkWOAAAAAAAAyGEyfaZU3bp1tWfPHsXHx6tixYpavny5fH19tXnzZlWrVi0rcgQAAAAAAEAOk+kzpSSpRIkSmjVrlq1zAQAAAAAAwEMi002pU6dOpbu+aNGi95wMAAAAAAAAHg6ZbkoVL1483avsJSQk3FdCAAAAAAAAyPky3ZTavXu31e24uDjt3r1bEydO1MiRI22WGAAAAAAAAHKuTDelKleunGJZ9erVFRAQoHHjxum5556zSWIAAAAAAADIuTJ99b20lC5dWtu3b7fV5gAAAAAAAJCDZfpMqaioKKvbhmHo7NmzGjp0qEqVKmWzxAAAAAAAAJBzZbop5ePjk2Kic8MwFBgYqO+//95miQEAAAAAACDnynRTavXq1Va3nZycVKhQIZUsWVK5cmV6cwAAAHAUr72W3RmkLVcuqWlTqW9fKT4+u7NJ25dfZncGAAA8MDLdRWrQoEFW5AEAAAAAAICHSIaaUosXL87wBtu0aXPPyQAAAAAAAODhkKGmVEhISIY2ZrFYlJCQcD/5AAAAAAAA4CGQoaZUYmJiVucBAAAAAACAh4hTdicAAAAAAACAh889XS4vJiZGa9eu1alTp3Tr1i2rdX369LFJYgAAAAAAAMi5Mt2U2r17t1q0aKHY2FjFxMQof/78unjxojw9PeXr60tTCgAAAAAAAHeV6eF7/fr1U+vWrXXlyhV5eHhoy5YtOnnypKpVq6bx48dnRY4AAAAAAADIYTLdlNqzZ4/eeecdOTk5ydnZWTdv3lRgYKDGjh2rDz74ICtyBAAAAAAAQA6T6aaUi4uLnJxu383X11enTp2SJHl7e+v06dO2zQ4AAAAAAAA5UqbnlKpataq2b9+uUqVKqUGDBho8eLAuXryob775RhUqVMiKHAEAAAAAAJDDZPhMqYSEBEnSqFGjVLhwYUnSyJEjlS9fPr3xxhu6cOGCZs6cmTVZAgAAAAAAIEfJ8JlSRYoUUZcuXfTqq6+qevXqkm4P3wsLC8uy5AAAAAAAAJAzZfhMqV69eunHH39U2bJlVa9ePc2dO1exsbFZmRsAAAAAAAByqAw3pT7++GMdO3ZMK1eu1KOPPqrevXurcOHC6tGjh7Zu3ZqVOQIAAAAAACCHyfTV9xo2bKh58+YpIiJCEyZM0KFDh1SrVi2VL19eEydOzIocAQAAAAAAkMNkuimVJHfu3Orevbs2bNigJUuWKCIiQgMGDLBlbgAAAAAAAMih7rkpFRsbq7lz56pBgwZq06aNChQooJEjR9oyNwAAAAAAAORQGb76XpJNmzZp9uzZWrhwoeLj4/XCCy9oxIgRql+/flbkBwAAAAAAgBwow02psWPHas6cOfrrr79UvXp1jRs3Th06dFCePHmyMj8AAAAAAADkQBluSo0bN04vv/yyFi5cqAoVKmRlTgAAAAAAAMjhMtyUOnPmjFxcXLIyFwAAAAAAADwkMjzROQ0pAAAAAAAA2Mo9X30PAAAAAAAAuFc0pQAAAAAAAGB3NKUAAAAAAABgdxme6Dy5hIQELVq0SIcOHZIklS9fXm3atJGzs7NNkwMAAAAAAEDOlOmm1LFjx9SyZUv9+++/Kl26tCRp9OjRCgwM1O+//64SJUrYPEkAAAAAAADkLJkevtenTx89+uijOn36tHbt2qVdu3bp1KlTCgoKUp8+fbIiRwAAAAAAAOQwmT5Tau3atdqyZYvy589vLitQoIA+/fRT1alTx6bJAQAAAAAAIGfK9JlSbm5uunbtWorl0dHRcnV1tUlSAAAAAAAAyNky3ZRq1aqVevbsqa1bt8owDBmGoS1btuj1119XmzZtsiJHAAAAAAAA5DCZbkpNnTpVJUqUUK1ateTu7i53d3fVqVNHJUuW1JQpU7IiRwAAAAAAAOQwmZ5TysfHR7/++quOHj2qw4cPS5LKli2rkiVL2jw5AAAAAAAA5EyZbkolKVWqlEqVKmXLXAAAAAAAAPCQyFBTqn///hoxYoS8vLzUv3//dGMnTpxok8QAAAAAAACQc2WoKbV7927FxcWZ/0+LxWKxTVYAAAAAAADI0TLUlFq9enWq/wcAAAAAAADuRaavvgcAAAAAAADcrwydKfXcc89leIM///zzPScDAAAAAACAh0OGmlLe3t5ZnQcAAAAAAAAeIhlqSs2ZMyer8wAAAAAAAMBDJENNqdRcuHBBR44ckSSVLl1ahQoVsllSAAAAAAAAyNkyPdF5TEyMXn31VRUuXFj169dX/fr1FRAQoG7duik2NtbmCf733396+eWXVaBAAXl4eKhixYrasWOHud4wDA0ePFiFCxeWh4eHmjRpoqNHj1pt4/Lly+rYsaPy5s0rHx8fdevWTdHR0VYx+/btU7169eTu7q7AwECNHTs2RS4LFy5UmTJl5O7urooVK2rp0qU2318AAAAAAICHQaabUv3799fatWu1ZMkSRUZGKjIyUr/++qvWrl2rd955x6bJXblyRXXq1JGLi4v++OMP/fnnn5owYYLy5ctnxowdO1ZTp07VjBkztHXrVnl5eSk4OFg3btwwYzp27KiDBw8qPDxcv/32m9atW6eePXua66OiotS0aVMVK1ZMO3fu1Lhx4zR06FDNnDnTjNm0aZM6dOigbt26affu3QoJCVFISIgOHDhg030GAAAAAAB4GGR6+N5PP/2kH3/8UQ0bNjSXtWjRQh4eHmrXrp2++OILmyU3ZswYBQYGWs1pFRQUZP7fMAxNnjxZH330kZ555hlJ0tdffy0/Pz8tWrRI7du316FDhxQWFqbt27erevXqkqTPPvtMLVq00Pjx4xUQEKDQ0FDdunVLs2fPlqurq8qXL689e/Zo4sSJZvNqypQpatasmQYMGCBJGjFihMLDwzVt2jTNmDHDZvsMAAAAAADwMMh0Uyo2NlZ+fn4plvv6+tp8+N7ixYsVHBystm3bau3atSpSpIjefPNN9ejRQ5J0/PhxRUREqEmTJuZ9vL29VbNmTW3evFnt27fX5s2b5ePjYzakJKlJkyZycnLS1q1b9eyzz2rz5s2qX7++XF1dzZjg4GCNGTNGV65cUb58+bR582b179/fKr/g4GAtWrQozfxv3rypmzdvmrejoqIkSXFxcYqLi7uv5yY7eTh5ZHcK6UrKz5HztHX9HXlfJWriiKiJ46EmjuVBqIdk+5oo1z1PN5rl4pydrf51WNTE8VATx0NNHA81cTwPcM9Ayvh3FIthGEZmNty4cWMVKFBAX3/9tdzd3SVJ169fV+fOnXX58mWtWLEi89mmIWn7/fv3V9u2bbV9+3a9/fbbmjFjhjp37qxNmzapTp06OnPmjAoXLmzer127drJYLFqwYIFGjRqlefPmmZOyJ/H19dWwYcP0xhtvqGnTpgoKCtKXX35prv/zzz9Vvnx5/fnnnypbtqxcXV01b948dejQwYz5/PPPNWzYMJ07dy7V/IcOHaphw4alWD5//nx5enre13MDAAAAAADgiGJjY/XSSy/p6tWryps3b5pxmW5fTp48Wc2aNdMjjzyiypUrS5L27t0rd3d3LVu27N4zTkViYqKqV6+uUaNGSZKqVq2qAwcOmE0pRzdo0CCrs6uioqIUGBiopk2bplsUR+f9qXd2p5AuDycPza4wW68eeFXXE69ndzqpuvr+VZtuj5rcP2rieKiJ43mYavIg1EOyfU3Ut69tt2dDcc7OCm/cWE+vXCmXhITsTidtkyfbdnvU5P5RE8dDTRwPNXE8tq6JnSWNFLubTDelKlasqKNHjyo0NFSHDx+WJHXo0EEdO3aUh4dtT3EvXLiwypUrZ7WsbNmy+umnnyRJ/v7+kqRz585ZnSl17tw5ValSxYw5f/681Tbi4+N1+fJl8/7+/v4pznZKun23mKT1qXFzc5Obm1uK5S4uLnJxcUnzfo7Okb+cJ3c98brD5mrr+jvqft6JmjgeauJ4qIljceR6SLavieLjbbu9LOCSkCAXR86TmjgeauJ4qInjoSaO5wHuGUgZ/46SoavvPf7447py5Yokafjw4ZKkHj16aMKECZowYYK6d+9u84aUJNWpUyfFsLu//vpLxYoVk3R70nN/f3+tXLnSXB8VFaWtW7eqVq1akqRatWopMjJSO3fuNGNWrVqlxMRE1axZ04xZt26d1ZjH8PBwlS5d2rzSX61ataweJykm6XEAAAAAAACQcRlqSh06dEgxMTGSpGHDhik6OjpLk0rSr18/bdmyRaNGjdKxY8c0f/58zZw5U7169ZIkWSwW9e3bV5988okWL16s/fv3q1OnTgoICFBISIik22dWNWvWTD169NC2bdu0ceNG9e7dW+3bt1dAQIAk6aWXXpKrq6u6deumgwcPasGCBZoyZYrV0Lu3335bYWFhmjBhgg4fPqyhQ4dqx44d6t27t12eCwAAAAAAgJwkQ8P3qlSpoq5du6pu3boyDEPjx49X7ty5U40dPHiwzZKrUaOGfvnlFw0aNEjDhw9XUFCQJk+erI4dO5oxAwcOVExMjHr27KnIyEjVrVtXYWFh5iTpkhQaGqrevXurcePGcnJy0vPPP6+pU6ea6729vbV8+XL16tVL1apVU8GCBTV48GD17NnTjKldu7bmz5+vjz76SB988IFKlSqlRYsWqUKFCjbbXwAAAAAAgIdFhppSc+fO1ZAhQ/Tbb7/JYrHojz/+UK5ULvFosVhs2pSSpFatWqlVq1ZprrdYLBo+fLg5rDA1+fPn1/z589N9nEqVKmn9+vXpxrRt21Zt27ZNP2EAAAAAAADcVYaaUqVLl9b3338vSXJyctLKlSvl6+ubpYkBAAAAAAAg58rQnFLJrV69Wvnz50+xPD4+XuvWrbNJUgAAAAAAAMjZMt2Ueuqpp3T58uUUy69evapGjRrZJCkAAAAAAADkbJluShmGIYvFkmL5pUuX5OXlZZOkAAAAAAAAkLNlaE4pSXruueck3Z5YvEuXLnJzczPXJSQkaN++fapdu7btMwQAAAAAAECOk+GmlLe3t6TbZ0rlyZNHHh4e5jpXV1c9+eST6tGjh+0zBAAAAAAAQI6T4abUnDlzZBiGJOmzzz5T7ty5sywpAAAAAAAA5GyZmlPKMAyFhobq7NmzWZUPAAAAAAAAHgKZako5OTmpVKlSunTpUlblAwAAAAAAgIdApq++9+mnn2rAgAE6cOBAVuQDAAAAAACAh0CG55RK0qlTJ8XGxqpy5cpydXW1mvBcki5fvmyz5AAAAAAAAJAzZbopNXny5CxIAwAAAAAAAA+TTDelOnfunBV5AAAAAAAA4CGS6aaUJCUkJGjRokU6dOiQJKl8+fJq06aNnJ2dbZocAAAAAAAAcqZMN6WOHTumFi1a6L///lPp0qUlSaNHj1ZgYKB+//13lShRwuZJAgAAAAAAIGfJ9NX3+vTpoxIlSuj06dPatWuXdu3apVOnTikoKEh9+vTJihwBAAAAAACQw2T6TKm1a9dqy5Ytyp8/v7msQIEC+vTTT1WnTh2bJgcAAAAAAICcKdNnSrm5uenatWsplkdHR8vV1dUmSQEAAAAAACBny3RTqlWrVurZs6e2bt0qwzBkGIa2bNmi119/XW3atMmKHAEAAAAAAJDDZLopNXXqVJUoUUK1atWSu7u73N3dVadOHZUsWVJTpkzJihwBAAAAAACQw2R6TikfHx/9+uuvOnbsmA4dOiRJKlu2rEqWLGnz5AAAAAAAAJAzZbgplZiYqHHjxmnx4sW6deuWGjdurCFDhsjDwyMr8wMAAAAAAEAOlOHheyNHjtQHH3yg3Llzq0iRIpoyZYp69eqVlbkBAAAAAAAgh8pwU+rrr7/W559/rmXLlmnRokVasmSJQkNDlZiYmJX5AQAAAAAAIAfKcFPq1KlTatGihXm7SZMmslgsOnPmTJYkBgAAAAAAgJwrw02p+Ph4ubu7Wy1zcXFRXFyczZMCAAAAAABAzpbhic4Nw1CXLl3k5uZmLrtx44Zef/11eXl5mct+/vln22YIAAAAAACAHCfDTanOnTunWPbyyy/bNBkAAAAAAAA8HDLclJozZ05W5gEAAAAAAICHSIbnlAIAAAAAAABshaYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7I6mFAAAAAAAAOyOphQAAAAAAADsjqYUAAAAAAAA7O6Bakp9+umnslgs6tu3r7nsxo0b6tWrlwoUKKDcuXPr+eef17lz56zud+rUKbVs2VKenp7y9fXVgAEDFB8fbxWzZs0aPf7443Jzc1PJkiU1d+7cFI8/ffp0FS9eXO7u7qpZs6a2bduWFbsJAAAAAACQ4z0wTant27fryy+/VKVKlayW9+vXT0uWLNHChQu1du1anTlzRs8995y5PiEhQS1bttStW7e0adMmzZs3T3PnztXgwYPNmOPHj6tly5Zq1KiR9uzZo759+6p79+5atmyZGbNgwQL1799fQ4YM0a5du1S5cmUFBwfr/PnzWb/zAAAAAAAAOcwD0ZSKjo5Wx44dNWvWLOXLl89cfvXqVf3f//2fJk6cqKeeekrVqlXTnDlztGnTJm3ZskWStHz5cv3555/69ttvVaVKFTVv3lwjRozQ9OnTdevWLUnSjBkzFBQUpAkTJqhs2bLq3bu3XnjhBU2aNMl8rIkTJ6pHjx7q2rWrypUrpxkzZsjT01OzZ8+275MBAAAAAACQAzwQTalevXqpZcuWatKkidXynTt3Ki4uzmp5mTJlVLRoUW3evFmStHnzZlWsWFF+fn5mTHBwsKKionTw4EEz5s5tBwcHm9u4deuWdu7caRXj5OSkJk2amDEAAAAAAADIuFzZncDdfP/999q1a5e2b9+eYl1ERIRcXV3l4+NjtdzPz08RERFmTPKGVNL6pHXpxURFRen69eu6cuWKEhISUo05fPhwmrnfvHlTN2/eNG9HRUVJkuLi4hQXF5febjs0DyeP7E4hXUn5OXKetq6/I++rRE0cETVxPNTEsTwI9ZBsXxPlctyvhnHOzlb/Oixq4nioieOhJo6HmjieB7hnIGX8O4rjvlIknT59Wm+//bbCw8Pl7u6e3elk2ujRozVs2LAUy5cvXy5PT89syMg2vqv0XXankCGzKzju0MqlS5fadHvU5P5RE8dDTRzPw1gTR66HZPuaqGlT224vC4Q3bpzdKaSPmjgeauJ4qInjoSaOx9Y1sbPY2NgMxTl0U2rnzp06f/68Hn/8cXNZQkKC1q1bp2nTpmnZsmW6deuWIiMjrc6WOnfunPz9/SVJ/v7+Ka6Sl3R1vuQxd16x79y5c8qbN688PDzk7OwsZ2fnVGOStpGaQYMGqX///ubtqKgoBQYGqmnTpsqbN28mngnH4v2pd3ankC4PJw/NrjBbrx54VdcTr2d3Oqm6+v5Vm26Pmtw/auJ4qInjeZhq8iDUQ7J9TZTsCseOJs7ZWeGNG+vplSvlkpCQ3emkbfJk226Pmtw/auJ4qInjoSaOx9Y1sbOkkWJ349BNqcaNG2v//v1Wy7p27aoyZcrovffeU2BgoFxcXLRy5Uo9//zzkqQjR47o1KlTqlWrliSpVq1aGjlypM6fPy9fX19JUnh4uPLmzaty5cqZMXf+pTE8PNzchqurq6pVq6aVK1cqJCREkpSYmKiVK1eqd+/eaebv5uYmNze3FMtdXFzk4uJyD8+IY3DkL+fJXU+87rC52rr+jrqfd6ImjoeaOB5q4lgcuR6S7Wui+Hjbbi8LuCQkyMWR86QmjoeaOB5q4nioieN5gHsGUsa/ozh0UypPnjyqUKGC1TIvLy8VKFDAXN6tWzf1799f+fPnV968efXWW2+pVq1aevLJJyVJTZs2Vbly5fTKK69o7NixioiI0EcffaRevXqZDaPXX39d06ZN08CBA/Xqq69q1apV+uGHH/T777+bj9u/f3917txZ1atX1xNPPKHJkycrJiZGXbt2tdOzAQAAAAAAkHM4dFMqIyZNmiQnJyc9//zzunnzpoKDg/X555+b652dnfXbb7/pjTfeUK1ateTl5aXOnTtr+PDhZkxQUJB+//139evXT1OmTNEjjzyir776SsHBwWbMiy++qAsXLmjw4MGKiIhQlSpVFBYWlmLycwAAAAAAANzdA9eUWrNmjdVtd3d3TZ8+XdOnT0/zPsWKFbvrRKANGzbU7t27043p3bt3usP1AAAAAAAAkDFO2Z0AAAAAAAAAHj40pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHc0pQAAAAAAAGB3NKUAAAAAAABgdzSlAAAAAAAAYHcO3ZQaPXq0atSooTx58sjX11chISE6cuSIVcyNGzfUq1cvFShQQLlz59bzzz+vc+fOWcWcOnVKLVu2lKenp3x9fTVgwADFx8dbxaxZs0aPP/643NzcVLJkSc2dOzdFPtOnT1fx4sXl7u6umjVratu2bTbfZwAAAAAAgIeBQzel1q5dq169emnLli0KDw9XXFycmjZtqpiYGDOmX79+WrJkiRYuXKi1a9fqzJkzeu6558z1CQkJatmypW7duqVNmzZp3rx5mjt3rgYPHmzGHD9+XC1btlSjRo20Z88e9e3bV927d9eyZcvMmAULFqh///4aMmSIdu3apcqVKys4OFjnz5+3z5MBAAAAAACQg+TK7gTSExYWZnV77ty58vX11c6dO1W/fn1dvXpV//d//6f58+frqaeekiTNmTNHZcuW1ZYtW/Tkk09q+fLl+vPPP7VixQr5+fmpSpUqGjFihN577z0NHTpUrq6umjFjhoKCgjRhwgRJUtmyZbVhwwZNmjRJwcHBkqSJEyeqR48e6tq1qyRpxowZ+v333zV79my9//77dnxWAAAAAAAAHnwOfabUna5evSpJyp8/vyRp586diouLU5MmTcyYMmXKqGjRotq8ebMkafPmzapYsaL8/PzMmODgYEVFRengwYNmTPJtJMUkbePWrVvauXOnVYyTk5OaNGlixgAAAAAAACDjHPpMqeQSExPVt29f1alTRxUqVJAkRUREyNXVVT4+Plaxfn5+ioiIMGOSN6SS1ietSy8mKipK169f15UrV5SQkJBqzOHDh9PM+ebNm7p586Z5OyoqSpIUFxenuLi4jO66w/Fw8sjuFNKVlJ8j52nr+jvyvkrUxBFRE8dDTRzLg1APyfY1US7H/WoY5+xs9a/DoiaOh5o4HmrieKiJ43mAewZSxr+jWAzDMLI4F5t444039Mcff2jDhg165JFHJEnz589X165drRo/kvTEE0+oUaNGGjNmjHr27KmTJ09azQ8VGxsrLy8vLV26VM2bN9djjz2mrl27atCgQWbM0qVL1bJlS8XGxurKlSsqUqSINm3apFq1apkxAwcO1Nq1a7V169ZUcx46dKiGDRuWYvn8+fPl6el5X88H8P/au/fgmu/8j+OvI1eRC9JqFE3clVXakKXbCopI3De64pqI2uqQ1UaZGkpWy7BtSUjQ1gpdw1rTCSo7WhtCjLQM1VqXslWjWwmWuETkQr6/P/rLGSf3kHxzEs/HjBnn+/mc73mfvM833+955Xy/BwAAAAAAe5STk6Nx48bp5s2b8vT0LHOe/caXD5gxY4Z27dqlAwcOWAMpSfLx8VF+fr5u3Lhh82mpy5cvy8fHxzqn+LfkFX0734Nzin9j3+XLl+Xp6amGDRvKwcFBDg4Opc4pWkdp5s6dq+joaOvtW7duqVWrVho0aFC5TbF3Xku9aruEcjVs0FDrf7Nekf+O1N3Cu7VdTqluvnOzWtdHTx4dPbE/9MT+PE49qQv9kKq/J3rzzepdXzUqcHDQnlde0cCUFDndv1/b5ZQtNrZ610dPHh09sT/0xP7QE/tT3T0xWdGZYhWx61DKMAxFRUUpKSlJqampat26tc24v7+/nJyclJKSotDQUEnSDz/8oIsXL1o/0dS7d28tXrxYV65cUbNmzSRJe/bskaenpzp37myd889//tNm3Xv27LGuw9nZWf7+/kpJSdHIkSMl/Xo6YUpKimbMmFFm/S4uLnJxcSmx3MnJSU5OTg/xE7EP9nxw/qC7hXftttbq7r+9Ps/i6In9oSf2h57YF3vuh1T9PdG9e9W7vhrgdP++nOy5Tnpif+iJ/aEn9oee2J86nBlIlT9GsetQavr06dq8ebN27NghDw8P6zWgvLy81LBhQ3l5eWnKlCmKjo5W06ZN5enpqaioKPXu3Vu9evWSJA0aNEidO3fWxIkT9Ze//EWZmZmaP3++pk+fbg2Mpk2bpvj4eM2ZM0eRkZHau3ev/vGPfyg5OdlaS3R0tMLDw9WjRw8FBAQoNjZWd+7csX4bHwAAAAAAACrPrkOpNWvWSJL69u1rszwxMVERERGSpBUrVqhBgwYKDQ1VXl6egoKCtHr1autcBwcH7dq1S2+88YZ69+6tRo0aKTw8XIsWLbLOad26tZKTk/XWW28pLi5OLVu21Lp16xQUFGSdM2bMGF29elULFixQZmamunfvrt27d5e4+DkAAAAAAAAqZtehVGWuwe7q6qqEhAQlJCSUOcfX17fE6XnF9e3bV99++225c2bMmFHu6XoAAAAAAAConAa1XQAAAAAAAAAeP4RSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUpVUUJCgvz8/OTq6qrf/va3Onz4cG2XBAAAAAAAUOcQSlXB1q1bFR0drYULF+rYsWPq1q2bgoKCdOXKldouDQAAAAAAoE4hlKqC5cuXa+rUqZo8ebI6d+6stWvXys3NTevXr6/t0gAAAAAAAOoUx9ouoK7Iz8/X0aNHNXfuXOuyBg0aaMCAAUpPTy/1Pnl5ecrLy7PevnnzpiTp+vXrKigoqNmCa5Brvmttl1Au1wauysnJkWu+q4xCo7bLKdW1a9eqdX305NHRE/tDT+zP49STutAPqfp7osLC6l1fNSq4f185OTm6dv++nOy4TtET+0NP7A89sT/0xP5Ud09Mdvv2bUmSYZR/HGUxKpoBSdKlS5fUokULHTp0SL1797YunzNnjvbv369vvvmmxH1iYmL05z//2cwyAQAAAAAA7MLPP/+sli1bljnOJ6Vq0Ny5cxUdHW29XVhYqOvXr8vb21sWi6UWK6vfbt26pVatWunnn3+Wp6dnbZcD0RN7RE/sDz2xL/TD/tAT+0NP7A89sT/0xP7QE3MYhqHbt2/r6aefLnceoVQlPfHEE3JwcNDly5dtll++fFk+Pj6l3sfFxUUuLi42yxo3blxTJaIYT09PfsnYGXpif+iJ/aEn9oV+2B96Yn/oif2hJ/aHntgfelLzvLy8KpzDhc4rydnZWf7+/kpJSbEuKywsVEpKis3pfAAAAAAAAKgYn5SqgujoaIWHh6tHjx4KCAhQbGys7ty5o8mTJ9d2aQAAAAAAAHUKoVQVjBkzRlevXtWCBQuUmZmp7t27a/fu3XrqqadquzQ8wMXFRQsXLixx6iRqDz2xP/TE/tAT+0I/7A89sT/0xP7QE/tDT+wPPbEvfPseAAAAAAAATMc1pQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpVDnREREyGKxyGKxyNnZWe3atdOiRYt07949paamymKxqEmTJsrNzbW535EjR6z3Q9VkZmYqKipKbdq0kYuLi1q1aqVhw4YpJSXFOufQoUMKCQlRkyZN5Orqqq5du2r58uW6f/++zbr279+v/v37q2nTpnJzc1P79u0VHh6u/Px8m96W9s/Pz8/kZ163REREaOTIkdb/P/iz8/b21uDBg/X999/b3Kdo/Ouvv7ZZnpeXJ29vb1ksFqWmppr0DOqvB3tTnJ+fn2JjY623z549Kzc3N23evNlmXmFhoV588UWNHj26BiutX4q2g6VLl9os3759u3VfULTfKP5v/vz5NuM3btwo9THGjBmjgIAAm991BQUF8vf31/jx42vmidUjVenRgz24dOmSunbtqj59+ujmzZtl9tFisSgzM9PMp1Tn9e3bV2+++WaJ5Rs2bFDjxo0lSTExMdafr6Ojo/z8/PTWW28pOzvbOj8pKUm9evWSl5eXPDw81KVLl1LXi8qpzPFvea//yvQM5SvvGNVisSgmJkYXLlyQxWKRg4ODfvnlF5v7Z2RkyNHRURaLRRcuXLAZ27hxo3r27Ck3Nzd5eHgoMDBQu3btMvHZ1Q8Ps50U39+zHzEfoRTqpMGDBysjI0Pnzp3TrFmzFBMTow8++MA67uHhoaSkJJv7/PWvf9Uzzzxjdql13oULF+Tv76+9e/fqgw8+0IkTJ7R7927169dP06dPl/TrgWdgYKBatmypffv26cyZM5o5c6bef/99hYWFqehLPk+dOqXBgwerR48eOnDggE6cOKFVq1bJ2dlZ9+/fV1xcnDIyMqz/JCkxMdF6+8iRI7X2c6iLiraTjIwMpaSkyNHRUUOHDi0xr1WrVkpMTLRZlpSUJHd3d7NKxQM6dOigpUuXKioqyrodSNJHH32k8+fPa+3atbVYXd3j6uqqZcuWKSsrq9x5P/zwg83vn3feeadS61+9erUuXrxoE6q89957ysjIUHx8/CPV/riobI+K/Pjjj3rppZfk6+urL7/8Ul5eXtax4n3MyMhQs2bNaqr0x1qXLl2UkZGhCxcuaNmyZfrkk080a9YsSVJKSorGjBmj0NBQHT58WEePHtXixYtVUFBQy1XXbRUd/1b0+i+vZ6jYgz/X2NhYeXp62ix7++23rXNbtGihzz77zOb+GzduVIsWLUqs9+2339brr7+uMWPG6Pvvv9fhw4f10ksvacSIEexHHkJVt5Pi+3v2I7XAAOqY8PBwY8SIETbLBg4caPTq1cvYt2+fIcmYP3++MWDAAOt4Tk6O4eXlZbz77rsGL/uqCQ4ONlq0aGFkZ2eXGMvKyjKys7MNb29v4/e//32J8Z07dxqSjL///e+GYRjGihUrDD8/v0o/tiQjKSnpoWt/3Dy4bZS2naSlpRmSjCtXrliXFW0vnp6eRk5OjnX5wIEDrdvLvn37TKi+fiutH0V8fX2NFStW2CwrLCw0+vXrZwwZMsQwDMM4ffq04erqauzYsaOGK61fwsPDjaFDhxqdOnUyZs+ebV2elJRk3RcU7TeysrJKXUdF44ZhGDt27DCcnZ2N7777zjhy5Ijh6OhoJCcnV+dTqbeq2qPvvvvO8PHxMcaNG2cUFBRY51emT6icwMBAY+bMmSWWJyYmGl5eXoZhGMbChQuNbt262YxPnTrV8PHxMQzDMGbOnGn07du3hit9vFTm+Le8139FPUPVPLg9POinn36yHlu1b9/eZqxDhw7WY6uffvrJMAzDSE9PNyQZK1euLLGu6Ohow8nJybh48WJNPIV66VG2E/YjtYdPSqFeaNiwofLz8623J06cqLS0NF28eFGS9Pnnn8vPz08vvPBCbZVYJ12/fl27d+/W9OnT1ahRoxLjjRs31ldffaVr167Z/HWoyLBhw9ShQwdt2bJFkuTj46OMjAwdOHCgxmuHrezsbG3atEnt2rWTt7e3zZi/v7/8/Pz0+eefS5IuXryoAwcOaOLEibVRKvTrKQKJiYlKS0vTp59+qoiICIWFhWn48OG1XVqd4+DgoCVLlmjVqlX673//WyOPMXz4cIWFhWnSpEkKDw9XeHi4QkJCauSx6qPK9ujQoUMKDAxUaGioNm3aJEdHRxOrREUePBbz8fHRyZMn9e9//7uWq6rfih//mn1/lG348OHKysrSwYMHJUkHDx5UVlaWhg0bZjNvy5Ytcnd31+uvv15iHbNmzVJBQYH1+AwPh9e5/SOUQp1mGIb+9a9/6csvv1T//v2ty5s1a6bg4GBt2LBBkrR+/XpFRkbWUpV113/+8x8ZhqFOnTqVOefs2bOSpGeffbbU8U6dOlnnvPrqqxo7dqwCAwPVvHlzjRo1SvHx8bp161b1Fw/t2rVL7u7ucnd3l4eHh3bu3KmtW7eqQYOSv/ojIyO1fv16Sb9eNyQkJERPPvmk2SXjAb6+voqNjdW0adOUkZGhuLi42i6pzho1apS6d++uhQsXljmnZcuW1u3F3d1d165dq9JjxMbG6uzZs7p27ZqWL1/+qCU/dirTo1GjRmnYsGGKj48v8/qQxfvYpUuXmioZDzh69Kg2b95sPRaLiopSz5491bVrV/n5+SksLEzr169XXl5eLVdaP5R1/FuV13/xnqF6OTk5acKECdZjq/Xr12vChAlycnKymXf27Fm1bdtWzs7OJdbx9NNPy9PT03ocjaqp7HZSfH/PfsR8/IkJdVLRm+2CggIVFhZq3LhxiomJsbnmUGRkpGbOnKkJEyYoPT1d27ZtU1paWi1WXfcY/38tqOqa6+DgoMTERL3//vvau3evvvnmGy1ZskTLli3T4cOH1bx580cpF8X069dPa9askSRlZWVp9erVCg4O1uHDh+Xr62szd8KECXrnnXd0/vx5bdiwQStXrqyNklHM5MmT9e677yoqKkqenp61XU6dtmzZMvXv37/UT3VKUlpamjw8PKy3mzRpUqX1b9myRRaLRf/73/905swZBQQEPFK9j6OKejRixAglJSUpLS1NL7/8cqlzivex+BtAVJ8TJ07I3d1d9+/fV35+voYMGWK9/k2jRo2UnJysH3/8Ufv27dPXX3+tWbNmKS4uTunp6XJzc6vl6uumio5/K3r9l9czVL/IyEi9+OKLWrJkibZt26b09HTdu3evxLyqHG+jYlXdTorv79mPmI9PSqFO6tevn44fP65z587p7t272rhxY4nTy4KDg3X37l1NmTJFw4YNK3HKEirWvn17WSwWnTlzpsw5HTp0kCSdPn261PHTp09b5xRp0aKFJk6cqPj4eJ08eVK5ublcvLkGNGrUSO3atVO7du3Us2dPrVu3Tnfu3NGnn35aYq63t7eGDh2qKVOmKDc3V8HBwbVQMUrj6OjIaUrVoE+fPgoKCtLcuXNLHW/durV1e2nXrl2pnygsy/nz5zVnzhytWbNGEydOVEREBJ8IeQgV9ejjjz9WWFiYgoODyzwNvHgfiwfwqJinp6du3rxZYvmNGzdsLirfsWNHHT9+XKdPn9bdu3e1c+dOPfXUUzb3adu2rV577TWtW7dOx44d06lTp7R169Yafw71VUXHvxW9/ivTM1Sfrl27qlOnTho7dqyeffZZ/eY3vykxp0OHDjp//nypp5ddunRJt27dKnEcjfJVdTspvr9nP2I+QinUSUVvtp955pky36w5Ojpq0qRJSk1N5dS9h9S0aVMFBQUpISFBd+7cKTF+48YNDRo0SE2bNtVHH31UYnznzp06d+6cxo4dW+ZjNGnSRM2bNy91/aheFotFDRo00N27d0sdj4yMVGpqqiZNmiQHBweTqwNq3tKlS/XFF18oPT292tZZWFioiIgIvfLKK5o0aZJiY2N1+/ZtLViwoNoe43FSXo8sFos++eQTjR8/XiEhIdq/f38tVFj/dezYUceOHSux/NixYzZvjou+bt3Pz6/UU4+K8/Pzk5ubG/v7R1CZ49/yVLVneHRFx1ZlvRcJCwtTdna2Pv744xJjH374oZycnBQaGlrTZdYrj7qdwHx0CfXae++9p9mzZ/MpqUeQkJCg3/3udwoICNCiRYv03HPP6d69e9qzZ4/WrFmj06dPW/96/cc//lEzZsyQp6enUlJSNHv2bI0ePVp/+MMfJP36V+7jx49r1KhRatu2rXJzc/XZZ5/p5MmTWrVqVS0/0/onLy9PmZmZkn49fS8+Pl7Z2dklLrJZZPDgwbp69SqnidWQmzdv6vjx4zbLin43/fLLLyXGfH19q3wKGcrXtWtXjR8//qFOTz1x4oTNx/ktFou6deumuLg4nTx5UidPnpQkeXl5ad26dRo6dKhCQ0M5ja+KKuqRxWLR2rVr5eDgoJCQECUnJ6tv377W8StXrig3N9fmPt7e3px+UQVvvPGG4uPj9ac//UmvvfaaXFxclJycrC1btuiLL76o1DpiYmKUk5OjkJAQ+fr66saNG1q5cqUKCgo0cODAGn4Gjy9e//Zn6tSpevXVV9W4ceNSx3v37q2ZM2dq9uzZys/P18iRI1VQUKBNmzYpLi5OsbGxatWqlblFP+bYjsxHKIV6zdnZWU888URtl1GntWnTRseOHdPixYs1a9YsZWRk6Mknn5S/v7/1ekWjR4/Wvn37tHjxYr388svKzc1V+/btNW/ePL355pvWC9IGBATo4MGDmjZtmi5dumS9eOD27dsVGBhYm0+zXtq9e7f1Ol0eHh7q1KmTtm3bZvMG7kEWi4XtpQalpqbq+eeft1k2ZcoUSb/+NfTDDz+0Gfvb3/6mCRMmmFbf42LRokUPdfpQnz59bG47ODjo1KlTmjdvntatWycfHx/rWFBQkCZPnqyIiAh9++23cnFxeeS6HycV9chisSghIUENGjTQkCFDtGvXLut+pmPHjiXmp6enq1evXjVWb33Tpk0bHThwQPPmzdOAAQOUn59v3X8MHjy4UusIDAxUQkKCJk2apMuXL6tJkyZ6/vnn9dVXX5XaI1QPXv/2x9HRscJjq9jYWD333HNavXq15s+fLwcHB73wwgvavn17mX9IRM1hOzKfxeDKagAAAAAAADAZ15QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACm+z+EecL7PBJ88QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2tIq2OC5QWlk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}