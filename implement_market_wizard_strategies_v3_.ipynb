{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoope70/daytrading-with-ml/blob/main/implement_market_wizard_strategies_v3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3unZTnDPdSb1",
        "outputId": "22e5422f-65ad-44e6-94c6-f873ca489642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dask==2024.11.2\n",
            "  Downloading dask-2024.11.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting rapids-dask-dependency==24.12.0\n",
            "  Downloading rapids_dask_dependency-24.12.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cudf-cu12==24.12.0\n",
            "  Downloading cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting cuml-cu12==24.12.0\n",
            "  Downloading cuml_cu12-24.12.0.tar.gz (2.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pylibraft-cu12==24.12.0\n",
            "  Downloading pylibraft_cu12-24.12.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pylibcudf-cu12==24.12.0\n",
            "  Downloading pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting numba==0.61.0\n",
            "  Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gym-anytrading==2.0.0\n",
            "  Downloading gym_anytrading-2.0.0-py3-none-any.whl.metadata (292 bytes)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting click>=8.1 (from dask==2024.11.2)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle>=3.0.0 (from dask==2024.11.2)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting fsspec>=2021.09.0 (from dask==2024.11.2)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting packaging>=20.0 (from dask==2024.11.2)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting partd>=1.4.0 (from dask==2024.11.2)\n",
            "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml>=5.3.1 (from dask==2024.11.2)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting toolz>=0.10.0 (from dask==2024.11.2)\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting importlib-metadata>=4.13.0 (from dask==2024.11.2)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting distributed==2024.11.2 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading distributed-2024.11.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting dask-expr==1.1.19 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pynvml<11.5.0a0,>=11.0.0 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting cachetools (from cudf-cu12==24.12.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cuda-python<13.0a0,<=12.6.0,>=12.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting cupy-cuda12x>=12.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting libcudf-cu12==24.12.* (from cudf-cu12==24.12.0)\n",
            "  Downloading libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numba-cuda<0.0.18,>=0.0.13 (from cudf-cu12==24.12.0)\n",
            "  Downloading numba_cuda-0.0.17.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12==24.12.0)\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvtx>=0.2.1 (from cudf-cu12==24.12.0)\n",
            "  Downloading nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting pandas<2.2.4dev0,>=2.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow<19.0.0a0,>=14.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pynvjitlink-cu12 (from cudf-cu12==24.12.0)\n",
            "  Downloading pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting rich (from cudf-cu12==24.12.0)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rmm-cu12==24.12.* (from cudf-cu12==24.12.0)\n",
            "  Downloading rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions>=4.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cuvs-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading cuvs_cu12-24.12.0.tar.gz (1.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dask-cuda==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading dask_cuda-24.12.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting dask-cudf-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading dask_cudf_cu12-24.12.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting joblib>=0.11 (from cuml-cu12==24.12.0)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting raft-dask-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading raft_dask_cu12-24.12.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy>=1.8.0 (from cuml-cu12==24.12.0)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treelite==4.3.0 (from cuml-cu12==24.12.0)\n",
            "  Downloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.0)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12==24.12.0)\n",
            "  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farama-notifications>=0.0.1 (from gymnasium==0.29.1)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting matplotlib>=3.1.1 (from gym-anytrading==2.0.0)\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting zict>=2.0.0 (from dask-cuda==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting jinja2>=2.10.3 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting locket>=1.0.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting msgpack>=1.0.2 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting psutil>=5.8.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tornado>=6.2.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting urllib3>=1.26.5 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting libkvikio-cu12==24.12.* (from libcudf-cu12==24.12.*->cudf-cu12==24.12.0)\n",
            "  Downloading libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting nvidia-nvcomp-cu12==4.1.0.6 (from libcudf-cu12==24.12.*->cudf-cu12==24.12.0)\n",
            "  Downloading nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl.metadata (862 bytes)\n",
            "Collecting distributed-ucxx-cu12==0.41.* (from raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading distributed_ucxx_cu12-0.41.0.tar.gz (991 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucx-py-cu12==0.41.* (from raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading ucx_py_cu12-0.41.0.tar.gz (1.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucxx-cu12==0.41.* (from distributed-ucxx-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading ucxx_cu12-0.41.0.tar.gz (3.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting libucx-cu12<1.18,>=1.15.0 (from ucx-py-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading libucx_cu12-1.17.0.post1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting libucxx-cu12==0.41.* (from ucxx-cu12==0.41.*->distributed-ucxx-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading libucxx_cu12-0.41.0.tar.gz (3.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch<3.0,>=2.3 (from stable-baselines3[extra])\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting opencv-python (from stable-baselines3[extra])\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pygame (from stable-baselines3[extra])\n",
            "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tqdm (from stable-baselines3[extra])\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
            "  Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting pillow (from stable-baselines3[extra])\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x>=12.0.0->cudf-cu12==24.12.0)\n",
            "  Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=4.13.0->dask==2024.11.2)\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.2.4dev0,>=2.0->cudf-cu12==24.12.0)\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.2.4dev0,>=2.0->cudf-cu12==24.12.0)\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading protobuf-6.30.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting setuptools>=41.0.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting six>1.9 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting filelock (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting networkx (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->cudf-cu12==24.12.0)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->cudf-cu12==24.12.0)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.10.3->distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->cudf-cu12==24.12.0)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading dask-2024.11.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapids_dask_dependency-24.12.0-py3-none-any.whl (15 kB)\n",
            "Downloading cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gym_anytrading-2.0.0-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cuda-24.12.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cudf_cu12-24.12.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_expr-1.1.19-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.5/244.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distributed-2024.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl (457.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.8/457.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl (915 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m916.0/916.0 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl (28.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.9/28.9 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba_cuda-0.0.17.1-py3-none-any.whl (424 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.7/424.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.30.0-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libucx_cu12-1.17.0.post1-py3-none-manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: cuml-cu12, pylibraft-cu12, cuvs-cu12, raft-dask-cu12, distributed-ucxx-cu12, ucx-py-cu12, ucxx-cu12, libucxx-cu12\n",
            "  Building wheel for cuml-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuml-cu12: filename=cuml_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=548018735 sha256=2418da8e8eb6e9e43ab4ef2a43b05eaec1b0e1c27f6eb93e9b390d625f87830d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/a8/b2/1b20fa5b8a53c9d3d5d0d9c5350683457c23d1f3e924beab41\n",
            "  Building wheel for pylibraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylibraft-cu12: filename=pylibraft_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=11802800 sha256=47d3915fd3cdf4022acbd0315f88b12155399ef0b0e77fcac050c459ab6b31b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/67/73/9252ad4b3876078a9bca569565977dd588cb54f66bd3bf2e0d\n",
            "  Building wheel for cuvs-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuvs-cu12: filename=cuvs_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=849668080 sha256=b19c011e0219334cf22fbb77768eec6798897afebdd4cbb48e6de156cfc3a1a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c8/33/82e634a5179b7034208bca3b0a465bde16e40d6212b63171b9\n",
            "  Building wheel for raft-dask-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for raft-dask-cu12: filename=raft_dask_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=196890281 sha256=22907cfcaf561dfe366b129021300168737a3cbad25812fd61819e1a9aeff4f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/14/3e/c40661899a098c7c99ae981bff10c67930615f082c0c886634\n",
            "  Building wheel for distributed-ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distributed-ucxx-cu12: filename=distributed_ucxx_cu12-0.41.0-py3-none-any.whl size=24803 sha256=73437e496b61b34a5f0f3d9e64c5873c1d176bf80379fa8318d1ebdd78fa560b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/9f/30/fc294cabfead20c6cd33ad49842809c23eb8cb9db2c857dd11\n",
            "  Building wheel for ucx-py-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucx-py-cu12: filename=ucx_py_cu12-0.41.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl size=2287997 sha256=ada163c63d31e19ff65ee1218448cea2de52e80797dca6a519a20d39fd09e2cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/e1/e6/87ca1ddc23cc8b9d857c9a0b1e8199b3ec60fe3f4efbbac3d5\n",
            "  Building wheel for ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucxx-cu12: filename=ucxx_cu12-0.41.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl size=841184 sha256=d498bf3c805f799d4a6f7f69269169dc3c544bd30f3410a0f4876a33d2e21723\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/6f/9b/dfcf3e4fa6df3069345e6a0560c94b6f2a3161ab38904da670\n",
            "  Building wheel for libucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libucxx-cu12: filename=libucxx_cu12-0.41.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl size=513262 sha256=9bd816b322e55d19230b8dda392da532e6b333e1d504c6576024dfcd78dd3177\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/04/a6/de68207e0e498ea1367f31a6e523e238e2b7afa9e31290d0cc\n",
            "Successfully built cuml-cu12 pylibraft-cu12 cuvs-cu12 raft-dask-cu12 distributed-ucxx-cu12 ucx-py-cu12 ucxx-cu12 libucxx-cu12\n",
            "Installing collected packages: triton, sortedcontainers, pytz, nvtx, nvidia-cusparselt-cu12, mpmath, libkvikio-cu12, fastrlock, farama-notifications, cuda-python, zipp, zict, urllib3, tzdata, typing_extensions, tqdm, tornado, toolz, tensorboard-data-server, tblib, sympy, six, setuptools, pyyaml, pyparsing, pynvml, pynvjitlink-cu12, pygments, pygame, pyarrow, psutil, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nvcomp-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, msgpack, mdurl, MarkupSafe, markdown, locket, llvmlite, libucx-cu12, kiwisolver, joblib, grpcio, fsspec, fonttools, filelock, cycler, cloudpickle, click, cachetools, absl-py, werkzeug, ucx-py-cu12, scipy, python-dateutil, partd, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, libucxx-cu12, libcudf-cu12, jinja2, importlib-metadata, gymnasium, cupy-cuda12x, contourpy, ale-py, treelite, tensorboard, rmm-cu12, rich, pandas, nvidia-cusolver-cu12, numba-cuda, matplotlib, dask, ucxx-cu12, torch, pylibraft-cu12, pylibcudf-cu12, gym-anytrading, distributed, dask-expr, stable-baselines3, rapids-dask-dependency, cuvs-cu12, cudf-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: nvtx\n",
            "    Found existing installation: nvtx 0.2.11\n",
            "    Uninstalling nvtx-0.2.11:\n",
            "      Successfully uninstalled nvtx-0.2.11\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: libkvikio-cu12\n",
            "    Found existing installation: libkvikio-cu12 25.2.1\n",
            "    Uninstalling libkvikio-cu12-25.2.1:\n",
            "      Successfully uninstalled libkvikio-cu12-25.2.1\n",
            "  Attempting uninstall: fastrlock\n",
            "    Found existing installation: fastrlock 0.8.3\n",
            "    Uninstalling fastrlock-0.8.3:\n",
            "      Successfully uninstalled fastrlock-0.8.3\n",
            "  Attempting uninstall: farama-notifications\n",
            "    Found existing installation: Farama-Notifications 0.0.4\n",
            "    Uninstalling Farama-Notifications-0.0.4:\n",
            "      Successfully uninstalled Farama-Notifications-0.0.4\n",
            "  Attempting uninstall: cuda-python\n",
            "    Found existing installation: cuda-python 12.6.2.post1\n",
            "    Uninstalling cuda-python-12.6.2.post1:\n",
            "      Successfully uninstalled cuda-python-12.6.2.post1\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.21.0\n",
            "    Uninstalling zipp-3.21.0:\n",
            "      Successfully uninstalled zipp-3.21.0\n",
            "  Attempting uninstall: zict\n",
            "    Found existing installation: zict 3.0.0\n",
            "    Uninstalling zict-3.0.0:\n",
            "      Successfully uninstalled zict-3.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.4.2\n",
            "    Uninstalling tornado-6.4.2:\n",
            "      Successfully uninstalled tornado-6.4.2\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 0.12.1\n",
            "    Uninstalling toolz-0.12.1:\n",
            "      Successfully uninstalled toolz-0.12.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.1\n",
            "    Uninstalling pyparsing-3.2.1:\n",
            "      Successfully uninstalled pyparsing-3.2.1\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 12.0.0\n",
            "    Uninstalling pynvml-12.0.0:\n",
            "      Successfully uninstalled pynvml-12.0.0\n",
            "  Attempting uninstall: pynvjitlink-cu12\n",
            "    Found existing installation: pynvjitlink-cu12 0.5.1\n",
            "    Uninstalling pynvjitlink-cu12-0.5.1:\n",
            "      Successfully uninstalled pynvjitlink-cu12-0.5.1\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nvcomp-cu12\n",
            "    Found existing installation: nvidia-nvcomp-cu12 4.2.0.11\n",
            "    Uninstalling nvidia-nvcomp-cu12-4.2.0.11:\n",
            "      Successfully uninstalled nvidia-nvcomp-cu12-4.2.0.11\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.7\n",
            "    Uninstalling Markdown-3.7:\n",
            "      Successfully uninstalled Markdown-3.7\n",
            "  Attempting uninstall: locket\n",
            "    Found existing installation: locket 1.0.0\n",
            "    Uninstalling locket-1.0.0:\n",
            "      Successfully uninstalled locket-1.0.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: libucx-cu12\n",
            "    Found existing installation: libucx-cu12 1.18.0\n",
            "    Uninstalling libucx-cu12-1.18.0:\n",
            "      Successfully uninstalled libucx-cu12-1.18.0\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.70.0\n",
            "    Uninstalling grpcio-1.70.0:\n",
            "      Successfully uninstalled grpcio-1.70.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.56.0\n",
            "    Uninstalling fonttools-4.56.0:\n",
            "      Successfully uninstalled fonttools-4.56.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.17.0\n",
            "    Uninstalling filelock-3.17.0:\n",
            "      Successfully uninstalled filelock-3.17.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: ucx-py-cu12\n",
            "    Found existing installation: ucx-py-cu12 0.42.0\n",
            "    Uninstalling ucx-py-cu12-0.42.0:\n",
            "      Successfully uninstalled ucx-py-cu12-0.42.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: partd\n",
            "    Found existing installation: partd 1.4.2\n",
            "    Uninstalling partd-1.4.2:\n",
            "      Successfully uninstalled partd-1.4.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: libucxx-cu12\n",
            "    Found existing installation: libucxx-cu12 0.42.0\n",
            "    Uninstalling libucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled libucxx-cu12-0.42.0\n",
            "  Attempting uninstall: libcudf-cu12\n",
            "    Found existing installation: libcudf-cu12 25.2.1\n",
            "    Uninstalling libcudf-cu12-25.2.1:\n",
            "      Successfully uninstalled libcudf-cu12-25.2.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "  Attempting uninstall: cupy-cuda12x\n",
            "    Found existing installation: cupy-cuda12x 13.3.0\n",
            "    Uninstalling cupy-cuda12x-13.3.0:\n",
            "      Successfully uninstalled cupy-cuda12x-13.3.0\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.10.2\n",
            "    Uninstalling ale-py-0.10.2:\n",
            "      Successfully uninstalled ale-py-0.10.2\n",
            "  Attempting uninstall: treelite\n",
            "    Found existing installation: treelite 4.4.1\n",
            "    Uninstalling treelite-4.4.1:\n",
            "      Successfully uninstalled treelite-4.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: rmm-cu12\n",
            "    Found existing installation: rmm-cu12 25.2.0\n",
            "    Uninstalling rmm-cu12-25.2.0:\n",
            "      Successfully uninstalled rmm-cu12-25.2.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: numba-cuda\n",
            "    Found existing installation: numba-cuda 0.2.0\n",
            "    Uninstalling numba-cuda-0.2.0:\n",
            "      Successfully uninstalled numba-cuda-0.2.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.12.1\n",
            "    Uninstalling dask-2024.12.1:\n",
            "      Successfully uninstalled dask-2024.12.1\n",
            "  Attempting uninstall: ucxx-cu12\n",
            "    Found existing installation: ucxx-cu12 0.42.0\n",
            "    Uninstalling ucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled ucxx-cu12-0.42.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: pylibraft-cu12\n",
            "    Found existing installation: pylibraft-cu12 25.2.0\n",
            "    Uninstalling pylibraft-cu12-25.2.0:\n",
            "      Successfully uninstalled pylibraft-cu12-25.2.0\n",
            "  Attempting uninstall: pylibcudf-cu12\n",
            "    Found existing installation: pylibcudf-cu12 25.2.1\n",
            "    Uninstalling pylibcudf-cu12-25.2.1:\n",
            "      Successfully uninstalled pylibcudf-cu12-25.2.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.12.1\n",
            "    Uninstalling distributed-2024.12.1:\n",
            "      Successfully uninstalled distributed-2024.12.1\n",
            "  Attempting uninstall: dask-expr\n",
            "    Found existing installation: dask-expr 1.1.21\n",
            "    Uninstalling dask-expr-1.1.21:\n",
            "      Successfully uninstalled dask-expr-1.1.21\n",
            "  Attempting uninstall: rapids-dask-dependency\n",
            "    Found existing installation: rapids-dask-dependency 25.2.0\n",
            "    Uninstalling rapids-dask-dependency-25.2.0:\n",
            "      Successfully uninstalled rapids-dask-dependency-25.2.0\n",
            "  Attempting uninstall: cuvs-cu12\n",
            "    Found existing installation: cuvs-cu12 25.2.1\n",
            "    Uninstalling cuvs-cu12-25.2.1:\n",
            "      Successfully uninstalled cuvs-cu12-25.2.1\n",
            "  Attempting uninstall: cudf-cu12\n",
            "    Found existing installation: cudf-cu12 25.2.1\n",
            "    Uninstalling cudf-cu12-25.2.1:\n",
            "      Successfully uninstalled cudf-cu12-25.2.1\n",
            "  Attempting uninstall: distributed-ucxx-cu12\n",
            "    Found existing installation: distributed-ucxx-cu12 0.42.0\n",
            "    Uninstalling distributed-ucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled distributed-ucxx-cu12-0.42.0\n",
            "  Attempting uninstall: dask-cudf-cu12\n",
            "    Found existing installation: dask-cudf-cu12 25.2.2\n",
            "    Uninstalling dask-cudf-cu12-25.2.2:\n",
            "      Successfully uninstalled dask-cudf-cu12-25.2.2\n",
            "  Attempting uninstall: dask-cuda\n",
            "    Found existing installation: dask-cuda 25.2.0\n",
            "    Uninstalling dask-cuda-25.2.0:\n",
            "      Successfully uninstalled dask-cuda-25.2.0\n",
            "  Attempting uninstall: raft-dask-cu12\n",
            "    Found existing installation: raft-dask-cu12 25.2.0\n",
            "    Uninstalling raft-dask-cu12-25.2.0:\n",
            "      Successfully uninstalled raft-dask-cu12-25.2.0\n",
            "  Attempting uninstall: cuml-cu12\n",
            "    Found existing installation: cuml-cu12 25.2.1\n",
            "    Uninstalling cuml-cu12-25.2.1:\n",
            "      Successfully uninstalled cuml-cu12-25.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-iam 2.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-dataproc 5.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-api-core 2.24.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.28.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "googleapis-common-protos 1.69.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-pubsub 2.25.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-spanner 3.52.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.79.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "wandb 0.19.8 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.0 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-bigtable 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "proto-plus 1.26.0 requires protobuf<6.0.0dev,>=3.19.0, but you have protobuf 6.30.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.1.0 ale-py-0.10.2 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 contourpy-1.3.1 cuda-python-12.6.0 cudf-cu12-24.12.0 cuml-cu12-24.12.0 cupy-cuda12x-13.4.0 cuvs-cu12-24.12.0 cycler-0.12.1 dask-2024.11.2 dask-cuda-24.12.0 dask-cudf-cu12-24.12.0 dask-expr-1.1.19 distributed-2024.11.2 distributed-ucxx-cu12-0.41.0 farama-notifications-0.0.4 fastrlock-0.8.3 filelock-3.17.0 fonttools-4.56.0 fsspec-2025.3.0 grpcio-1.71.0 gym-anytrading-2.0.0 gymnasium-0.29.1 importlib-metadata-8.6.1 jinja2-3.1.6 joblib-1.4.2 kiwisolver-1.4.8 libcudf-cu12-24.12.0 libkvikio-cu12-24.12.1 libucx-cu12-1.17.0.post1 libucxx-cu12-0.41.0 llvmlite-0.44.0 locket-1.0.0 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.1.0 networkx-3.4.2 numba-0.61.0 numba-cuda-0.0.17.1 numpy-2.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvcomp-cu12-4.1.0.6 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 nvtx-0.2.11 opencv-python-4.11.0.86 packaging-24.2 pandas-2.2.3 partd-1.4.2 pillow-11.1.0 protobuf-6.30.0 psutil-7.0.0 pyarrow-18.1.0 pygame-2.6.1 pygments-2.19.1 pylibcudf-cu12-24.12.0 pylibraft-cu12-24.12.0 pynvjitlink-cu12-0.5.2 pynvml-11.4.1 pyparsing-3.2.1 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 raft-dask-cu12-24.12.0 rapids-dask-dependency-24.12.0 rich-13.9.4 rmm-cu12-24.12.1 scipy-1.15.2 setuptools-76.0.0 six-1.17.0 sortedcontainers-2.4.0 stable-baselines3-2.5.0 sympy-1.13.1 tblib-3.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 toolz-1.0.0 torch-2.6.0 tornado-6.4.2 tqdm-4.67.1 treelite-4.3.0 triton-3.2.0 typing_extensions-4.12.2 tzdata-2025.1 ucx-py-cu12-0.41.0 ucxx-cu12-0.41.0 urllib3-2.3.0 werkzeug-3.1.3 zict-3.0.0 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "cycler",
                  "dateutil",
                  "importlib_metadata",
                  "kiwisolver",
                  "psutil",
                  "rapids_dask_dependency",
                  "six",
                  "tornado",
                  "zipp"
                ]
              },
              "id": "26f1c398340b427ea05678f4821f7f04"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall \\\n",
        "    dask==2024.11.2 \\\n",
        "    rapids-dask-dependency==24.12.0 \\\n",
        "    cudf-cu12==24.12.0 \\\n",
        "    cuml-cu12==24.12.0 \\\n",
        "    pylibraft-cu12==24.12.0 \\\n",
        "    pylibcudf-cu12==24.12.0 \\\n",
        "    numba==0.61.0 \\\n",
        "    stable-baselines3[extra] \\\n",
        "    gymnasium==0.29.1 \\\n",
        "    gym-anytrading==2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk2eXrK9N8sy",
        "outputId": "d80ff0fe-bb86-4610-9c23-ca45d09e50da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym-anytrading in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (0.29.1)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.1.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/374.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Collecting swig==4.* (from gymnasium[box2d])\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.30.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (76.0.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[box2d] stable-baselines3[extra] gym-anytrading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "simIAIAMDvA9",
        "outputId": "c9509ee6-5479-4c72-f0f1-b5257377c07a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.54)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Collecting protobuf==3.20.3\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.1.3)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.0\n",
            "    Uninstalling protobuf-6.30.0:\n",
            "      Successfully uninstalled protobuf-6.30.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "508b61ee9b854450b1e1e8ba012c745f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install yfinance xgboost joblib protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LSRmcQn3MTvU",
        "outputId": "c4b305ea-e350-4aa6-dc55-2e187712c6c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (3.20.3)\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-6.30.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Using cached protobuf-6.30.0-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-iam 2.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-dataproc 5.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-api-core 2.24.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.28.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "googleapis-common-protos 1.69.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-pubsub 2.25.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-spanner 3.52.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.79.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "wandb 0.19.8 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.0 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.0 which is incompatible.\n",
            "google-cloud-bigtable 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.0 which is incompatible.\n",
            "proto-plus 1.26.0 requires protobuf<6.0.0dev,>=3.19.0, but you have protobuf 6.30.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-6.30.0\n",
            "Collecting protobuf==3.20.3\n",
            "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.0\n",
            "    Uninstalling protobuf-6.30.0:\n",
            "      Successfully uninstalled protobuf-6.30.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ff8332a0ebed430ba35af7d73a06c5e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (76.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
            "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, tensorboard\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.3\n",
            "    Uninstalling numpy-2.1.3:\n",
            "      Successfully uninstalled numpy-2.1.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2 tensorboard-2.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade protobuf\n",
        "!pip install protobuf==3.20.3\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48yV-FjZMW6-",
        "outputId": "fea695a8-c8a9-4f18-8056-004135c35c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0\n",
            "    Uninstalling torch-2.6.0:\n",
            "      Successfully uninstalled torch-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oeEKYZmoMaPH",
        "outputId": "edeb35d1-f658-4732-e5df-346543c2754c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cudf-cu12\n",
            "  Downloading cudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting cuml-cu12\n",
            "  Downloading cuml_cu12-25.2.1.tar.gz (2.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapids-dask-dependency\n",
            "  Downloading rapids_dask_dependency-25.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cachetools (from cudf-cu12)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cuda-python<13.0a0,>=12.6.2 (from cudf-cu12)\n",
            "  Downloading cuda_python-12.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting cupy-cuda12x>=12.0.0 (from cudf-cu12)\n",
            "  Using cached cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting fsspec>=0.6.0 (from cudf-cu12)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting libcudf-cu12==25.2.* (from cudf-cu12)\n",
            "  Downloading libcudf_cu12-25.2.2-py3-none-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numba-cuda<0.3.0a0,>=0.2.0 (from cudf-cu12)\n",
            "  Downloading numba_cuda-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting numba<0.61.0a0,>=0.59.1 (from cudf-cu12)\n",
            "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12)\n",
            "  Using cached numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting nvtx>=0.2.1 (from cudf-cu12)\n",
            "  Using cached nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting packaging (from cudf-cu12)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas<2.2.4dev0,>=2.0 (from cudf-cu12)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting pyarrow<20.0.0a0,>=14.0.0 (from cudf-cu12)\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pylibcudf-cu12==25.2.* (from cudf-cu12)\n",
            "  Downloading pylibcudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting pynvjitlink-cu12 (from cudf-cu12)\n",
            "  Using cached pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting rich (from cudf-cu12)\n",
            "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rmm-cu12==25.2.* (from cudf-cu12)\n",
            "  Downloading rmm_cu12-25.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions>=4.0.0 (from cudf-cu12)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting libkvikio-cu12==25.2.* (from libcudf-cu12==25.2.*->cudf-cu12)\n",
            "  Downloading libkvikio_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting nvidia-nvcomp-cu12==4.2.0.11 (from libcudf-cu12==25.2.*->cudf-cu12)\n",
            "  Downloading nvidia_nvcomp_cu12-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl.metadata (863 bytes)\n",
            "Collecting cuvs-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading cuvs_cu12-25.2.1.tar.gz (1.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dask-cuda==25.2.* (from cuml-cu12)\n",
            "  Downloading dask_cuda-25.2.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting dask-cudf-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading dask_cudf_cu12-25.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting joblib>=0.11 (from cuml-cu12)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting libcuml-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading libcuml_cu12-25.2.1.tar.gz (4.1 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting pylibraft-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading pylibraft_cu12-25.2.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting raft-dask-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading raft_dask_cu12-25.2.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy>=1.8.0 (from cuml-cu12)\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting treelite==4.4.1 (from cuml-cu12)\n",
            "  Downloading treelite-4.4.1-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting dask==2024.12.1 (from rapids-dask-dependency)\n",
            "  Downloading dask-2024.12.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting distributed==2024.12.1 (from rapids-dask-dependency)\n",
            "  Downloading distributed-2024.12.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting dask-expr==1.1.21 (from rapids-dask-dependency)\n",
            "  Downloading dask_expr-1.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting libcuvs-cu12==25.2.* (from cuvs-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading libcuvs_cu12-25.2.1.tar.gz (4.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click>=8.1 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle>=3.0.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting partd>=1.4.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml>=5.3.1 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting toolz>=0.10.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting importlib_metadata>=4.13.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pynvml<13.0.0a0,>=12.0.0 (from dask-cuda==25.2.*->cuml-cu12)\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting zict>=2.0.0 (from dask-cuda==25.2.*->cuml-cu12)\n",
            "  Using cached zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting jinja2>=2.10.3 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting locket>=1.0.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting msgpack>=1.0.2 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting psutil>=5.8.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tornado>=6.2.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting urllib3>=1.26.5 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting libraft-cu12==25.2.* (from libcuml-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading libraft_cu12-25.2.0.tar.gz (5.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting distributed-ucxx-cu12==0.42.* (from raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading distributed_ucxx_cu12-0.42.0.tar.gz (997 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucx-py-cu12==0.42.* (from raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading ucx_py_cu12-0.42.0.tar.gz (1.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucxx-cu12==0.42.* (from distributed-ucxx-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading ucxx_cu12-0.42.0.tar.gz (3.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting libucx-cu12<1.19,>=1.15.0 (from ucx-py-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading libucx_cu12-1.18.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting libucxx-cu12==0.42.* (from ucxx-cu12==0.42.*->distributed-ucxx-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading libucxx_cu12-0.42.0.tar.gz (3.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cuda-bindings~=12.8.0 (from cuda-python<13.0a0,>=12.6.2->cudf-cu12)\n",
            "  Downloading cuda_bindings-12.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x>=12.0.0->cudf-cu12)\n",
            "  Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba<0.61.0a0,>=0.59.1->cudf-cu12)\n",
            "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12)\n",
            "  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12->cuml-cu12)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->cudf-cu12)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->cudf-cu12)\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting zipp>=3.20 (from importlib_metadata>=4.13.0->dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.10.3->distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->cudf-cu12)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml<13.0.0a0,>=12.0.0->dask-cuda==25.2.*->cuml-cu12)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading cudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcudf_cu12-25.2.2-py3-none-manylinux_2_28_x86_64.whl (557.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.7/557.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylibcudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rmm_cu12-25.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libkvikio_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvcomp_cu12-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl (46.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapids_dask_dependency-25.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading dask-2024.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cuda-25.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cudf_cu12-25.2.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_expr-1.1.21-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distributed-2024.12.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading treelite-4.4.1-py3-none-manylinux2014_x86_64.whl (922 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.8/922.8 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_python-12.8.0-py3-none-any.whl (11 kB)\n",
            "Using cached cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba_cuda-0.2.0-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.7/443.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Using cached nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (46.2 MB)\n",
            "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading cuda_bindings-12.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "Using cached partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
            "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libucx_cu12-1.18.0-py3-none-manylinux_2_28_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: cuml-cu12, cuvs-cu12, libcuml-cu12, pylibraft-cu12, raft-dask-cu12, distributed-ucxx-cu12, libcuvs-cu12, libraft-cu12, ucx-py-cu12, ucxx-cu12, libucxx-cu12\n",
            "  Building wheel for cuml-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuml-cu12: filename=cuml_cu12-25.2.1-cp311-cp311-manylinux_2_28_x86_64.whl size=9708883 sha256=645732a1e89bff0eaf5832e2d9b9277ed5ad55802935deaa4f36cf2c848305bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/05/99/2ba4d47fa6b7433c469a53a0be406737d3e703866a37b00d1f\n",
            "  Building wheel for cuvs-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuvs-cu12: filename=cuvs_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl size=2317704 sha256=5fc01ad6fcc84e66c5d3dd89690e1fdca64299a55c9bc37ee2a1ba2ddd6107a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/f4/6e/2b1349b6608494674dcab7a67caf6e92572b467e31b94c5ccb\n",
            "  Building wheel for libcuml-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libcuml-cu12: filename=libcuml_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl size=405006204 sha256=36630506b77f92066d4a19de8a4d52dd32d8bcc8597a93de44f58f8832bc8ece\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/dd/bb/be110f3f4dce61cdd3575d757f9bfa91c60e3c6d7e37ce0490\n",
            "  Building wheel for pylibraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylibraft-cu12: filename=pylibraft_cu12-25.2.0-cp311-cp311-manylinux_2_28_x86_64.whl size=851210 sha256=62186880220c3704e195ee3386774b48d7d340e310efd9d02c0b69d2057d8d6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/c8/f2/b134085eaa02b2a75d8bdd9ed640b4719ab22ce879889ff3b5\n",
            "  Building wheel for raft-dask-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for raft-dask-cu12: filename=raft_dask_cu12-25.2.0-cp311-cp311-manylinux_2_28_x86_64.whl size=293515763 sha256=e8180027a9a0d2830c555d54398059a04294b5e655aa40b88c416eec4a3a908b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/3a/ec/7def1e0bb02ac32c18f0f8234e4c692f73ea9c12744129969f\n",
            "  Building wheel for distributed-ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distributed-ucxx-cu12: filename=distributed_ucxx_cu12-0.42.0-py3-none-any.whl size=24814 sha256=24b4a9541965904448582b805c1b66c8f3d5a319fb86d73b2656877cc3a15694\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/6f/c8/218f0214f308d7f7308daffa946c2ae614a09478732659bd74\n",
            "  Building wheel for libcuvs-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libcuvs-cu12: filename=libcuvs_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl size=1184487347 sha256=eb4791a3aeb57c06898276b021e47267bb37b7f345c7a528a859c0b7370eb8e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/07/b8/5ef838697bece6ef046ece66c8259fd8c74013fbcf16db2a5e\n",
            "  Building wheel for libraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libraft-cu12: filename=libraft_cu12-25.2.0-py3-none-manylinux_2_28_x86_64.whl size=22311914 sha256=ef9ac99deec9fd2b5b67b88e8c84135a963cda553677048b01a99e1e8fac866b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/eb/f8/7221f323f4db20f7a2b52a432aaf57db5a91ace04c298ae06e\n",
            "  Building wheel for ucx-py-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucx-py-cu12: filename=ucx_py_cu12-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl size=2288214 sha256=4550e781576b8b855600f4731a489c2b124e55f7dfcb8438e76dea876c47c958\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/33/ec/770cb565db452511ae7e3a7dca0576463d566fe357c8ed7b59\n",
            "  Building wheel for ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucxx-cu12: filename=ucxx_cu12-0.42.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl size=725335 sha256=f3173262ad032899a7bbe7bcb1aec346246fdda3e84eaa909f2519b5b702b105\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/c9/73/d230d4204c9d12079812778542f992372f3739ef5c0322f38c\n",
            "  Building wheel for libucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libucxx-cu12: filename=libucxx_cu12-0.42.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl size=514759 sha256=852a1247b2e40ead703ebc7f4cc87c885787854fa89a01556c3403e1e2c5b120\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/70/6d/c8257996440e62cf9db49618493e7cf3187dd225321711eeae\n",
            "Successfully built cuml-cu12 cuvs-cu12 libcuml-cu12 pylibraft-cu12 raft-dask-cu12 distributed-ucxx-cu12 libcuvs-cu12 libraft-cu12 ucx-py-cu12 ucxx-cu12 libucxx-cu12\n",
            "Installing collected packages: sortedcontainers, pytz, nvtx, nvidia-ml-py, libkvikio-cu12, fastrlock, cuda-bindings, zipp, zict, urllib3, tzdata, typing_extensions, tornado, toolz, tblib, six, pyyaml, pynvml, pynvjitlink-cu12, pygments, pyarrow, psutil, packaging, nvidia-nvjitlink-cu12, nvidia-nvcomp-cu12, nvidia-curand-cu12, nvidia-cublas-cu12, numpy, msgpack, mdurl, MarkupSafe, locket, llvmlite, libucx-cu12, joblib, fsspec, cuda-python, cloudpickle, click, cachetools, ucx-py-cu12, scipy, rmm-cu12, python-dateutil, partd, nvidia-cusparse-cu12, nvidia-cufft-cu12, numba, markdown-it-py, libucxx-cu12, libcudf-cu12, jinja2, importlib_metadata, cupy-cuda12x, ucxx-cu12, treelite, rich, pylibcudf-cu12, pandas, nvidia-cusolver-cu12, numba-cuda, dask, libraft-cu12, distributed, dask-expr, cudf-cu12, rapids-dask-dependency, pylibraft-cu12, libcuvs-cu12, libcuml-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, cuvs-cu12, raft-dask-cu12, cuml-cu12\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: nvtx\n",
            "    Found existing installation: nvtx 0.2.11\n",
            "    Uninstalling nvtx-0.2.11:\n",
            "      Successfully uninstalled nvtx-0.2.11\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 12.570.86\n",
            "    Uninstalling nvidia-ml-py-12.570.86:\n",
            "      Successfully uninstalled nvidia-ml-py-12.570.86\n",
            "  Attempting uninstall: libkvikio-cu12\n",
            "    Found existing installation: libkvikio-cu12 24.12.1\n",
            "    Uninstalling libkvikio-cu12-24.12.1:\n",
            "      Successfully uninstalled libkvikio-cu12-24.12.1\n",
            "  Attempting uninstall: fastrlock\n",
            "    Found existing installation: fastrlock 0.8.3\n",
            "    Uninstalling fastrlock-0.8.3:\n",
            "      Successfully uninstalled fastrlock-0.8.3\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.21.0\n",
            "    Uninstalling zipp-3.21.0:\n",
            "      Successfully uninstalled zipp-3.21.0\n",
            "  Attempting uninstall: zict\n",
            "    Found existing installation: zict 3.0.0\n",
            "    Uninstalling zict-3.0.0:\n",
            "      Successfully uninstalled zict-3.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.4.2\n",
            "    Uninstalling tornado-6.4.2:\n",
            "      Successfully uninstalled tornado-6.4.2\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 1.0.0\n",
            "    Uninstalling toolz-1.0.0:\n",
            "      Successfully uninstalled toolz-1.0.0\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.4.1\n",
            "    Uninstalling pynvml-11.4.1:\n",
            "      Successfully uninstalled pynvml-11.4.1\n",
            "  Attempting uninstall: pynvjitlink-cu12\n",
            "    Found existing installation: pynvjitlink-cu12 0.5.2\n",
            "    Uninstalling pynvjitlink-cu12-0.5.2:\n",
            "      Successfully uninstalled pynvjitlink-cu12-0.5.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 7.0.0\n",
            "    Uninstalling psutil-7.0.0:\n",
            "      Successfully uninstalled psutil-7.0.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvcomp-cu12\n",
            "    Found existing installation: nvidia-nvcomp-cu12 4.1.0.6\n",
            "    Uninstalling nvidia-nvcomp-cu12-4.1.0.6:\n",
            "      Successfully uninstalled nvidia-nvcomp-cu12-4.1.0.6\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: locket\n",
            "    Found existing installation: locket 1.0.0\n",
            "    Uninstalling locket-1.0.0:\n",
            "      Successfully uninstalled locket-1.0.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.44.0\n",
            "    Uninstalling llvmlite-0.44.0:\n",
            "      Successfully uninstalled llvmlite-0.44.0\n",
            "  Attempting uninstall: libucx-cu12\n",
            "    Found existing installation: libucx-cu12 1.17.0.post1\n",
            "    Uninstalling libucx-cu12-1.17.0.post1:\n",
            "      Successfully uninstalled libucx-cu12-1.17.0.post1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: cuda-python\n",
            "    Found existing installation: cuda-python 12.6.0\n",
            "    Uninstalling cuda-python-12.6.0:\n",
            "      Successfully uninstalled cuda-python-12.6.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: ucx-py-cu12\n",
            "    Found existing installation: ucx-py-cu12 0.41.0\n",
            "    Uninstalling ucx-py-cu12-0.41.0:\n",
            "      Successfully uninstalled ucx-py-cu12-0.41.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: rmm-cu12\n",
            "    Found existing installation: rmm-cu12 24.12.1\n",
            "    Uninstalling rmm-cu12-24.12.1:\n",
            "      Successfully uninstalled rmm-cu12-24.12.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: partd\n",
            "    Found existing installation: partd 1.4.2\n",
            "    Uninstalling partd-1.4.2:\n",
            "      Successfully uninstalled partd-1.4.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.61.0\n",
            "    Uninstalling numba-0.61.0:\n",
            "      Successfully uninstalled numba-0.61.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: libucxx-cu12\n",
            "    Found existing installation: libucxx-cu12 0.41.0\n",
            "    Uninstalling libucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled libucxx-cu12-0.41.0\n",
            "  Attempting uninstall: libcudf-cu12\n",
            "    Found existing installation: libcudf-cu12 24.12.0\n",
            "    Uninstalling libcudf-cu12-24.12.0:\n",
            "      Successfully uninstalled libcudf-cu12-24.12.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: cupy-cuda12x\n",
            "    Found existing installation: cupy-cuda12x 13.4.0\n",
            "    Uninstalling cupy-cuda12x-13.4.0:\n",
            "      Successfully uninstalled cupy-cuda12x-13.4.0\n",
            "  Attempting uninstall: ucxx-cu12\n",
            "    Found existing installation: ucxx-cu12 0.41.0\n",
            "    Uninstalling ucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled ucxx-cu12-0.41.0\n",
            "  Attempting uninstall: treelite\n",
            "    Found existing installation: treelite 4.3.0\n",
            "    Uninstalling treelite-4.3.0:\n",
            "      Successfully uninstalled treelite-4.3.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pylibcudf-cu12\n",
            "    Found existing installation: pylibcudf-cu12 24.12.0\n",
            "    Uninstalling pylibcudf-cu12-24.12.0:\n",
            "      Successfully uninstalled pylibcudf-cu12-24.12.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: numba-cuda\n",
            "    Found existing installation: numba-cuda 0.0.17.1\n",
            "    Uninstalling numba-cuda-0.0.17.1:\n",
            "      Successfully uninstalled numba-cuda-0.0.17.1\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.11.2\n",
            "    Uninstalling dask-2024.11.2:\n",
            "      Successfully uninstalled dask-2024.11.2\n",
            "  Attempting uninstall: libraft-cu12\n",
            "    Found existing installation: libraft-cu12 25.2.0\n",
            "    Uninstalling libraft-cu12-25.2.0:\n",
            "      Successfully uninstalled libraft-cu12-25.2.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.11.2\n",
            "    Uninstalling distributed-2024.11.2:\n",
            "      Successfully uninstalled distributed-2024.11.2\n",
            "  Attempting uninstall: dask-expr\n",
            "    Found existing installation: dask-expr 1.1.19\n",
            "    Uninstalling dask-expr-1.1.19:\n",
            "      Successfully uninstalled dask-expr-1.1.19\n",
            "  Attempting uninstall: cudf-cu12\n",
            "    Found existing installation: cudf-cu12 24.12.0\n",
            "    Uninstalling cudf-cu12-24.12.0:\n",
            "      Successfully uninstalled cudf-cu12-24.12.0\n",
            "  Attempting uninstall: rapids-dask-dependency\n",
            "    Found existing installation: rapids-dask-dependency 24.12.0\n",
            "    Uninstalling rapids-dask-dependency-24.12.0:\n",
            "      Successfully uninstalled rapids-dask-dependency-24.12.0\n",
            "  Attempting uninstall: pylibraft-cu12\n",
            "    Found existing installation: pylibraft-cu12 24.12.0\n",
            "    Uninstalling pylibraft-cu12-24.12.0:\n",
            "      Successfully uninstalled pylibraft-cu12-24.12.0\n",
            "  Attempting uninstall: libcuvs-cu12\n",
            "    Found existing installation: libcuvs-cu12 25.2.1\n",
            "    Uninstalling libcuvs-cu12-25.2.1:\n",
            "      Successfully uninstalled libcuvs-cu12-25.2.1\n",
            "  Attempting uninstall: libcuml-cu12\n",
            "    Found existing installation: libcuml-cu12 25.2.1\n",
            "    Uninstalling libcuml-cu12-25.2.1:\n",
            "      Successfully uninstalled libcuml-cu12-25.2.1\n",
            "  Attempting uninstall: distributed-ucxx-cu12\n",
            "    Found existing installation: distributed-ucxx-cu12 0.41.0\n",
            "    Uninstalling distributed-ucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled distributed-ucxx-cu12-0.41.0\n",
            "  Attempting uninstall: dask-cudf-cu12\n",
            "    Found existing installation: dask-cudf-cu12 24.12.0\n",
            "    Uninstalling dask-cudf-cu12-24.12.0:\n",
            "      Successfully uninstalled dask-cudf-cu12-24.12.0\n",
            "  Attempting uninstall: dask-cuda\n",
            "    Found existing installation: dask-cuda 24.12.0\n",
            "    Uninstalling dask-cuda-24.12.0:\n",
            "      Successfully uninstalled dask-cuda-24.12.0\n",
            "  Attempting uninstall: cuvs-cu12\n",
            "    Found existing installation: cuvs-cu12 24.12.0\n",
            "    Uninstalling cuvs-cu12-24.12.0:\n",
            "      Successfully uninstalled cuvs-cu12-24.12.0\n",
            "  Attempting uninstall: raft-dask-cu12\n",
            "    Found existing installation: raft-dask-cu12 24.12.0\n",
            "    Uninstalling raft-dask-cu12-24.12.0:\n",
            "      Successfully uninstalled raft-dask-cu12-24.12.0\n",
            "  Attempting uninstall: cuml-cu12\n",
            "    Found existing installation: cuml-cu12 24.12.0\n",
            "    Uninstalling cuml-cu12-24.12.0:\n",
            "      Successfully uninstalled cuml-cu12-24.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "torch 2.5.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
            "torch 2.5.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
            "torch 2.5.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
            "torch 2.5.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
            "torch 2.5.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 cuda-bindings-12.8.0 cuda-python-12.8.0 cudf-cu12-25.2.2 cuml-cu12-25.2.1 cupy-cuda12x-13.4.0 cuvs-cu12-25.2.1 dask-2024.12.1 dask-cuda-25.2.0 dask-cudf-cu12-25.2.2 dask-expr-1.1.21 distributed-2024.12.1 distributed-ucxx-cu12-0.42.0 fastrlock-0.8.3 fsspec-2025.3.0 importlib_metadata-8.6.1 jinja2-3.1.6 joblib-1.4.2 libcudf-cu12-25.2.2 libcuml-cu12-25.2.1 libcuvs-cu12-25.2.1 libkvikio-cu12-25.2.1 libraft-cu12-25.2.0 libucx-cu12-1.18.0 libucxx-cu12-0.42.0 llvmlite-0.43.0 locket-1.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.1.0 numba-0.60.0 numba-cuda-0.2.0 numpy-2.0.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cufft-cu12-11.3.3.83 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-ml-py-12.570.86 nvidia-nvcomp-cu12-4.2.0.11 nvidia-nvjitlink-cu12-12.8.93 nvtx-0.2.11 packaging-24.2 pandas-2.2.3 partd-1.4.2 psutil-7.0.0 pyarrow-19.0.1 pygments-2.19.1 pylibcudf-cu12-25.2.2 pylibraft-cu12-25.2.0 pynvjitlink-cu12-0.5.2 pynvml-12.0.0 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 raft-dask-cu12-25.2.0 rapids-dask-dependency-25.2.0 rich-13.9.4 rmm-cu12-25.2.0 scipy-1.15.2 six-1.17.0 sortedcontainers-2.4.0 tblib-3.0.0 toolz-1.0.0 tornado-6.4.2 treelite-4.4.1 typing_extensions-4.12.2 tzdata-2025.1 ucx-py-cu12-0.42.0 ucxx-cu12-0.42.0 urllib3-2.3.0 zict-3.0.0 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "importlib_metadata",
                  "psutil",
                  "rapids_dask_dependency",
                  "six",
                  "tornado",
                  "zipp"
                ]
              },
              "id": "50238f56d0954400a0b20586204d7096"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install --force-reinstall cudf-cu12 cuml-cu12 rapids-dask-dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpIpkuE2SCve"
      },
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__sEW5w3SXr1",
        "outputId": "461c08fe-5589-4eb9-cf5d-f6284f31094f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp requirements.txt /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjalGotfhpIv",
        "outputId": "0d7faa9c-83f7-48ca-d034-1f5b4f3d52ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "absl-py==2.1.0\n",
            "accelerate==1.3.0\n",
            "aiohappyeyeballs==2.4.6\n",
            "aiohttp==3.11.13\n",
            "aiosignal==1.3.2\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.23\n",
            "albumentations==2.0.5\n",
            "ale-py==0.10.2\n",
            "altair==5.5.0\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BxX4NtYJaEE",
        "outputId": "da27b8bf-e935-4a51-c5c3-b2f8e1781c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ cuDF Version: 25.02.02\n",
            "✅ cuML Version: 25.02.01\n",
            "✅ Dask Version: 2024.12.1\n",
            "✅ Stable Baselines3 Installed: 2.5.0\n",
            "✅ Gymnasium Version: 0.29.1\n",
            "✅ NumPy Version: 2.0.2\n",
            "✅ SciPy Version: 1.15.2\n",
            "✅ Pandas Version: 2.2.3\n",
            "Wed Mar 12 16:15:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# ✅ Core Libraries\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import numba\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "# ✅ Machine Learning & Data Processing\n",
        "import xgboost as xgb\n",
        "import yfinance as yf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ✅ RAPIDS Libraries (cuDF & cuML for GPU acceleration)\n",
        "import cudf\n",
        "import cuml\n",
        "import dask\n",
        "\n",
        "# ✅ Reinforcement Learning (Stable Baselines3)\n",
        "import torch\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import A2C, PPO, DDPG\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "\n",
        "# ✅ Gym & Trading Environments\n",
        "import gymnasium as gym  # ✅ Use Gymnasium instead of Gym\n",
        "from gym import spaces\n",
        "import gym_anytrading\n",
        "from gym_anytrading.envs import StocksEnv\n",
        "from gymnasium.spaces import Box\n",
        "from gymnasium.wrappers import TimeLimit  # ✅ Fix: Explicitly import TimeLimit\n",
        "\n",
        "# ✅ TensorFlow & GPU Optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# ✅ Set CUDA Paths\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-11.8'\n",
        "os.environ['PATH'] += ':/usr/local/cuda-11.8/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda-11.8/lib64'\n",
        "\n",
        "# ✅ Print Version Check\n",
        "print(\"✅ cuDF Version:\", cudf.__version__)\n",
        "print(\"✅ cuML Version:\", cuml.__version__)\n",
        "print(\"✅ Dask Version:\", dask.__version__)\n",
        "print(\"✅ Stable Baselines3 Installed:\", stable_baselines3.__version__)\n",
        "print(\"✅ Gymnasium Version:\", gym.__version__)\n",
        "print(\"✅ NumPy Version:\", np.__version__)\n",
        "print(\"✅ SciPy Version:\", scipy.__version__)\n",
        "print(\"✅ Pandas Version:\", pd.__version__)\n",
        "\n",
        "# ✅ GPU Check\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HEZ1KrHqkzLA"
      },
      "outputs": [],
      "source": [
        "class DiscreteTradingEnv(gym.Env):\n",
        "    def __init__(self, df, frame_bound=(10, 100), window_size=10, verbose=False):\n",
        "        super(DiscreteTradingEnv, self).__init__()\n",
        "        self.df = df\n",
        "        self.frame_bound = frame_bound\n",
        "        self.window_size = window_size\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # ✅ Portfolio & Trading Variables\n",
        "        self.initial_balance = 100000  # ✅ Starting capital\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0  # ✅ Tracks the number of shares\n",
        "        self.last_trade_price = 0  # ✅ Stores last executed trade price\n",
        "        self.position_size = 0.1  # ✅ Adjustable capital allocation per trade\n",
        "\n",
        "        # ✅ Logging Trades & Rewards\n",
        "        self.trade_log = []  # ✅ Stores executed trades\n",
        "        self.rewards_log = []  # ✅ Stores reward history\n",
        "\n",
        "        # ✅ Define Discrete Action Space\n",
        "        self.action_space = Discrete(3)  # 0: SELL, 1: HOLD, 2: BUY\n",
        "        self.observation_space = Box(low=-np.inf, high=np.inf, shape=(window_size + 2,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        \"\"\"Resets the environment and returns the initial observation & info.\"\"\"\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "\n",
        "        # ✅ Reset Portfolio\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "\n",
        "        # ✅ Clear Logs\n",
        "        self.trade_log.clear()\n",
        "        self.rewards_log.clear()\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Executes an action (BUY/SELL/HOLD), updates the portfolio, and returns next state.\"\"\"\n",
        "\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            self.done = True\n",
        "            return self._next_observation(), 0, self.done, False, {}\n",
        "\n",
        "        self.current_step += 1\n",
        "        prev_price = self.df['Close'].iloc[self.current_step - 1]\n",
        "        new_price = self.df['Close'].iloc[self.current_step]\n",
        "\n",
        "        reward = 0\n",
        "        executed = False\n",
        "        old_portfolio_value = self.portfolio_value  # ✅ Store before modification\n",
        "\n",
        "        if action == 2:  # ✅ BUY\n",
        "            allocated_funds = self.portfolio_value * self.position_size\n",
        "            if self.portfolio_value >= allocated_funds:\n",
        "                shares_bought = allocated_funds / new_price\n",
        "                self.shares_held += shares_bought\n",
        "                self.portfolio_value -= shares_bought * new_price\n",
        "                self.last_trade_price = new_price\n",
        "\n",
        "                # ✅ Exploration reward\n",
        "                reward = 0.02 * np.exp(-0.001 * self.current_step) - 0.01\n",
        "                executed = True\n",
        "                trade_type = \"BUY\"\n",
        "\n",
        "        elif action == 0 and self.shares_held > 0:  # ✅ SELL\n",
        "            sell_value = self.shares_held * new_price\n",
        "            reward = (new_price - self.last_trade_price) * self.shares_held\n",
        "\n",
        "            # ✅ Reward profitable trades, penalize unprofitable ones\n",
        "            reward += 0.01 if reward > 0 else -0.01\n",
        "\n",
        "            self.portfolio_value += sell_value\n",
        "            executed = True\n",
        "            trade_type = \"SELL\"\n",
        "\n",
        "            # ✅ Reset holdings after sale\n",
        "            self.shares_held = 0.0\n",
        "            self.last_trade_price = 0.0\n",
        "\n",
        "        else:  # ✅ HOLD\n",
        "            trade_type = \"HOLD\"\n",
        "            reward -= 0.002 * self.shares_held  # ✅ Scaled penalty for excessive holding\n",
        "\n",
        "        # ✅ Log trade\n",
        "        if executed:\n",
        "            self.trade_log.append({\n",
        "                \"Step\": self.current_step,\n",
        "                \"Action\": trade_type,\n",
        "                \"Shares Held\": self.shares_held,\n",
        "                \"Portfolio Value\": self.portfolio_value,\n",
        "                \"Stock Price\": new_price,\n",
        "                \"Reward\": reward,\n",
        "                \"Profit/Loss\": reward if action == 0 else 0\n",
        "            })\n",
        "\n",
        "        # ✅ Store reward\n",
        "        self.rewards_log.append(reward)\n",
        "\n",
        "        return self._next_observation(), reward, self.done, False, {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        \"\"\"Returns the latest window of stock prices + shares held + portfolio value.\"\"\"\n",
        "        stock_prices = np.array(self.df['Close'].iloc[self.current_step - self.window_size:self.current_step], dtype=np.float32)\n",
        "        return np.concatenate(([self.portfolio_value], stock_prices, [self.shares_held]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKG932vFKBfA",
        "outputId": "cd39cb87-7fa2-44fc-91ce-2f15570b174a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ TensorFlow GPU memory growth enabled\n",
            "Attempt 1: Downloading AAPL stock data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully downloaded stock data!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ✅ Ensure TensorFlow GPU Memory Allocation is Configured\n",
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)  # Prevents full allocation\n",
        "        print(\"✅ TensorFlow GPU memory growth enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"⚠️ TensorFlow GPU memory issue: {e}\")\n",
        "\n",
        "# ✅ CUDA Paths\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-11.8'\n",
        "os.environ['PATH'] += ':/usr/local/cuda-11.8/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda-11.8/lib64'\n",
        "\n",
        "\n",
        "\n",
        "def download_stock_data(ticker, period=\"720d\", interval=\"1h\", max_retries=5):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt}: Downloading {ticker} stock data...\")\n",
        "            df_live = yf.download(ticker, period=period, interval=interval)\n",
        "            if not df_live.empty:\n",
        "                print(\"✅ Successfully downloaded stock data!\")\n",
        "                df_live.reset_index(inplace=True)\n",
        "                return df_live\n",
        "            raise ValueError(\"Downloaded data is empty. Retrying...\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error: {e}. Retrying in {attempt * 5} seconds...\")\n",
        "            time.sleep(attempt * 5)\n",
        "    print(\"❌ Failed to download stock data after multiple attempts.\")\n",
        "    return None\n",
        "\n",
        "df_live = download_stock_data(\"AAPL\")\n",
        "if df_live is None:\n",
        "    print(\"⚠️ Using previously saved dataset instead.\")\n",
        "    file_path = '/content/drive/My Drive/aaplfeature_engineered_dataset.csv'\n",
        "    df_live = pd.read_csv(file_path)\n",
        "\n",
        "df = df_live.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "p9Iyp3gMLizz"
      },
      "outputs": [],
      "source": [
        "# ✅ Fix Missing Index\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MiabhGq1Lz-n"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 📌 Step 3: Feature Engineering\n",
        "# ============================\n",
        "def compute_technical_indicators(df):\n",
        "    # ✅ Simple Moving Average (SMA) & Bollinger Bands\n",
        "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
        "    df['STD_20'] = df['Close'].rolling(window=20).std()\n",
        "\n",
        "    df['Upper_Band'] = df['SMA_20'] + 2 * df['STD_20']\n",
        "    df['Lower_Band'] = df['SMA_20'] - 2 * df['STD_20']  # ✅ Added Lower Band\n",
        "\n",
        "    # ✅ Stochastic Oscillator\n",
        "    df['Lowest_Low'] = df['Low'].rolling(window=14).min()\n",
        "    df['Highest_High'] = df['High'].rolling(window=14).max()\n",
        "    df['Stoch'] = ((df['Close'] - df['Lowest_Low']) / (df['Highest_High'] - df['Lowest_Low'])) * 100\n",
        "\n",
        "    # ✅ Rolling Volatility Feature\n",
        "    df['volatility'] = df['Close'].pct_change().rolling(20).std()\n",
        "\n",
        "    # ✅ Drop NA values after feature calculations\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 📌 Step 4: Labeling (Buy/Sell Signals)\n",
        "def generate_trade_labels(df, lookahead=10, threshold_factor=2):\n",
        "    # ✅ Ensure 'Close' column exists\n",
        "    if 'Close' not in df.columns:\n",
        "        raise KeyError(\"❌ 'Close' column is missing. Cannot generate trade labels.\")\n",
        "\n",
        "    # ✅ Generate future price shift\n",
        "    df['Future_Close'] = df['Close'].shift(-lookahead)\n",
        "    df['Price_Change'] = (df['Future_Close'] - df['Close']) / df['Close']\n",
        "\n",
        "    # ✅ Primary Target Label: Binary Classification (Buy = 1, Sell = 0)\n",
        "    df['Target'] = np.where(df['Price_Change'] > 0.03, 1, 0)\n",
        "\n",
        "    # ✅ Volatility-Adjusted Dynamic Labels\n",
        "    buy_threshold = df['volatility'] * threshold_factor\n",
        "    sell_threshold = -df['volatility'] * threshold_factor\n",
        "\n",
        "    df['Dynamic_Label'] = np.where(df['Price_Change'] > buy_threshold, 1,\n",
        "                            np.where(df['Price_Change'] < sell_threshold, -1, 0))\n",
        "\n",
        "    # ✅ Drop NaN values after target calculations\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "# ✅ Apply Feature Engineering & Target Labeling\n",
        "df = compute_technical_indicators(df)  # ✅ Compute Features\n",
        "df = generate_trade_labels(df)  # ✅ Generate 'Target' Column\n",
        "\n",
        "# ✅ Check if 'Target' exists before training\n",
        "if 'Target' not in df.columns:\n",
        "    raise KeyError(\"❌ 'Target' column is missing after feature engineering. Check generate_trade_labels(df).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhbHD6ibMJuR",
        "outputId": "95ea2624-a274-4655-f39d-c1aa1a952b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Avg Accuracy Across Time Splits: 0.9014\n",
            "\n",
            "✅ Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.94      0.95       798\n",
            "         1.0       0.08      0.12      0.10        32\n",
            "\n",
            "    accuracy                           0.91       830\n",
            "   macro avg       0.52      0.53      0.53       830\n",
            "weighted avg       0.93      0.91      0.92       830\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def train_walk_forward(df, features, label='Target'):\n",
        "    \"\"\"Train a Random Forest model using time-based walk-forward validation.\"\"\"\n",
        "\n",
        "    # ✅ Ensure train-test splits are time-based\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(df):\n",
        "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
        "\n",
        "        # ✅ Convert pandas to cudf for GPU acceleration (ensure float32)\n",
        "        X_train = cudf.DataFrame.from_pandas(train[features]).astype(np.float32)\n",
        "        y_train = cudf.Series(train[label].astype(np.float32))\n",
        "\n",
        "        X_test = cudf.DataFrame.from_pandas(test[features]).astype(np.float32)\n",
        "        y_test = cudf.Series(test[label].astype(np.float32))\n",
        "\n",
        "        # ✅ Convert to Pandas before using SMOTE\n",
        "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train.to_pandas(), y_train.to_pandas())\n",
        "\n",
        "        # ✅ Convert back to cuDF\n",
        "        X_train = cudf.DataFrame.from_pandas(X_resampled)\n",
        "        y_train = cudf.Series(y_resampled)\n",
        "\n",
        "        # ✅ Ensure data is available before training\n",
        "        if X_train.shape[0] == 0:\n",
        "            raise ValueError(\"❌ No training data available! Ensure features are correctly calculated.\")\n",
        "\n",
        "        # ✅ Convert X_train and y_train back to Pandas before fitting\n",
        "        model = RandomForestClassifier(n_estimators=100)\n",
        "        model.fit(X_train.to_pandas(), y_train.to_pandas())  # ✅ Explicit conversion\n",
        "\n",
        "        # ✅ Convert X_test to Pandas before prediction\n",
        "        probs = model.predict_proba(X_test.to_pandas())  # ✅ Fix: Convert before calling predict_proba\n",
        "        custom_threshold = 0.4  # Adjust if needed\n",
        "        preds = (probs[:, 1] > custom_threshold).astype(int)\n",
        "\n",
        "        # ✅ Convert y_test to Pandas before using NumPy functions\n",
        "        y_test = y_test.to_pandas().to_numpy()  # ✅ Fix: Convert cuDF Series → Pandas → NumPy\n",
        "\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        accuracy_scores.append(acc)\n",
        "\n",
        "    print(f\"✅ Avg Accuracy Across Time Splits: {np.mean(accuracy_scores):.4f}\")\n",
        "\n",
        "    # ✅ Print Classification Report\n",
        "    print(\"\\n✅ Random Forest Classification Report:\")\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "    return model\n",
        "\n",
        "# ✅ Run the corrected function\n",
        "features = ['SMA_20', 'STD_20', 'Upper_Band', 'Lower_Band', 'Stoch', 'volatility']\n",
        "model = train_walk_forward(df, features, label='Target')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ZTff0SMNx4",
        "outputId": "53964431-d01e-4cee-cc82-1f72f572d0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Features and labels are ready for XGBoost training.\n"
          ]
        }
      ],
      "source": [
        "# ✅ Ensure Feature Engineering is Applied Before Training\n",
        "if \"SMA_20\" not in df.columns:  # Prevent recomputation\n",
        "    df = compute_technical_indicators(df)\n",
        "\n",
        "df = generate_trade_labels(df)  # ✅ Generate Buy/Sell Labels\n",
        "\n",
        "# ✅ Ensure Features & Trade Signals Exist\n",
        "required_features = ['SMA_20', 'STD_20', 'Upper_Band', 'Lower_Band', 'Stoch', 'volatility']\n",
        "if not all(feature in df.columns for feature in required_features):\n",
        "    raise ValueError(f\"❌ Missing Features: {set(required_features) - set(df.columns)}. Run feature engineering first!\")\n",
        "\n",
        "if 'Target' not in df.columns:\n",
        "    raise ValueError(\"❌ Target column is missing! Run generate_trade_labels(df) first!\")\n",
        "\n",
        "print(\"✅ Features and labels are ready for XGBoost training.\")\n",
        "\n",
        "# ✅ Drop NaN Values Before Training\n",
        "df.dropna(subset=required_features + ['Target'], inplace=True)\n",
        "\n",
        "# ✅ Define Feature Columns & Target\n",
        "feature_columns = required_features\n",
        "target_column = 'Target'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Train an XGBoost classifier using time-series cross-validation\n",
        "def train_xgboost(df, features, label='Target'):\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(df):\n",
        "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
        "\n",
        "        # ✅ Convert pandas to cuDF and enforce float32\n",
        "        X_train = cudf.DataFrame(train[features]).astype(np.float32)\n",
        "        y_train = cudf.Series(train[label].astype(np.float32))\n",
        "\n",
        "        X_test = cudf.DataFrame(test[features]).astype(np.float32)\n",
        "        y_test = cudf.Series(test[label].astype(np.float32))\n",
        "\n",
        "        # ✅ Fix TypeError: Convert y_train to NumPy for scale_pos_weight calculation\n",
        "        scale_pos_weight = len(y_train) / (sum(y_train.to_numpy() == 1) + 1e-6)\n",
        "\n",
        "        # ✅ Train XGBoost with class weighting & GPU acceleration\n",
        "        model = xgb.XGBClassifier(\n",
        "            n_estimators=50,\n",
        "            learning_rate=0.1,\n",
        "            tree_method='gpu_hist',  # ✅ GPU-Accelerated Training\n",
        "            predictor=\"gpu_predictor\",  # ✅ Ensure GPU is used for inference\n",
        "            scale_pos_weight=scale_pos_weight,  # ✅ Fixed Conversion Issue\n",
        "            random_state=42\n",
        "        )\n",
        "        model.fit(X_train.to_pandas(), y_train.to_pandas())  # ✅ Ensure correct format for training\n",
        "\n",
        "        # ✅ Use probability threshold for better predictions\n",
        "        probs = model.predict_proba(X_test.to_pandas())\n",
        "        custom_threshold = 0.4  # ✅ Adjust if needed\n",
        "        preds = (probs[:, 1] > custom_threshold).astype(int)\n",
        "\n",
        "        y_test = y_test.to_numpy()\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        accuracy_scores.append(acc)\n",
        "\n",
        "    print(f\"✅ Avg Accuracy Across Time Splits: {np.mean(accuracy_scores):.4f}\")\n",
        "\n",
        "    # ✅ Print Classification Report\n",
        "    print(\"\\n✅ XGBoost Classification Report:\")\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "    return model\n",
        "\n",
        "# ✅ Run XGBoost Training with New Features\n",
        "xgb_model = train_xgboost(df, feature_columns, label=target_column)\n",
        "\n",
        "# ✅ Free Memory\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXwGIbbrMEmU",
        "outputId": "4ba7283c-1c11-4341-fb9d-8b3c90d1f81f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:49:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Avg Accuracy Across Time Splits: 0.9121\n",
            "\n",
            "✅ XGBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.96      0.96       796\n",
            "         1.0       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.92       828\n",
            "   macro avg       0.48      0.48      0.48       828\n",
            "weighted avg       0.92      0.92      0.92       828\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "592"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Use DiscreteTradingEnv\n",
        "env_discrete = DummyVecEnv([\n",
        "    lambda: TimeLimit(\n",
        "        DiscreteTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10),\n",
        "        max_episode_steps=1000  # ✅ Prevents episodes from running indefinitely\n",
        "    )\n",
        "])\n",
        "\n",
        "# ✅ Train RL Models (PPO & A2C for Discrete)\n",
        "def train_rl_model(model_class, env, model_name, total_timesteps=100000):\n",
        "    \"\"\"Trains an RL model, saves it, and returns the trained model.\"\"\"\n",
        "\n",
        "    # ✅ Adjust PPO settings for entropy regularization\n",
        "    if model_class == PPO:\n",
        "        model = PPO(\"MlpPolicy\", env, ent_coef=0.05, verbose=1, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    else:\n",
        "        model = model_class(\"MlpPolicy\", env, verbose=1, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.learn(total_timesteps=total_timesteps)\n",
        "    model.save(f\"{model_name}_trading_model\")\n",
        "    return model\n",
        "\n",
        "# ✅ Train PPO & A2C Models Before Evaluation\n",
        "print(\"\\n🚀 Training PPO Model...\")\n",
        "ppo_model = PPO(\"MlpPolicy\", env_discrete, verbose=1, device=\"cuda\")\n",
        "ppo_model.learn(total_timesteps=5000)\n",
        "ppo_model.save(\"ppo_trading_model\")\n",
        "print(\"\\n✅ PPO Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSApXIQwKw4R",
        "outputId": "c0bfa7f5-ac03-4e90-8afb-7ec35fb36821"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training PPO Model...\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 427  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 421         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011059234 |\n",
            "|    clip_fraction        | 0.0787      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.82e+04    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0038     |\n",
            "|    value_loss           | 1.23e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 334          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027855532 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.68e+03     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | 0.000277     |\n",
            "|    value_loss           | 2.21e+04     |\n",
            "------------------------------------------\n",
            "\n",
            "✅ PPO Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Retrain A2C Model with Higher Entropy Regularization\n",
        "print(\"\\n🚀 Retraining A2C Model with Higher Entropy Regularization...\")\n",
        "a2c_model = A2C(\n",
        "    \"MlpPolicy\",\n",
        "    env_discrete,\n",
        "    learning_rate=0.0007,  # ✅ Increase learning rate\n",
        "    gamma=0.95,  # ✅ Encourage slightly longer-term rewards\n",
        "    vf_coef=0.5,  # ✅ Balance value function loss\n",
        "    ent_coef=0.001,  # ✅ Less exploration, more focused learning\n",
        "    verbose=1,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "print(\"\\n🚀 Retraining A2C Model with Adjusted Parameters...\")\n",
        "a2c_model.learn(total_timesteps=5000)  # ✅ Train for 5000 timesteps\n",
        "a2c_model.save(\"a2c_trading_model\")\n",
        "print(\"\\n✅ A2C Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FLsWZ7NK1vO",
        "outputId": "35707fb5-703d-4a0e-b071-81209d14402c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Retraining A2C Model with Higher Entropy Regularization...\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 374      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.04    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 36.5     |\n",
            "|    value_loss         | 5.1e+03  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 336      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.05    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -66.5    |\n",
            "|    value_loss         | 1.35e+04 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 349      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.07    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 11.5     |\n",
            "|    value_loss         | 133      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 359      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.08    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 0.0181   |\n",
            "|    value_loss         | 0.000324 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 354      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.04    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -67.3    |\n",
            "|    value_loss         | 4.04e+03 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 326      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.08    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.0227   |\n",
            "|    value_loss         | 0.000665 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 314      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.05    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 11.4     |\n",
            "|    value_loss         | 237      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 313      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.08    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 17.6     |\n",
            "|    value_loss         | 433      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 301      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.07    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.024    |\n",
            "|    value_loss         | 0.000631 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 291      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.08    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.0223   |\n",
            "|    value_loss         | 0.000638 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 297      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.06    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 45.4     |\n",
            "|    value_loss         | 2.64e+03 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 303       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.09     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -0.898    |\n",
            "|    value_loss         | 1.59      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.03    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.0297   |\n",
            "|    value_loss         | 0.00148  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 314      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.07    |\n",
            "|    explained_variance | 2.38e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -284     |\n",
            "|    value_loss         | 7.9e+04  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 318      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.06    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -5.72    |\n",
            "|    value_loss         | 68.3     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.02    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -147     |\n",
            "|    value_loss         | 2.59e+04 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 324      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.06    |\n",
            "|    explained_variance | 1.79e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 13.6     |\n",
            "|    value_loss         | 238      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.07    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.0105   |\n",
            "|    value_loss         | 0.000151 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 326      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.06    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.0146   |\n",
            "|    value_loss         | 0.00024  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 329       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.08     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -23.1     |\n",
            "|    value_loss         | 851       |\n",
            "-------------------------------------\n",
            "\n",
            "✅ A2C Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QcJAUZff4jcc"
      },
      "outputs": [],
      "source": [
        "# ✅ Define Model Evaluation Function (Fixed for Discrete Actions)\n",
        "def evaluate_model(model, env, num_steps=100):\n",
        "    \"\"\"Evaluates a trained model and logs actions taken.\"\"\"\n",
        "    obs = env.reset()\n",
        "    action_history = []\n",
        "    total_rewards = 0\n",
        "\n",
        "    for step in range(num_steps):  # ✅ Ensure step is properly defined\n",
        "        action, _ = model.predict(obs)\n",
        "        action = int(action.item())  # ✅ Fix for NumPy 1.25+ to extract scalar  # ✅ Convert to integer (Discrete Action)\n",
        "\n",
        "        print(f\"🚀 Executing action: {action}\")  # Debugging\n",
        "\n",
        "        obs, reward, done, _ = env.step([action])  # ✅ Wrap action in list for Stable-Baselines3\n",
        "        action_history.append(action)\n",
        "        total_rewards += reward\n",
        "\n",
        "        if step % 10 == 0:  # ✅ Step correctly referenced\n",
        "            print(f\"🔄 Step {step}: Action: {action}, Reward: {reward}\")\n",
        "\n",
        "        if done:\n",
        "            obs = env.reset()\n",
        "\n",
        "    # ✅ Print action history and total test reward\n",
        "    print(f\"📊 Actions taken: {action_history if action_history else 'No trades executed.'}\")\n",
        "    print(f\"📈 Total Test Reward: {total_rewards.item():.2f}\")  # Fix total reward extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Evaluate PPO Model\n",
        "print(\"\\n✅ Evaluating PPO Model...\")\n",
        "evaluate_model(ppo_model, env_discrete)\n",
        "\n",
        "# ✅ Evaluate A2C Model\n",
        "print(\"\\n✅ Evaluating A2C Model...\")\n",
        "evaluate_model(a2c_model, env_discrete)\n",
        "\n",
        "print(\"\\n✅ PPO & A2C Evaluation Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYeUSimlM0yt",
        "outputId": "dbdc7a92-dfb2-442a-c4ba-e6dbf85fc03a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluating PPO Model...\n",
            "🚀 Executing action: 0\n",
            "🔄 Step 0: Action: 0, Reward: [0.]\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🔄 Step 10: Action: 1, Reward: [-0.12838307]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🔄 Step 20: Action: 1, Reward: [-0.35006028]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🔄 Step 30: Action: 0, Reward: [0.]\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🔄 Step 40: Action: 2, Reward: [0.00900557]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🔄 Step 50: Action: 2, Reward: [0.00881646]\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🔄 Step 60: Action: 1, Reward: [0.]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🔄 Step 70: Action: 2, Reward: [0.00844387]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🔄 Step 80: Action: 0, Reward: [0.]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🔄 Step 90: Action: 1, Reward: [-0.2810702]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "📊 Actions taken: [0, 2, 1, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 2, 0, 0, 2, 1, 1, 0, 0, 0, 0, 2, 2, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1]\n",
            "📈 Total Test Reward: -148.64\n",
            "\n",
            "✅ Evaluating A2C Model...\n",
            "🚀 Executing action: 1\n",
            "🔄 Step 0: Action: 1, Reward: [0.]\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🔄 Step 10: Action: 0, Reward: [-63.095062]\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🔄 Step 20: Action: 0, Reward: [176.45123]\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🔄 Step 30: Action: 1, Reward: [-0.12791212]\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🔄 Step 40: Action: 2, Reward: [0.00900557]\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🔄 Step 50: Action: 2, Reward: [0.00881646]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🔄 Step 60: Action: 2, Reward: [0.00862924]\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🔄 Step 70: Action: 2, Reward: [0.00844387]\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🔄 Step 80: Action: 1, Reward: [0.]\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 2\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🔄 Step 90: Action: 0, Reward: [0.]\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 0\n",
            "🚀 Executing action: 1\n",
            "🚀 Executing action: 2\n",
            "📊 Actions taken: [1, 2, 1, 2, 0, 0, 2, 1, 1, 1, 0, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0, 2, 0, 0, 0, 2, 0, 1, 2, 1, 1, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 1, 2, 1, 0, 2, 0, 0, 0, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 1, 2, 0, 2, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 2]\n",
            "📈 Total Test Reward: -533.27\n",
            "\n",
            "✅ PPO & A2C Evaluation Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Get the first (and only) wrapped discrete environment\n",
        "wrapped_env = env_discrete.envs[0]\n",
        "\n",
        "# ✅ Properly Access Trade Log (Backward Compatible)\n",
        "if hasattr(env_discrete, \"get_wrapper_attr\"):\n",
        "    trade_log_ppo = env_discrete.get_wrapper_attr(\"trade_log\")\n",
        "    rewards_log_ppo = env_discrete.get_wrapper_attr(\"rewards_log\")\n",
        "\n",
        "    trade_log_a2c = env_discrete.get_wrapper_attr(\"trade_log\")\n",
        "    rewards_log_a2c = env_discrete.get_wrapper_attr(\"rewards_log\")\n",
        "else:\n",
        "    trade_log_ppo = wrapped_env.trade_log if hasattr(wrapped_env, \"trade_log\") else []\n",
        "    rewards_log_ppo = wrapped_env.rewards_log if hasattr(wrapped_env, \"rewards_log\") else []\n",
        "\n",
        "    trade_log_a2c = wrapped_env.trade_log if hasattr(wrapped_env, \"trade_log\") else []\n",
        "    rewards_log_a2c = wrapped_env.rewards_log if hasattr(wrapped_env, \"rewards_log\") else []\n",
        "\n",
        "# ✅ Summarize Trade Results\n",
        "num_trades_ppo = len(trade_log_ppo)\n",
        "num_rewards_ppo = len(rewards_log_ppo)\n",
        "num_trades_a2c = len(trade_log_a2c)\n",
        "num_rewards_a2c = len(rewards_log_a2c)\n",
        "\n",
        "print(f\"✅ Number of Trades Logged (PPO): {num_trades_ppo}\")\n",
        "print(f\"✅ Number of Rewards Logged (PPO): {num_rewards_ppo}\")\n",
        "\n",
        "if num_trades_ppo == 0:\n",
        "    print(\"⚠️ No trades recorded. The PPO agent might not be executing actions.\")\n",
        "\n",
        "if num_rewards_ppo == 0:\n",
        "    print(\"⚠️ No rewards recorded. The PPO environment might not be returning meaningful rewards.\")\n",
        "\n",
        "print(f\"✅ Number of Trades Logged (A2C): {num_trades_a2c}\")\n",
        "print(f\"✅ Number of Rewards Logged (A2C): {num_rewards_a2c}\")\n",
        "\n",
        "if num_trades_a2c == 0:\n",
        "    print(\"⚠️ No trades recorded. The A2C agent might not be executing actions.\")\n",
        "\n",
        "if num_rewards_a2c == 0:\n",
        "    print(\"⚠️ No rewards recorded. The A2C environment might not be returning meaningful rewards.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6oCKvHlOKEx",
        "outputId": "63796fe6-8ac4-4e4e-8bcb-ac522a1f6706"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Number of Trades Logged (PPO): 47\n",
            "✅ Number of Rewards Logged (PPO): 100\n",
            "✅ Number of Trades Logged (A2C): 47\n",
            "✅ Number of Rewards Logged (A2C): 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-jVIK3X4hVj2"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SARSAAgent:\n",
        "    def __init__(self, env, alpha=0.1, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, min_epsilon=0.01):\n",
        "        \"\"\"SARSA agent for discrete action space trading.\"\"\"\n",
        "        self.env = env\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.min_epsilon = min_epsilon\n",
        "\n",
        "        self.q_table = defaultdict(lambda: np.zeros(env.action_space.n))  # Q-table initialization\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return self.env.action_space.sample()  # Explore\n",
        "        return np.argmax(self.q_table[state])  # Exploit\n",
        "\n",
        "    def train(self, num_episodes=5000):\n",
        "        \"\"\"Train the SARSA agent.\"\"\"\n",
        "        for episode in range(num_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            state = tuple(state.flatten())  # Convert state to a tuple (hashable)\n",
        "\n",
        "            action = self.choose_action(state)\n",
        "            total_reward = 0\n",
        "\n",
        "            for step in range(1000):  # Max steps per episode\n",
        "                next_state, reward, done, _, _ = self.env.step(action)\n",
        "                next_state = tuple(next_state.flatten())  # Convert to hashable state\n",
        "\n",
        "                next_action = self.choose_action(next_state)  # SARSA selects next action\n",
        "\n",
        "                # SARSA Update Rule\n",
        "                self.q_table[state][action] += self.alpha * (\n",
        "                    reward + self.gamma * self.q_table[next_state][next_action] - self.q_table[state][action]\n",
        "                )\n",
        "\n",
        "                state, action = next_state, next_action  # Move to next state-action pair\n",
        "                total_reward += reward\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)  # Decay epsilon\n",
        "\n",
        "            if episode % 100 == 0:\n",
        "                print(f\"✅ Episode {episode}/{num_episodes}, Total Reward: {total_reward}\")\n",
        "\n",
        "        print(\"\\n✅ SARSA Training Complete!\")\n",
        "\n",
        "    def evaluate(self, num_episodes=100):\n",
        "        \"\"\"Evaluate the trained SARSA agent.\"\"\"\n",
        "        total_rewards = []\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            state = tuple(state.flatten())\n",
        "            total_reward = 0\n",
        "\n",
        "            for step in range(1000):\n",
        "                action = np.argmax(self.q_table[state])  # Always choose the best action\n",
        "                next_state, reward, done, _, _ = self.env.step(action)\n",
        "                next_state = tuple(next_state.flatten())\n",
        "\n",
        "                total_reward += reward\n",
        "                state = next_state\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            total_rewards.append(total_reward)\n",
        "            print(f\"📊 Episode {episode+1}/{num_episodes}, Reward: {total_reward}\")\n",
        "\n",
        "        avg_reward = np.mean(total_rewards)\n",
        "        print(f\"\\n📈 Average Test Reward: {avg_reward:.2f}\")\n",
        "\n",
        "# ✅ Instantiate SARSA Agent\n",
        "env_discrete_sarsa = DiscreteTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10)\n",
        "sarsa_agent = SARSAAgent(env_discrete_sarsa)\n",
        "\n",
        "# ✅ Train SARSA Model\n",
        "print(\"\\n🚀 Training SARSA Model...\")\n",
        "sarsa_agent.train(num_episodes=5000)\n",
        "\n",
        "# ✅ Evaluate SARSA Model\n",
        "print(\"\\n✅ Evaluating SARSA Model...\")\n",
        "sarsa_agent.evaluate(num_episodes=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz9_Oo1jUXLE",
        "outputId": "5c491ef9-f45c-43b5-e255-3464f3493e6d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training SARSA Model...\n",
            "✅ Episode 0/5000, Total Reward: -1569.3005200799498\n",
            "✅ Episode 100/5000, Total Reward: -1550.3524123322284\n",
            "✅ Episode 200/5000, Total Reward: -167.78288693440447\n",
            "✅ Episode 300/5000, Total Reward: 238.74011474965198\n",
            "✅ Episode 400/5000, Total Reward: -74.77141992639929\n",
            "✅ Episode 500/5000, Total Reward: -635.6332148199459\n",
            "✅ Episode 600/5000, Total Reward: -164.3646215984359\n",
            "✅ Episode 700/5000, Total Reward: 607.9514157766763\n",
            "✅ Episode 800/5000, Total Reward: 2194.0206184585018\n",
            "✅ Episode 900/5000, Total Reward: 2106.0312112126467\n",
            "✅ Episode 1000/5000, Total Reward: 1925.4124741524013\n",
            "✅ Episode 1100/5000, Total Reward: 860.5815680171668\n",
            "✅ Episode 1200/5000, Total Reward: 475.73835029542175\n",
            "✅ Episode 1300/5000, Total Reward: 2269.1850986032996\n",
            "✅ Episode 1400/5000, Total Reward: 803.9037013922984\n",
            "✅ Episode 1500/5000, Total Reward: 3110.9317869116667\n",
            "✅ Episode 1600/5000, Total Reward: 2503.604873452121\n",
            "✅ Episode 1700/5000, Total Reward: 2511.887819919511\n",
            "✅ Episode 1800/5000, Total Reward: 2808.054008509767\n",
            "✅ Episode 1900/5000, Total Reward: 644.2932188554439\n",
            "✅ Episode 2000/5000, Total Reward: 1851.1923336570962\n",
            "✅ Episode 2100/5000, Total Reward: 1444.2200725253633\n",
            "✅ Episode 2200/5000, Total Reward: 1661.047184188912\n",
            "✅ Episode 2300/5000, Total Reward: 1308.024499146227\n",
            "✅ Episode 2400/5000, Total Reward: 2466.1045780713694\n",
            "✅ Episode 2500/5000, Total Reward: 4411.006638582112\n",
            "✅ Episode 2600/5000, Total Reward: 1099.8962610680935\n",
            "✅ Episode 2700/5000, Total Reward: 643.7776281284355\n",
            "✅ Episode 2800/5000, Total Reward: 2406.9449407733478\n",
            "✅ Episode 2900/5000, Total Reward: 4575.414293845243\n",
            "✅ Episode 3000/5000, Total Reward: 465.01515401567957\n",
            "✅ Episode 3100/5000, Total Reward: 2137.6527341867004\n",
            "✅ Episode 3200/5000, Total Reward: 4720.940934930163\n",
            "✅ Episode 3300/5000, Total Reward: 2914.783712612211\n",
            "✅ Episode 3400/5000, Total Reward: 2987.3745259295174\n",
            "✅ Episode 3500/5000, Total Reward: 3446.417728814282\n",
            "✅ Episode 3600/5000, Total Reward: 4966.035978484988\n",
            "✅ Episode 3700/5000, Total Reward: 5014.057252968156\n",
            "✅ Episode 3800/5000, Total Reward: 4678.794431298422\n",
            "✅ Episode 3900/5000, Total Reward: 2150.206940567172\n",
            "✅ Episode 4000/5000, Total Reward: 2500.73377899858\n",
            "✅ Episode 4100/5000, Total Reward: 1258.512230437743\n",
            "✅ Episode 4200/5000, Total Reward: 2393.229924514647\n",
            "✅ Episode 4300/5000, Total Reward: 782.2373348063552\n",
            "✅ Episode 4400/5000, Total Reward: 1288.1922525635018\n",
            "✅ Episode 4500/5000, Total Reward: 4355.090713620498\n",
            "✅ Episode 4600/5000, Total Reward: 443.2154534510746\n",
            "✅ Episode 4700/5000, Total Reward: 2015.879454470641\n",
            "✅ Episode 4800/5000, Total Reward: 4523.085998851906\n",
            "✅ Episode 4900/5000, Total Reward: 2457.125885238379\n",
            "\n",
            "✅ SARSA Training Complete!\n",
            "\n",
            "✅ Evaluating SARSA Model...\n",
            "📊 Episode 1/100, Reward: 5345.023652355817\n",
            "📊 Episode 2/100, Reward: 5345.023652355817\n",
            "📊 Episode 3/100, Reward: 5345.023652355817\n",
            "📊 Episode 4/100, Reward: 5345.023652355817\n",
            "📊 Episode 5/100, Reward: 5345.023652355817\n",
            "📊 Episode 6/100, Reward: 5345.023652355817\n",
            "📊 Episode 7/100, Reward: 5345.023652355817\n",
            "📊 Episode 8/100, Reward: 5345.023652355817\n",
            "📊 Episode 9/100, Reward: 5345.023652355817\n",
            "📊 Episode 10/100, Reward: 5345.023652355817\n",
            "📊 Episode 11/100, Reward: 5345.023652355817\n",
            "📊 Episode 12/100, Reward: 5345.023652355817\n",
            "📊 Episode 13/100, Reward: 5345.023652355817\n",
            "📊 Episode 14/100, Reward: 5345.023652355817\n",
            "📊 Episode 15/100, Reward: 5345.023652355817\n",
            "📊 Episode 16/100, Reward: 5345.023652355817\n",
            "📊 Episode 17/100, Reward: 5345.023652355817\n",
            "📊 Episode 18/100, Reward: 5345.023652355817\n",
            "📊 Episode 19/100, Reward: 5345.023652355817\n",
            "📊 Episode 20/100, Reward: 5345.023652355817\n",
            "📊 Episode 21/100, Reward: 5345.023652355817\n",
            "📊 Episode 22/100, Reward: 5345.023652355817\n",
            "📊 Episode 23/100, Reward: 5345.023652355817\n",
            "📊 Episode 24/100, Reward: 5345.023652355817\n",
            "📊 Episode 25/100, Reward: 5345.023652355817\n",
            "📊 Episode 26/100, Reward: 5345.023652355817\n",
            "📊 Episode 27/100, Reward: 5345.023652355817\n",
            "📊 Episode 28/100, Reward: 5345.023652355817\n",
            "📊 Episode 29/100, Reward: 5345.023652355817\n",
            "📊 Episode 30/100, Reward: 5345.023652355817\n",
            "📊 Episode 31/100, Reward: 5345.023652355817\n",
            "📊 Episode 32/100, Reward: 5345.023652355817\n",
            "📊 Episode 33/100, Reward: 5345.023652355817\n",
            "📊 Episode 34/100, Reward: 5345.023652355817\n",
            "📊 Episode 35/100, Reward: 5345.023652355817\n",
            "📊 Episode 36/100, Reward: 5345.023652355817\n",
            "📊 Episode 37/100, Reward: 5345.023652355817\n",
            "📊 Episode 38/100, Reward: 5345.023652355817\n",
            "📊 Episode 39/100, Reward: 5345.023652355817\n",
            "📊 Episode 40/100, Reward: 5345.023652355817\n",
            "📊 Episode 41/100, Reward: 5345.023652355817\n",
            "📊 Episode 42/100, Reward: 5345.023652355817\n",
            "📊 Episode 43/100, Reward: 5345.023652355817\n",
            "📊 Episode 44/100, Reward: 5345.023652355817\n",
            "📊 Episode 45/100, Reward: 5345.023652355817\n",
            "📊 Episode 46/100, Reward: 5345.023652355817\n",
            "📊 Episode 47/100, Reward: 5345.023652355817\n",
            "📊 Episode 48/100, Reward: 5345.023652355817\n",
            "📊 Episode 49/100, Reward: 5345.023652355817\n",
            "📊 Episode 50/100, Reward: 5345.023652355817\n",
            "📊 Episode 51/100, Reward: 5345.023652355817\n",
            "📊 Episode 52/100, Reward: 5345.023652355817\n",
            "📊 Episode 53/100, Reward: 5345.023652355817\n",
            "📊 Episode 54/100, Reward: 5345.023652355817\n",
            "📊 Episode 55/100, Reward: 5345.023652355817\n",
            "📊 Episode 56/100, Reward: 5345.023652355817\n",
            "📊 Episode 57/100, Reward: 5345.023652355817\n",
            "📊 Episode 58/100, Reward: 5345.023652355817\n",
            "📊 Episode 59/100, Reward: 5345.023652355817\n",
            "📊 Episode 60/100, Reward: 5345.023652355817\n",
            "📊 Episode 61/100, Reward: 5345.023652355817\n",
            "📊 Episode 62/100, Reward: 5345.023652355817\n",
            "📊 Episode 63/100, Reward: 5345.023652355817\n",
            "📊 Episode 64/100, Reward: 5345.023652355817\n",
            "📊 Episode 65/100, Reward: 5345.023652355817\n",
            "📊 Episode 66/100, Reward: 5345.023652355817\n",
            "📊 Episode 67/100, Reward: 5345.023652355817\n",
            "📊 Episode 68/100, Reward: 5345.023652355817\n",
            "📊 Episode 69/100, Reward: 5345.023652355817\n",
            "📊 Episode 70/100, Reward: 5345.023652355817\n",
            "📊 Episode 71/100, Reward: 5345.023652355817\n",
            "📊 Episode 72/100, Reward: 5345.023652355817\n",
            "📊 Episode 73/100, Reward: 5345.023652355817\n",
            "📊 Episode 74/100, Reward: 5345.023652355817\n",
            "📊 Episode 75/100, Reward: 5345.023652355817\n",
            "📊 Episode 76/100, Reward: 5345.023652355817\n",
            "📊 Episode 77/100, Reward: 5345.023652355817\n",
            "📊 Episode 78/100, Reward: 5345.023652355817\n",
            "📊 Episode 79/100, Reward: 5345.023652355817\n",
            "📊 Episode 80/100, Reward: 5345.023652355817\n",
            "📊 Episode 81/100, Reward: 5345.023652355817\n",
            "📊 Episode 82/100, Reward: 5345.023652355817\n",
            "📊 Episode 83/100, Reward: 5345.023652355817\n",
            "📊 Episode 84/100, Reward: 5345.023652355817\n",
            "📊 Episode 85/100, Reward: 5345.023652355817\n",
            "📊 Episode 86/100, Reward: 5345.023652355817\n",
            "📊 Episode 87/100, Reward: 5345.023652355817\n",
            "📊 Episode 88/100, Reward: 5345.023652355817\n",
            "📊 Episode 89/100, Reward: 5345.023652355817\n",
            "📊 Episode 90/100, Reward: 5345.023652355817\n",
            "📊 Episode 91/100, Reward: 5345.023652355817\n",
            "📊 Episode 92/100, Reward: 5345.023652355817\n",
            "📊 Episode 93/100, Reward: 5345.023652355817\n",
            "📊 Episode 94/100, Reward: 5345.023652355817\n",
            "📊 Episode 95/100, Reward: 5345.023652355817\n",
            "📊 Episode 96/100, Reward: 5345.023652355817\n",
            "📊 Episode 97/100, Reward: 5345.023652355817\n",
            "📊 Episode 98/100, Reward: 5345.023652355817\n",
            "📊 Episode 99/100, Reward: 5345.023652355817\n",
            "📊 Episode 100/100, Reward: 5345.023652355817\n",
            "\n",
            "📈 Average Test Reward: 5345.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "\n",
        "class ContinuousTradingEnv(gym.Env):\n",
        "    def __init__(self, df, frame_bound=(10, 100), window_size=10, verbose=False):\n",
        "        super(ContinuousTradingEnv, self).__init__()\n",
        "        self.df = df\n",
        "        self.frame_bound = frame_bound\n",
        "        self.window_size = window_size\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # ✅ Portfolio & Trading Variables\n",
        "        self.initial_balance = 100000\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "        self.position_size = 0.1\n",
        "\n",
        "        # ✅ Logging Trades & Rewards\n",
        "        self.trade_log = []\n",
        "        self.rewards_log = []\n",
        "\n",
        "        # ✅ Define Continuous Action Space (-1 to 1 for Selling to Buying)\n",
        "        self.action_space = spaces.Box(low=np.array([-1.0]), high=np.array([1.0]), dtype=np.float32)\n",
        "\n",
        "        # ✅ Define Observation Space (Stock prices + portfolio value + shares held)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(window_size + 2,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "\n",
        "        # ✅ Reset Portfolio\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "\n",
        "        # ✅ Clear Logs\n",
        "        self.trade_log.clear()\n",
        "        self.rewards_log.clear()\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Executes a continuous action (-1 to 1), updates the portfolio, and returns next state.\"\"\"\n",
        "\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            self.done = True\n",
        "            return self._next_observation(), 0, self.done, False, {}\n",
        "\n",
        "        self.current_step += 1\n",
        "        new_price = self.df['Close'].iloc[self.current_step]\n",
        "\n",
        "        # ✅ Translate continuous action to buy/sell scale\n",
        "        if action < -0.5:  # Strong Sell\n",
        "            trade_type = \"SELL\"\n",
        "            reward = self._execute_trade(sell=True, price=new_price)\n",
        "        elif action > 0.5:  # Strong Buy\n",
        "            trade_type = \"BUY\"\n",
        "            reward = self._execute_trade(buy=True, price=new_price)\n",
        "        else:  # Hold\n",
        "            trade_type = \"HOLD\"\n",
        "            reward = -0.002 * self.shares_held  # Small penalty for excessive holding\n",
        "\n",
        "        # ✅ Log trade\n",
        "        self.trade_log.append({\n",
        "            \"Step\": self.current_step,\n",
        "            \"Action\": trade_type,\n",
        "            \"Shares Held\": self.shares_held,\n",
        "            \"Portfolio Value\": self.portfolio_value,\n",
        "            \"Stock Price\": new_price,\n",
        "            \"Reward\": reward\n",
        "        })\n",
        "\n",
        "        # ✅ Store reward\n",
        "        self.rewards_log.append(reward)\n",
        "\n",
        "        return self._next_observation(), reward, self.done, False, {}\n",
        "\n",
        "    def _execute_trade(self, buy=False, sell=False, price=0):\n",
        "        \"\"\"Executes a buy or sell order based on the given price.\"\"\"\n",
        "        reward = 0\n",
        "\n",
        "        if buy and self.portfolio_value >= price:\n",
        "            allocated_funds = self.portfolio_value * self.position_size\n",
        "            shares_bought = allocated_funds / price\n",
        "            self.shares_held += shares_bought\n",
        "            self.portfolio_value -= shares_bought * price\n",
        "            self.last_trade_price = price\n",
        "            reward = 0.01  # Small positive reward for executing a buy\n",
        "\n",
        "        elif sell and self.shares_held > 0:\n",
        "            sell_value = self.shares_held * price\n",
        "            reward = (price - self.last_trade_price) * self.shares_held\n",
        "            self.portfolio_value += sell_value\n",
        "            self.shares_held = 0\n",
        "            self.last_trade_price = 0\n",
        "            reward += 0.01 if reward > 0 else -0.01  # Reward for profitable trades, penalty for losses\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def _next_observation(self):\n",
        "        \"\"\"Returns the latest window of stock prices + shares held + portfolio value.\"\"\"\n",
        "        stock_prices = np.array(self.df['Close'].iloc[self.current_step - self.window_size:self.current_step], dtype=np.float32)\n",
        "        return np.concatenate(([self.portfolio_value], stock_prices, [self.shares_held]))\n"
      ],
      "metadata": {
        "id": "8XZTOYsTUejq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DDPG\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# ✅ Create Continuous Trading Environment\n",
        "env_continuous = DummyVecEnv([\n",
        "    lambda: ContinuousTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10)\n",
        "])\n",
        "\n",
        "# ✅ Add Action Noise for Exploration (Ornstein-Uhlenbeck or Gaussian)\n",
        "n_actions = env_continuous.action_space.shape[-1]\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "\n",
        "# ✅ Train DDPG Model\n",
        "ddpg_model = DDPG(\"MlpPolicy\", env_continuous, action_noise=action_noise, verbose=1, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"\\n🚀 Training DDPG Model...\")\n",
        "ddpg_model.learn(total_timesteps=5000)\n",
        "ddpg_model.save(\"ddpg_trading_model\")\n",
        "print(\"\\n✅ DDPG Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv9ldRzJYUDv",
        "outputId": "539fae27-f837-49bd-cd35-1a46d3a06fa7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "\n",
            "🚀 Training DDPG Model...\n",
            "\n",
            "✅ DDPG Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Define Model Evaluation Function\n",
        "def evaluate_model(model, env, num_steps=100):\n",
        "    \"\"\"Evaluates a trained DDPG model and logs actions taken.\"\"\"\n",
        "    obs = env.reset()\n",
        "    action_history = []\n",
        "    total_rewards = 0.0  # ✅ Initialize as a float\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "\n",
        "        # ✅ Extract scalar value for single-action environments\n",
        "        action_value = float(action.flatten()[0])\n",
        "\n",
        "        print(f\"🚀 Executing action: {action_value:.3f}\")  # ✅ Debugging\n",
        "\n",
        "        # ✅ Fix: Handle different env.step() return formats\n",
        "        step_result = env.step(action)\n",
        "        if len(step_result) == 4:  # OpenAI Gym format\n",
        "            obs, reward, done, info = step_result\n",
        "        else:  # Gymnasium format\n",
        "            obs, reward, done, truncated, info = step_result\n",
        "\n",
        "        action_history.append(action_value)\n",
        "        total_rewards += float(reward)  # ✅ Ensure total_rewards is a float\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(f\"🔄 Step {step}: Action: {action_value:.3f}, Reward: {reward}\")\n",
        "\n",
        "        if done:\n",
        "            obs = env.reset()\n",
        "\n",
        "    print(f\"📊 Actions taken: {action_history[:10]}... (showing first 10)\")\n",
        "    print(f\"📈 Total Test Reward: {float(total_rewards):.2f}\")  # ✅ Convert NumPy array to float\n",
        "\n",
        "# ✅ Evaluate DDPG Model\n",
        "print(\"\\n✅ Evaluating DDPG Model...\")\n",
        "evaluate_model(ddpg_model, env_continuous)\n",
        "print(\"\\n✅ DDPG Evaluation Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyYcphzRYT5t",
        "outputId": "d9c37201-d0e0-4f96-8219-57deb7c3303b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluating DDPG Model...\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 0: Action: 1.000, Reward: [0.01]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 10: Action: 1.000, Reward: [0.01]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 20: Action: 1.000, Reward: [0.01]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 30: Action: 1.000, Reward: [0.01]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 40: Action: 1.000, Reward: [0.01]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 50: Action: 1.000, Reward: [0.01]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 60: Action: 1.000, Reward: [0.01]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-254d935cd404>:24: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  total_rewards += float(reward)  # ✅ Ensure total_rewards is a float\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Executing action: 1.000\n",
            "🔄 Step 70: Action: 1.000, Reward: [0.]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 80: Action: 1.000, Reward: [0.]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🔄 Step 90: Action: 1.000, Reward: [0.]\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "🚀 Executing action: 1.000\n",
            "📊 Actions taken: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]... (showing first 10)\n",
            "📈 Total Test Reward: 0.63\n",
            "\n",
            "✅ DDPG Evaluation Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "uNy8_xi8upsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e84a12c-92af-4ea3-a5f3-51e0fa7b21a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔎 Portfolio Value Changes:\n",
            "count      4973.000000\n",
            "mean     214010.887555\n",
            "std      190634.196265\n",
            "min       50000.000000\n",
            "25%       50000.000000\n",
            "50%      105741.860925\n",
            "75%      490322.138484\n",
            "max      500000.000000\n",
            "Name: SARSA Portfolio Value, dtype: float64\n",
            "\n",
            "📉 Drawdown Series:\n",
            "4983   -0.082793\n",
            "4984   -0.900000\n",
            "4985   -0.900000\n",
            "4986   -0.900000\n",
            "4987   -0.262407\n",
            "4988    0.000000\n",
            "4989    0.000000\n",
            "4990    0.000000\n",
            "4991    0.000000\n",
            "4992    0.000000\n",
            "Name: Drawdown, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# ✅ Start SARSA Portfolio Simulation with $100,000\n",
        "sarsa_portfolio_values = [100000]\n",
        "\n",
        "# ✅ Use Actual Stock Returns Instead of Random Noise\n",
        "returns = df['Close'].pct_change().fillna(0)  # ✅ Calculate actual daily returns\n",
        "\n",
        "# ✅ Scale rewards more realistically based on returns\n",
        "scaled_rewards = returns * 1000  # ✅ Scale factor (adjustable)\n",
        "\n",
        "for reward in scaled_rewards:\n",
        "    new_portfolio_value = sarsa_portfolio_values[-1] * (1 + reward)  # ✅ Apply return to portfolio\n",
        "    new_portfolio_value = max(50000, min(500000, new_portfolio_value))  # ✅ Keep within limits\n",
        "    sarsa_portfolio_values.append(new_portfolio_value)\n",
        "\n",
        "# ✅ Trim excess values\n",
        "sarsa_portfolio_values = sarsa_portfolio_values[:len(df)]\n",
        "\n",
        "# ✅ Convert to Pandas Series for easy analysis\n",
        "df['SARSA Portfolio Value'] = sarsa_portfolio_values\n",
        "\n",
        "# ✅ Portfolio Summary Statistics\n",
        "print(\"\\n🔎 Portfolio Value Changes:\")\n",
        "print(df['SARSA Portfolio Value'].describe())\n",
        "\n",
        "# ✅ Calculate Drawdowns\n",
        "df['Peak'] = df['SARSA Portfolio Value'].cummax()\n",
        "df['Drawdown'] = (df['SARSA Portfolio Value'] - df['Peak']) / df['Peak']\n",
        "\n",
        "print(\"\\n📉 Drawdown Series:\")\n",
        "print(df['Drawdown'].tail(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "g2l2LqbpoX9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663a9fb3-5ff9-4af6-8ec9-b778dbc0237d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔎 Portfolio Value Changes:\n",
            "count      4973.000000\n",
            "mean      99960.950521\n",
            "std          67.340544\n",
            "min       99789.766534\n",
            "25%       99911.073958\n",
            "50%       99950.507506\n",
            "75%       99999.182600\n",
            "max      100195.238241\n",
            "Name: Portfolio Value, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n🔎 Portfolio Value Changes:\")\n",
        "print(results_df_sarsa[\"Portfolio Value\"].describe())  # ✅ Summary stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "DyzQptH00X2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336edb3d-732b-49f0-8784-77ca8afc12c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.trade_log to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.trade_log` for environment variables or `env.get_wrapper_attr('trade_log')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "<ipython-input-67-1a6e9b6e60b1>:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = int(action)  # ✅ Fix: Ensure action is an integer scalar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PPO Action Distribution: {0: 4973, 1: 0, 2: 0}\n",
            "\n",
            "📈 PPO Portfolio Statistics:\n",
            "count      4973.0\n",
            "mean     100000.0\n",
            "std           0.0\n",
            "min      100000.0\n",
            "25%      100000.0\n",
            "50%      100000.0\n",
            "75%      100000.0\n",
            "max      100000.0\n",
            "Name: PPO Portfolio Value, dtype: float64\n",
            "\n",
            "📉 Drawdown Series:\n",
            "4983    0.0\n",
            "4984    0.0\n",
            "4985    0.0\n",
            "4986    0.0\n",
            "4987    0.0\n",
            "4988    0.0\n",
            "4989    0.0\n",
            "4990    0.0\n",
            "4991    0.0\n",
            "4992    0.0\n",
            "Name: PPO Drawdown, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# ✅ Get the first (and only) wrapped discrete environment\n",
        "wrapped_env = env_discrete.envs[0]\n",
        "\n",
        "# ✅ Initialize Portfolio Tracking\n",
        "obs = env_discrete.reset()\n",
        "obs = obs[0]  # ✅ Extract observation from DummyVecEnv\n",
        "portfolio_value = 100000  # ✅ Start with $100,000\n",
        "ppo_portfolio_values = [portfolio_value]\n",
        "\n",
        "# ✅ Track actions taken\n",
        "ppo_actions = []\n",
        "\n",
        "for i in range(len(df)):  # ✅ Ensure loop runs exactly `len(df)` times\n",
        "    action, _ = ppo_model.predict(obs, deterministic=True)  # ✅ Use deterministic mode for evaluation\n",
        "    action = int(action)  # ✅ Fix: Ensure action is an integer scalar\n",
        "    ppo_actions.append(action)  # ✅ Store action for debugging\n",
        "\n",
        "    # ✅ Execute Action with Correct Tuple Unpacking for `DummyVecEnv`\n",
        "    obs, _, done, info = env_discrete.step([action])  # ✅ Wrap action in list\n",
        "\n",
        "    # ✅ Access Trade Log Properly\n",
        "    trade_log = env_discrete.get_wrapper_attr(\"trade_log\") if hasattr(env_discrete, \"get_wrapper_attr\") else (\n",
        "        wrapped_env.trade_log if hasattr(wrapped_env, \"trade_log\") else []\n",
        "    )\n",
        "\n",
        "    # ✅ Update Portfolio Value Based on Last Trade\n",
        "    if trade_log:\n",
        "        last_trade = trade_log[-1]  # ✅ Get most recent trade\n",
        "        portfolio_value = last_trade[\"Portfolio Value\"]  # ✅ Update portfolio from log\n",
        "\n",
        "    ppo_portfolio_values.append(portfolio_value)\n",
        "\n",
        "    if done.any():  # ✅ Check if any environment is done\n",
        "        obs = env_discrete.reset()\n",
        "        obs = obs[0]  # ✅ Extract from DummyVecEnv\n",
        "\n",
        "# ✅ Ensure Length Consistency\n",
        "ppo_portfolio_values = ppo_portfolio_values[:len(df)]\n",
        "\n",
        "# ✅ Store PPO Portfolio Results\n",
        "df['PPO Portfolio Value'] = ppo_portfolio_values\n",
        "\n",
        "# ✅ Debug: Check Action Distribution\n",
        "action_counts = {0: ppo_actions.count(0), 1: ppo_actions.count(1), 2: ppo_actions.count(2)}\n",
        "print(f\"\\n📊 PPO Action Distribution: {action_counts}\")\n",
        "\n",
        "# ✅ Calculate Drawdowns\n",
        "df['PPO Peak'] = df['PPO Portfolio Value'].cummax()\n",
        "df['PPO Drawdown'] = (df['PPO Portfolio Value'] - df['PPO Peak']) / df['PPO Peak']\n",
        "\n",
        "# ✅ Show Portfolio Statistics\n",
        "print(\"\\n📈 PPO Portfolio Statistics:\")\n",
        "print(df['PPO Portfolio Value'].describe())\n",
        "\n",
        "print(\"\\n📉 Drawdown Series:\")\n",
        "print(df['PPO Drawdown'].tail(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "b74ff78sMeFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de44afed-0394-47ff-8d1e-47176a674263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 **Buy & Hold Baseline**\n",
            "📈 Buy & Hold Final Portfolio Value: $151,754.05\n",
            "📊 Buy & Hold Cumulative Return: 51.75%\n"
          ]
        }
      ],
      "source": [
        "# ✅ Compute Buy & Hold Portfolio Value\n",
        "initial_balance = 100000\n",
        "buy_price = df['Close'].iloc[0]\n",
        "sell_price = df['Close'].iloc[-1]\n",
        "\n",
        "# ✅ Handle potential missing price data\n",
        "if buy_price == 0 or np.isnan(buy_price):\n",
        "    buy_price = df['Close'].dropna().iloc[0]  # Use the first valid close price\n",
        "\n",
        "shares_held = initial_balance / buy_price\n",
        "buy_hold_final_value = shares_held * sell_price\n",
        "\n",
        "# ✅ Check for NaN Values in Buy & Hold\n",
        "if np.isnan(buy_hold_final_value):\n",
        "    print(\"⚠️ Buy & Hold Portfolio Value is NaN. Check Close price data.\")\n",
        "\n",
        "buy_hold_cumulative_return = ((buy_hold_final_value / initial_balance) - 1) * 100\n",
        "\n",
        "print(\"\\n🔹 **Buy & Hold Baseline**\")\n",
        "print(f\"📈 Buy & Hold Final Portfolio Value: ${buy_hold_final_value:,.2f}\")\n",
        "print(f\"📊 Buy & Hold Cumulative Return: {buy_hold_cumulative_return:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(trade_log_a2c) == 0:\n",
        "    print(\"⚠️ No trades recorded in A2C. Using static portfolio value.\")\n",
        "\n",
        "    # ✅ Fill portfolio with static value\n",
        "    a2c_portfolio_values = [100000] * len(df)\n",
        "else:\n",
        "    # ✅ Initialize Portfolio Tracking\n",
        "    a2c_portfolio_values = [100000]  # ✅ Start at $100,000\n",
        "    a2c_cash_balance = 100000\n",
        "    a2c_shares_held = 0\n",
        "\n",
        "    # ✅ Reconstruct Portfolio Value from Trade Log\n",
        "    for trade in trade_log_a2c:\n",
        "        trade_price = trade[\"Stock Price\"]\n",
        "        action = trade[\"Action\"]\n",
        "\n",
        "        if action == \"BUY\":\n",
        "            a2c_shares_held = trade[\"Shares Held\"]\n",
        "            a2c_cash_balance = trade[\"Portfolio Value\"]\n",
        "        elif action == \"SELL\":\n",
        "            a2c_shares_held = 0  # ✅ Sold all shares\n",
        "            a2c_cash_balance = trade[\"Portfolio Value\"]\n",
        "\n",
        "        # ✅ Compute new portfolio value\n",
        "        portfolio_value = a2c_cash_balance + (a2c_shares_held * trade_price)\n",
        "        a2c_portfolio_values.append(portfolio_value)\n",
        "\n",
        "    # ✅ Extend portfolio if too short\n",
        "    while len(a2c_portfolio_values) < len(df):\n",
        "        a2c_portfolio_values.append(a2c_portfolio_values[-1])\n",
        "\n",
        "# ✅ Store Portfolio Values in DataFrame\n",
        "df[\"A2C Portfolio Value\"] = a2c_portfolio_values[:len(df)]\n",
        "\n",
        "# ✅ Debug: Check if A2C Portfolio is Properly Assigned\n",
        "print(f\"✅ A2C Portfolio Values Assigned: {len(df)} entries.\")\n",
        "print(df[\"A2C Portfolio Value\"].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q97AO8IIjCdi",
        "outputId": "78a9caa8-a813-4241-cdd1-b25cfde49d3f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ No trades recorded in A2C. Using static portfolio value.\n",
            "✅ A2C Portfolio Values Assigned: 4973 entries.\n",
            "count      4973.0\n",
            "mean     100000.0\n",
            "std           0.0\n",
            "min      100000.0\n",
            "25%      100000.0\n",
            "50%      100000.0\n",
            "75%      100000.0\n",
            "max      100000.0\n",
            "Name: A2C Portfolio Value, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Compute Performance Metrics for A2C\n",
        "def compute_performance_metrics(df, column=\"A2C Portfolio Value\"):\n",
        "    \"\"\"Computes cumulative return, Sharpe ratio, and max drawdown.\"\"\"\n",
        "    returns = df[column].pct_change().dropna()\n",
        "\n",
        "    cumulative_return = (df[column].iloc[-1] / df[column].iloc[0] - 1) * 100\n",
        "    sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() != 0 else 0\n",
        "    max_drawdown = (df[column] / df[column].cummax() - 1).min() * 100\n",
        "\n",
        "    return cumulative_return, sharpe_ratio, max_drawdown\n",
        "\n",
        "# ✅ Evaluate A2C Portfolio Performance\n",
        "a2c_cumulative_return, a2c_sharpe_ratio, a2c_max_drawdown = compute_performance_metrics(df)\n",
        "\n",
        "print(\"\\n🔹 **Reinforcement Learning (A2C) Performance Evaluation**\")\n",
        "print(f\"📈 A2C Final Portfolio Value: ${df['A2C Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"📊 A2C Cumulative Return: {a2c_cumulative_return:.2f}%\")\n",
        "print(f\"⚡ A2C Sharpe Ratio: {a2c_sharpe_ratio:.2f}\")\n",
        "print(f\"📉 A2C Max Drawdown: {a2c_max_drawdown:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMxh1NvOjWkh",
        "outputId": "b751cab8-5786-4650-b6d4-c852e7644e59"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 **Reinforcement Learning (A2C) Performance Evaluation**\n",
            "📈 A2C Final Portfolio Value: $100,000.00\n",
            "📊 A2C Cumulative Return: 0.00%\n",
            "⚡ A2C Sharpe Ratio: 0.00\n",
            "📉 A2C Max Drawdown: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3o9ZXEqMl7ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Ensure DDPG trade log is available\n",
        "if hasattr(env_continuous, \"get_wrapper_attr\"):\n",
        "    trade_log_ddpg = env_continuous.get_wrapper_attr(\"trade_log\")\n",
        "else:\n",
        "    trade_log_ddpg = env_continuous.envs[0].trade_log if hasattr(env_continuous.envs[0], \"trade_log\") else []\n",
        "\n",
        "# ✅ Initialize Portfolio Tracking\n",
        "if len(trade_log_ddpg) == 0:\n",
        "    print(\"⚠️ No trades recorded in DDPG. Using static portfolio value.\")\n",
        "\n",
        "    # ✅ Fill portfolio with static value\n",
        "    ddpg_portfolio_values = [100000] * len(df)\n",
        "else:\n",
        "    # ✅ Start with initial capital\n",
        "    ddpg_portfolio_values = [100000]\n",
        "    ddpg_cash_balance = 100000\n",
        "    ddpg_shares_held = 0\n",
        "\n",
        "    # ✅ Reconstruct Portfolio from Trade Log\n",
        "    for trade in trade_log_ddpg:\n",
        "        trade_price = trade[\"Stock Price\"]\n",
        "        action = trade[\"Action\"]\n",
        "\n",
        "        if action == \"BUY\":\n",
        "            ddpg_shares_held = trade[\"Shares Held\"]\n",
        "            ddpg_cash_balance = trade[\"Portfolio Value\"]\n",
        "        elif action == \"SELL\":\n",
        "            ddpg_shares_held = 0  # ✅ Sold all shares\n",
        "            ddpg_cash_balance = trade[\"Portfolio Value\"]\n",
        "\n",
        "        # ✅ Compute new portfolio value\n",
        "        portfolio_value = ddpg_cash_balance + (ddpg_shares_held * trade_price)\n",
        "        ddpg_portfolio_values.append(portfolio_value)\n",
        "\n",
        "    # ✅ Extend portfolio if too short\n",
        "    while len(ddpg_portfolio_values) < len(df):\n",
        "        ddpg_portfolio_values.append(ddpg_portfolio_values[-1])\n",
        "\n",
        "# ✅ Store Portfolio Values in DataFrame\n",
        "df[\"DDPG Portfolio Value\"] = ddpg_portfolio_values[:len(df)]\n",
        "\n",
        "# ✅ Debug: Check if DDPG Portfolio is Properly Assigned\n",
        "print(f\"✅ DDPG Portfolio Values Assigned: {len(df)} entries.\")\n",
        "print(df[\"DDPG Portfolio Value\"].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYh6DnwDm2_O",
        "outputId": "c03711c9-97b5-4876-e41f-5424f36f0284"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DDPG Portfolio Values Assigned: 4973 entries.\n",
            "count      4973.000000\n",
            "mean      87900.664995\n",
            "std         938.676428\n",
            "min       83619.462872\n",
            "25%       87801.321815\n",
            "50%       87801.321815\n",
            "75%       87801.321815\n",
            "max      100533.542552\n",
            "Name: DDPG Portfolio Value, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Define Function to Compute Performance Metrics\n",
        "def compute_performance_metrics(df, column=\"DDPG Portfolio Value\"):\n",
        "    \"\"\"Computes cumulative return, Sharpe ratio, and max drawdown.\"\"\"\n",
        "    returns = df[column].pct_change().dropna()\n",
        "\n",
        "    cumulative_return = (df[column].iloc[-1] / df[column].iloc[0] - 1) * 100\n",
        "    sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() != 0 else 0\n",
        "    max_drawdown = (df[column] / df[column].cummax() - 1).min() * 100\n",
        "\n",
        "    return cumulative_return, sharpe_ratio, max_drawdown\n",
        "\n",
        "# ✅ Evaluate DDPG Portfolio Performance\n",
        "ddpg_cumulative_return, ddpg_sharpe_ratio, ddpg_max_drawdown = compute_performance_metrics(df)\n",
        "\n",
        "print(\"\\n🔹 **Reinforcement Learning (DDPG) Performance Evaluation**\")\n",
        "print(f\"📈 DDPG Final Portfolio Value: ${df['DDPG Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"📊 DDPG Cumulative Return: {ddpg_cumulative_return:.2f}%\")\n",
        "print(f\"⚡ DDPG Sharpe Ratio: {ddpg_sharpe_ratio:.2f}\")\n",
        "print(f\"📉 DDPG Max Drawdown: {ddpg_max_drawdown:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtlhbiAgm2kX",
        "outputId": "81131eb8-343d-4d7d-c5e9-eedc48d6e85d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 **Reinforcement Learning (DDPG) Performance Evaluation**\n",
            "📈 DDPG Final Portfolio Value: $87,801.32\n",
            "📊 DDPG Cumulative Return: -12.20%\n",
            "⚡ DDPG Sharpe Ratio: -0.29\n",
            "📉 DDPG Max Drawdown: -16.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atmLHZvxOZBb",
        "outputId": "416e5a96-0123-4acb-b26e-a96b71e91ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 **Final Performance Summary**\n",
            "\n",
            "🔹 **A2C**\n",
            "📈 Final Portfolio Value: $100,000.00\n",
            "📊 Cumulative Return: 0.00%\n",
            "⚡ Sharpe Ratio: 0.00\n",
            "📉 Max Drawdown: 0.00%\n",
            "\n",
            "🔹 **PPO**\n",
            "📈 Final Portfolio Value: $100,000.00\n",
            "📊 Cumulative Return: 0.00%\n",
            "⚡ Sharpe Ratio: 0.00\n",
            "📉 Max Drawdown: 0.00%\n",
            "\n",
            "🔹 **DDPG**\n",
            "📈 Final Portfolio Value: $87,801.32\n",
            "📊 Cumulative Return: -12.20%\n",
            "⚡ Sharpe Ratio: -0.29\n",
            "📉 Max Drawdown: -16.82%\n",
            "\n",
            "🔹 **XGBoost**\n",
            "📈 Final Portfolio Value: $100,000.00\n",
            "📊 Cumulative Return: 0.00%\n",
            "⚡ Sharpe Ratio: 0.00\n",
            "📉 Max Drawdown: 0.00%\n",
            "\n",
            "🔹 **Random Forest**\n",
            "📈 Final Portfolio Value: $100,000.00\n",
            "📊 Cumulative Return: 0.00%\n",
            "⚡ Sharpe Ratio: 0.00\n",
            "📉 Max Drawdown: 0.00%\n",
            "\n",
            "🔹 **SARSA**\n",
            "📈 Final Portfolio Value: $500,000.00\n",
            "📊 Cumulative Return: 400.00%\n",
            "⚡ Sharpe Ratio: 6.09\n",
            "📉 Max Drawdown: -90.00%\n",
            "\n",
            "🔹 **Buy & Hold**\n",
            "📈 Final Portfolio Value: $100,000.00\n",
            "📊 Cumulative Return: 0.00%\n",
            "⚡ Sharpe Ratio: 0.00\n",
            "📉 Max Drawdown: 0.00%\n",
            "\n",
            "🏆 **Best Strategy Based on Final Portfolio Value: SARSA!**\n"
          ]
        }
      ],
      "source": [
        "# ✅ Ensure Portfolio Value is Numeric for DDPG\n",
        "df[\"DDPG Portfolio Value\"] = df[\"DDPG Portfolio Value\"].apply(\n",
        "    lambda x: float(x[0]) if isinstance(x, (np.ndarray, list)) and len(x) > 0 else float(x)\n",
        ")\n",
        "\n",
        "# ✅ Ensure All Models Have Portfolio Value Data\n",
        "portfolio_dfs = {\n",
        "    \"A2C\": \"A2C Portfolio Value\",\n",
        "    \"PPO\": \"PPO Portfolio Value\",\n",
        "    \"DDPG\": \"DDPG Portfolio Value\",\n",
        "    \"XGBoost\": \"XGBoost Portfolio Value\",\n",
        "    \"Random Forest\": \"RF Portfolio Value\",\n",
        "    \"SARSA\": \"SARSA Portfolio Value\",\n",
        "    \"Buy & Hold\": \"Buy Hold Portfolio Value\"\n",
        "}\n",
        "\n",
        "for model, column in portfolio_dfs.items():\n",
        "    if column not in df.columns:\n",
        "        df[column] = [100000] * len(df)  # ✅ Default to initial balance if missing\n",
        "\n",
        "# ✅ Compute Performance Metrics for All Strategies\n",
        "strategy_metrics = {}\n",
        "for model, column in portfolio_dfs.items():\n",
        "    cumulative_return, sharpe_ratio, max_drawdown = compute_performance_metrics(df, column)\n",
        "    strategy_metrics[model] = {\n",
        "        \"Final Portfolio Value\": df[column].iloc[-1],\n",
        "        \"Cumulative Return (%)\": cumulative_return,\n",
        "        \"Sharpe Ratio\": sharpe_ratio,\n",
        "        \"Max Drawdown (%)\": max_drawdown\n",
        "    }\n",
        "\n",
        "# ✅ Determine Best Strategy Based on Final Portfolio Value\n",
        "best_strategy = max(strategy_metrics, key=lambda k: strategy_metrics[k][\"Final Portfolio Value\"])\n",
        "\n",
        "# ✅ Print Final Performance Summary\n",
        "print(\"\\n📊 **Final Performance Summary**\")\n",
        "for model, metrics in strategy_metrics.items():\n",
        "    print(f\"\\n🔹 **{model}**\")\n",
        "    print(f\"📈 Final Portfolio Value: ${metrics['Final Portfolio Value']:,.2f}\")\n",
        "    print(f\"📊 Cumulative Return: {metrics['Cumulative Return (%)']:.2f}%\")\n",
        "    print(f\"⚡ Sharpe Ratio: {metrics['Sharpe Ratio']:.2f}\")\n",
        "    print(f\"📉 Max Drawdown: {metrics['Max Drawdown (%)']:.2f}%\")\n",
        "\n",
        "# ✅ Print Best Strategy Based on Final Portfolio Value\n",
        "print(f\"\\n🏆 **Best Strategy Based on Final Portfolio Value: {best_strategy}!**\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}