{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoope70/daytrading-with-ml/blob/main/implement_market_wizard_strategies_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3unZTnDPdSb1",
        "outputId": "d73c37c6-f684-4413-d06f-b1da00505086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dask==2024.11.2\n",
            "  Downloading dask-2024.11.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting rapids-dask-dependency==24.12.0\n",
            "  Downloading rapids_dask_dependency-24.12.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cudf-cu12==24.12.0\n",
            "  Downloading cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting cuml-cu12==24.12.0\n",
            "  Downloading cuml_cu12-24.12.0.tar.gz (2.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pylibraft-cu12==24.12.0\n",
            "  Downloading pylibraft_cu12-24.12.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pylibcudf-cu12==24.12.0\n",
            "  Downloading pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting numba==0.61.0\n",
            "  Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gym-anytrading==2.0.0\n",
            "  Downloading gym_anytrading-2.0.0-py3-none-any.whl.metadata (292 bytes)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting click>=8.1 (from dask==2024.11.2)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle>=3.0.0 (from dask==2024.11.2)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting fsspec>=2021.09.0 (from dask==2024.11.2)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting packaging>=20.0 (from dask==2024.11.2)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting partd>=1.4.0 (from dask==2024.11.2)\n",
            "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml>=5.3.1 (from dask==2024.11.2)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting toolz>=0.10.0 (from dask==2024.11.2)\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting importlib-metadata>=4.13.0 (from dask==2024.11.2)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting distributed==2024.11.2 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading distributed-2024.11.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting dask-expr==1.1.19 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pynvml<11.5.0a0,>=11.0.0 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting cachetools (from cudf-cu12==24.12.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cuda-python<13.0a0,<=12.6.0,>=12.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting cupy-cuda12x>=12.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting libcudf-cu12==24.12.* (from cudf-cu12==24.12.0)\n",
            "  Downloading libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numba-cuda<0.0.18,>=0.0.13 (from cudf-cu12==24.12.0)\n",
            "  Downloading numba_cuda-0.0.17.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12==24.12.0)\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m406.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvtx>=0.2.1 (from cudf-cu12==24.12.0)\n",
            "  Downloading nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting pandas<2.2.4dev0,>=2.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow<19.0.0a0,>=14.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pynvjitlink-cu12 (from cudf-cu12==24.12.0)\n",
            "  Downloading pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting rich (from cudf-cu12==24.12.0)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rmm-cu12==24.12.* (from cudf-cu12==24.12.0)\n",
            "  Downloading rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions>=4.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cuvs-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading cuvs_cu12-24.12.0.tar.gz (1.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dask-cuda==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading dask_cuda-24.12.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting dask-cudf-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading dask_cudf_cu12-24.12.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting joblib>=0.11 (from cuml-cu12==24.12.0)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting raft-dask-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading raft_dask_cu12-24.12.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy>=1.8.0 (from cuml-cu12==24.12.0)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treelite==4.3.0 (from cuml-cu12==24.12.0)\n",
            "  Downloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.0)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12==24.12.0)\n",
            "  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farama-notifications>=0.0.1 (from gymnasium==0.29.1)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting matplotlib>=3.1.1 (from gym-anytrading==2.0.0)\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting zict>=2.0.0 (from dask-cuda==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting jinja2>=2.10.3 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting locket>=1.0.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting msgpack>=1.0.2 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting psutil>=5.8.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tornado>=6.2.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting urllib3>=1.26.5 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting libkvikio-cu12==24.12.* (from libcudf-cu12==24.12.*->cudf-cu12==24.12.0)\n",
            "  Downloading libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting nvidia-nvcomp-cu12==4.1.0.6 (from libcudf-cu12==24.12.*->cudf-cu12==24.12.0)\n",
            "  Downloading nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl.metadata (862 bytes)\n",
            "Collecting distributed-ucxx-cu12==0.41.* (from raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading distributed_ucxx_cu12-0.41.0.tar.gz (991 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucx-py-cu12==0.41.* (from raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading ucx_py_cu12-0.41.0.tar.gz (1.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucxx-cu12==0.41.* (from distributed-ucxx-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading ucxx_cu12-0.41.0.tar.gz (3.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting libucx-cu12<1.18,>=1.15.0 (from ucx-py-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading libucx_cu12-1.17.0.post1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting libucxx-cu12==0.41.* (from ucxx-cu12==0.41.*->distributed-ucxx-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading libucxx_cu12-0.41.0.tar.gz (3.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch<3.0,>=2.3 (from stable-baselines3[extra])\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting opencv-python (from stable-baselines3[extra])\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pygame (from stable-baselines3[extra])\n",
            "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tqdm (from stable-baselines3[extra])\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
            "  Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting pillow (from stable-baselines3[extra])\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x>=12.0.0->cudf-cu12==24.12.0)\n",
            "  Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=4.13.0->dask==2024.11.2)\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.2.4dev0,>=2.0->cudf-cu12==24.12.0)\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.2.4dev0,>=2.0->cudf-cu12==24.12.0)\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting setuptools>=41.0.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting six>1.9 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting filelock (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting networkx (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->cudf-cu12==24.12.0)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->cudf-cu12==24.12.0)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.10.3->distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->cudf-cu12==24.12.0)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading dask-2024.11.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapids_dask_dependency-24.12.0-py3-none-any.whl (15 kB)\n",
            "Downloading cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gym_anytrading-2.0.0-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cuda-24.12.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cudf_cu12-24.12.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_expr-1.1.19-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.5/244.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distributed-2024.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl (457.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.8/457.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl (915 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m916.0/916.0 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl (28.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.9/28.9 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba_cuda-0.0.17.1-py3-none-any.whl (424 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.7/424.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libucx_cu12-1.17.0.post1-py3-none-manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: cuml-cu12, pylibraft-cu12, cuvs-cu12, raft-dask-cu12, distributed-ucxx-cu12, ucx-py-cu12, ucxx-cu12, libucxx-cu12\n",
            "  Building wheel for cuml-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuml-cu12: filename=cuml_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=548018735 sha256=2418da8e8eb6e9e43ab4ef2a43b05eaec1b0e1c27f6eb93e9b390d625f87830d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/a8/b2/1b20fa5b8a53c9d3d5d0d9c5350683457c23d1f3e924beab41\n",
            "  Building wheel for pylibraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylibraft-cu12: filename=pylibraft_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=11802800 sha256=47d3915fd3cdf4022acbd0315f88b12155399ef0b0e77fcac050c459ab6b31b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/67/73/9252ad4b3876078a9bca569565977dd588cb54f66bd3bf2e0d\n",
            "  Building wheel for cuvs-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuvs-cu12: filename=cuvs_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=849668080 sha256=b19c011e0219334cf22fbb77768eec6798897afebdd4cbb48e6de156cfc3a1a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c8/33/82e634a5179b7034208bca3b0a465bde16e40d6212b63171b9\n",
            "  Building wheel for raft-dask-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for raft-dask-cu12: filename=raft_dask_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=196890281 sha256=22907cfcaf561dfe366b129021300168737a3cbad25812fd61819e1a9aeff4f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/14/3e/c40661899a098c7c99ae981bff10c67930615f082c0c886634\n",
            "  Building wheel for distributed-ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distributed-ucxx-cu12: filename=distributed_ucxx_cu12-0.41.0-py3-none-any.whl size=24803 sha256=73437e496b61b34a5f0f3d9e64c5873c1d176bf80379fa8318d1ebdd78fa560b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/9f/30/fc294cabfead20c6cd33ad49842809c23eb8cb9db2c857dd11\n",
            "  Building wheel for ucx-py-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucx-py-cu12: filename=ucx_py_cu12-0.41.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl size=2287997 sha256=ada163c63d31e19ff65ee1218448cea2de52e80797dca6a519a20d39fd09e2cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/e1/e6/87ca1ddc23cc8b9d857c9a0b1e8199b3ec60fe3f4efbbac3d5\n",
            "  Building wheel for ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucxx-cu12: filename=ucxx_cu12-0.41.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl size=841184 sha256=d498bf3c805f799d4a6f7f69269169dc3c544bd30f3410a0f4876a33d2e21723\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/6f/9b/dfcf3e4fa6df3069345e6a0560c94b6f2a3161ab38904da670\n",
            "  Building wheel for libucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libucxx-cu12: filename=libucxx_cu12-0.41.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl size=513262 sha256=9bd816b322e55d19230b8dda392da532e6b333e1d504c6576024dfcd78dd3177\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/04/a6/de68207e0e498ea1367f31a6e523e238e2b7afa9e31290d0cc\n",
            "Successfully built cuml-cu12 pylibraft-cu12 cuvs-cu12 raft-dask-cu12 distributed-ucxx-cu12 ucx-py-cu12 ucxx-cu12 libucxx-cu12\n",
            "Installing collected packages: triton, sortedcontainers, pytz, nvtx, nvidia-cusparselt-cu12, mpmath, libkvikio-cu12, fastrlock, farama-notifications, cuda-python, zipp, zict, urllib3, tzdata, typing_extensions, tqdm, tornado, toolz, tensorboard-data-server, tblib, sympy, six, setuptools, pyyaml, pyparsing, pynvml, pynvjitlink-cu12, pygments, pygame, pyarrow, psutil, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nvcomp-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, msgpack, mdurl, MarkupSafe, markdown, locket, llvmlite, libucx-cu12, kiwisolver, joblib, grpcio, fsspec, fonttools, filelock, cycler, cloudpickle, click, cachetools, absl-py, werkzeug, ucx-py-cu12, scipy, python-dateutil, partd, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, libucxx-cu12, libcudf-cu12, jinja2, importlib-metadata, gymnasium, cupy-cuda12x, contourpy, ale-py, treelite, tensorboard, rmm-cu12, rich, pandas, nvidia-cusolver-cu12, numba-cuda, matplotlib, dask, ucxx-cu12, torch, pylibraft-cu12, pylibcudf-cu12, gym-anytrading, distributed, dask-expr, stable-baselines3, rapids-dask-dependency, cuvs-cu12, cudf-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: nvtx\n",
            "    Found existing installation: nvtx 0.2.11\n",
            "    Uninstalling nvtx-0.2.11:\n",
            "      Successfully uninstalled nvtx-0.2.11\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: libkvikio-cu12\n",
            "    Found existing installation: libkvikio-cu12 25.2.1\n",
            "    Uninstalling libkvikio-cu12-25.2.1:\n",
            "      Successfully uninstalled libkvikio-cu12-25.2.1\n",
            "  Attempting uninstall: fastrlock\n",
            "    Found existing installation: fastrlock 0.8.3\n",
            "    Uninstalling fastrlock-0.8.3:\n",
            "      Successfully uninstalled fastrlock-0.8.3\n",
            "  Attempting uninstall: farama-notifications\n",
            "    Found existing installation: Farama-Notifications 0.0.4\n",
            "    Uninstalling Farama-Notifications-0.0.4:\n",
            "      Successfully uninstalled Farama-Notifications-0.0.4\n",
            "  Attempting uninstall: cuda-python\n",
            "    Found existing installation: cuda-python 12.6.2.post1\n",
            "    Uninstalling cuda-python-12.6.2.post1:\n",
            "      Successfully uninstalled cuda-python-12.6.2.post1\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.21.0\n",
            "    Uninstalling zipp-3.21.0:\n",
            "      Successfully uninstalled zipp-3.21.0\n",
            "  Attempting uninstall: zict\n",
            "    Found existing installation: zict 3.0.0\n",
            "    Uninstalling zict-3.0.0:\n",
            "      Successfully uninstalled zict-3.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.4.2\n",
            "    Uninstalling tornado-6.4.2:\n",
            "      Successfully uninstalled tornado-6.4.2\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 0.12.1\n",
            "    Uninstalling toolz-0.12.1:\n",
            "      Successfully uninstalled toolz-0.12.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.1\n",
            "    Uninstalling pyparsing-3.2.1:\n",
            "      Successfully uninstalled pyparsing-3.2.1\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 12.0.0\n",
            "    Uninstalling pynvml-12.0.0:\n",
            "      Successfully uninstalled pynvml-12.0.0\n",
            "  Attempting uninstall: pynvjitlink-cu12\n",
            "    Found existing installation: pynvjitlink-cu12 0.5.2\n",
            "    Uninstalling pynvjitlink-cu12-0.5.2:\n",
            "      Successfully uninstalled pynvjitlink-cu12-0.5.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nvcomp-cu12\n",
            "    Found existing installation: nvidia-nvcomp-cu12 4.2.0.11\n",
            "    Uninstalling nvidia-nvcomp-cu12-4.2.0.11:\n",
            "      Successfully uninstalled nvidia-nvcomp-cu12-4.2.0.11\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.7\n",
            "    Uninstalling Markdown-3.7:\n",
            "      Successfully uninstalled Markdown-3.7\n",
            "  Attempting uninstall: locket\n",
            "    Found existing installation: locket 1.0.0\n",
            "    Uninstalling locket-1.0.0:\n",
            "      Successfully uninstalled locket-1.0.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: libucx-cu12\n",
            "    Found existing installation: libucx-cu12 1.18.0\n",
            "    Uninstalling libucx-cu12-1.18.0:\n",
            "      Successfully uninstalled libucx-cu12-1.18.0\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.56.0\n",
            "    Uninstalling fonttools-4.56.0:\n",
            "      Successfully uninstalled fonttools-4.56.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.17.0\n",
            "    Uninstalling filelock-3.17.0:\n",
            "      Successfully uninstalled filelock-3.17.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: ucx-py-cu12\n",
            "    Found existing installation: ucx-py-cu12 0.42.0\n",
            "    Uninstalling ucx-py-cu12-0.42.0:\n",
            "      Successfully uninstalled ucx-py-cu12-0.42.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: partd\n",
            "    Found existing installation: partd 1.4.2\n",
            "    Uninstalling partd-1.4.2:\n",
            "      Successfully uninstalled partd-1.4.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: libucxx-cu12\n",
            "    Found existing installation: libucxx-cu12 0.42.0\n",
            "    Uninstalling libucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled libucxx-cu12-0.42.0\n",
            "  Attempting uninstall: libcudf-cu12\n",
            "    Found existing installation: libcudf-cu12 25.2.1\n",
            "    Uninstalling libcudf-cu12-25.2.1:\n",
            "      Successfully uninstalled libcudf-cu12-25.2.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "  Attempting uninstall: cupy-cuda12x\n",
            "    Found existing installation: cupy-cuda12x 13.3.0\n",
            "    Uninstalling cupy-cuda12x-13.3.0:\n",
            "      Successfully uninstalled cupy-cuda12x-13.3.0\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.10.2\n",
            "    Uninstalling ale-py-0.10.2:\n",
            "      Successfully uninstalled ale-py-0.10.2\n",
            "  Attempting uninstall: treelite\n",
            "    Found existing installation: treelite 4.4.1\n",
            "    Uninstalling treelite-4.4.1:\n",
            "      Successfully uninstalled treelite-4.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: rmm-cu12\n",
            "    Found existing installation: rmm-cu12 25.2.0\n",
            "    Uninstalling rmm-cu12-25.2.0:\n",
            "      Successfully uninstalled rmm-cu12-25.2.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: numba-cuda\n",
            "    Found existing installation: numba-cuda 0.2.0\n",
            "    Uninstalling numba-cuda-0.2.0:\n",
            "      Successfully uninstalled numba-cuda-0.2.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.12.1\n",
            "    Uninstalling dask-2024.12.1:\n",
            "      Successfully uninstalled dask-2024.12.1\n",
            "  Attempting uninstall: ucxx-cu12\n",
            "    Found existing installation: ucxx-cu12 0.42.0\n",
            "    Uninstalling ucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled ucxx-cu12-0.42.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: pylibraft-cu12\n",
            "    Found existing installation: pylibraft-cu12 25.2.0\n",
            "    Uninstalling pylibraft-cu12-25.2.0:\n",
            "      Successfully uninstalled pylibraft-cu12-25.2.0\n",
            "  Attempting uninstall: pylibcudf-cu12\n",
            "    Found existing installation: pylibcudf-cu12 25.2.1\n",
            "    Uninstalling pylibcudf-cu12-25.2.1:\n",
            "      Successfully uninstalled pylibcudf-cu12-25.2.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.12.1\n",
            "    Uninstalling distributed-2024.12.1:\n",
            "      Successfully uninstalled distributed-2024.12.1\n",
            "  Attempting uninstall: dask-expr\n",
            "    Found existing installation: dask-expr 1.1.21\n",
            "    Uninstalling dask-expr-1.1.21:\n",
            "      Successfully uninstalled dask-expr-1.1.21\n",
            "  Attempting uninstall: rapids-dask-dependency\n",
            "    Found existing installation: rapids-dask-dependency 25.2.0\n",
            "    Uninstalling rapids-dask-dependency-25.2.0:\n",
            "      Successfully uninstalled rapids-dask-dependency-25.2.0\n",
            "  Attempting uninstall: cuvs-cu12\n",
            "    Found existing installation: cuvs-cu12 25.2.1\n",
            "    Uninstalling cuvs-cu12-25.2.1:\n",
            "      Successfully uninstalled cuvs-cu12-25.2.1\n",
            "  Attempting uninstall: cudf-cu12\n",
            "    Found existing installation: cudf-cu12 25.2.1\n",
            "    Uninstalling cudf-cu12-25.2.1:\n",
            "      Successfully uninstalled cudf-cu12-25.2.1\n",
            "  Attempting uninstall: distributed-ucxx-cu12\n",
            "    Found existing installation: distributed-ucxx-cu12 0.42.0\n",
            "    Uninstalling distributed-ucxx-cu12-0.42.0:\n",
            "      Successfully uninstalled distributed-ucxx-cu12-0.42.0\n",
            "  Attempting uninstall: dask-cudf-cu12\n",
            "    Found existing installation: dask-cudf-cu12 25.2.2\n",
            "    Uninstalling dask-cudf-cu12-25.2.2:\n",
            "      Successfully uninstalled dask-cudf-cu12-25.2.2\n",
            "  Attempting uninstall: dask-cuda\n",
            "    Found existing installation: dask-cuda 25.2.0\n",
            "    Uninstalling dask-cuda-25.2.0:\n",
            "      Successfully uninstalled dask-cuda-25.2.0\n",
            "  Attempting uninstall: raft-dask-cu12\n",
            "    Found existing installation: raft-dask-cu12 25.2.0\n",
            "    Uninstalling raft-dask-cu12-25.2.0:\n",
            "      Successfully uninstalled raft-dask-cu12-25.2.0\n",
            "  Attempting uninstall: cuml-cu12\n",
            "    Found existing installation: cuml-cu12 25.2.1\n",
            "    Uninstalling cuml-cu12-25.2.1:\n",
            "      Successfully uninstalled cuml-cu12-25.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-pubsub 2.28.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n",
            "google-cloud-bigtable 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "cudf-polars-cu12 25.2.2 requires pylibcudf-cu12==25.2.*, but you have pylibcudf-cu12 24.12.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.79.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.1 which is incompatible.\n",
            "wandb 0.19.8 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-spanner 3.52.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-dataproc 5.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "googleapis-common-protos 1.69.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "google-cloud-iam 2.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.1.0 ale-py-0.10.2 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 contourpy-1.3.1 cuda-python-12.6.0 cudf-cu12-24.12.0 cuml-cu12-24.12.0 cupy-cuda12x-13.4.0 cuvs-cu12-24.12.0 cycler-0.12.1 dask-2024.11.2 dask-cuda-24.12.0 dask-cudf-cu12-24.12.0 dask-expr-1.1.19 distributed-2024.11.2 distributed-ucxx-cu12-0.41.0 farama-notifications-0.0.4 fastrlock-0.8.3 filelock-3.18.0 fonttools-4.56.0 fsspec-2025.3.0 grpcio-1.71.0 gym-anytrading-2.0.0 gymnasium-0.29.1 importlib-metadata-8.6.1 jinja2-3.1.6 joblib-1.4.2 kiwisolver-1.4.8 libcudf-cu12-24.12.0 libkvikio-cu12-24.12.1 libucx-cu12-1.17.0.post1 libucxx-cu12-0.41.0 llvmlite-0.44.0 locket-1.0.0 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.1.0 networkx-3.4.2 numba-0.61.0 numba-cuda-0.0.17.1 numpy-2.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvcomp-cu12-4.1.0.6 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 nvtx-0.2.11 opencv-python-4.11.0.86 packaging-24.2 pandas-2.2.3 partd-1.4.2 pillow-11.1.0 protobuf-6.30.1 psutil-7.0.0 pyarrow-18.1.0 pygame-2.6.1 pygments-2.19.1 pylibcudf-cu12-24.12.0 pylibraft-cu12-24.12.0 pynvjitlink-cu12-0.5.2 pynvml-11.4.1 pyparsing-3.2.1 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 raft-dask-cu12-24.12.0 rapids-dask-dependency-24.12.0 rich-13.9.4 rmm-cu12-24.12.1 scipy-1.15.2 setuptools-76.0.0 six-1.17.0 sortedcontainers-2.4.0 stable-baselines3-2.5.0 sympy-1.13.1 tblib-3.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 toolz-1.0.0 torch-2.6.0 tornado-6.4.2 tqdm-4.67.1 treelite-4.3.0 triton-3.2.0 typing_extensions-4.12.2 tzdata-2025.1 ucx-py-cu12-0.41.0 ucxx-cu12-0.41.0 urllib3-2.3.0 werkzeug-3.1.3 zict-3.0.0 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "cycler",
                  "dateutil",
                  "importlib_metadata",
                  "kiwisolver",
                  "psutil",
                  "rapids_dask_dependency",
                  "six",
                  "tornado",
                  "zipp"
                ]
              },
              "id": "2c06de0d084e4ec984fe178bf1954de4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall \\\n",
        "    dask==2024.11.2 \\\n",
        "    rapids-dask-dependency==24.12.0 \\\n",
        "    cudf-cu12==24.12.0 \\\n",
        "    cuml-cu12==24.12.0 \\\n",
        "    pylibraft-cu12==24.12.0 \\\n",
        "    pylibcudf-cu12==24.12.0 \\\n",
        "    numba==0.61.0 \\\n",
        "    stable-baselines3[extra] \\\n",
        "    gymnasium==0.29.1 \\\n",
        "    gym-anytrading==2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk2eXrK9N8sy",
        "outputId": "dd66ee6d-4446-4bbc-bd81-8530c90d1a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym-anytrading in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (0.29.1)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.1.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Collecting swig==4.* (from gymnasium[box2d])\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.30.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (76.0.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[box2d] stable-baselines3[extra] gym-anytrading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "simIAIAMDvA9",
        "outputId": "467d856a-1d44-4f1d-be48-fec8ebeb2bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.54)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Collecting protobuf==3.20.3\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.1.3)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.1\n",
            "    Uninstalling protobuf-6.30.1:\n",
            "      Successfully uninstalled protobuf-6.30.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "e5e072893e744b38aad966e4bdb35bb4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install yfinance xgboost joblib protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LSRmcQn3MTvU",
        "outputId": "957cb205-a6c9-4638-f1a2-1534067defcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (3.20.3)\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Using cached protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-pubsub 2.28.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-bigtable 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.79.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.1 which is incompatible.\n",
            "wandb 0.19.8 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-spanner 3.52.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-dataproc 5.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "googleapis-common-protos 1.69.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "google-cloud-iam 2.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-6.30.1\n",
            "Collecting protobuf==3.20.3\n",
            "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.1\n",
            "    Uninstalling protobuf-6.30.1:\n",
            "      Successfully uninstalled protobuf-6.30.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "64293eda85034e12a95f696a4e67abfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (76.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
            "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, tensorboard\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.3\n",
            "    Uninstalling numpy-2.1.3:\n",
            "      Successfully uninstalled numpy-2.1.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
            "pylibcugraph-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2 tensorboard-2.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade protobuf\n",
        "!pip install protobuf==3.20.3\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48yV-FjZMW6-",
        "outputId": "0222a969-ff1a-4b97-98a3-f725f6464601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oeEKYZmoMaPH",
        "outputId": "7e301f61-965d-4893-b21c-f217f07d184b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cudf-cu12\n",
            "  Downloading cudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting cuml-cu12\n",
            "  Downloading cuml_cu12-25.2.1.tar.gz (2.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapids-dask-dependency\n",
            "  Downloading rapids_dask_dependency-25.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cachetools (from cudf-cu12)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cuda-python<13.0a0,>=12.6.2 (from cudf-cu12)\n",
            "  Downloading cuda_python-12.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting cupy-cuda12x>=12.0.0 (from cudf-cu12)\n",
            "  Using cached cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting fsspec>=0.6.0 (from cudf-cu12)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting libcudf-cu12==25.2.* (from cudf-cu12)\n",
            "  Downloading libcudf_cu12-25.2.2-py3-none-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numba-cuda<0.3.0a0,>=0.2.0 (from cudf-cu12)\n",
            "  Downloading numba_cuda-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting numba<0.61.0a0,>=0.59.1 (from cudf-cu12)\n",
            "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting nvtx>=0.2.1 (from cudf-cu12)\n",
            "  Using cached nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting packaging (from cudf-cu12)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas<2.2.4dev0,>=2.0 (from cudf-cu12)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting pyarrow<20.0.0a0,>=14.0.0 (from cudf-cu12)\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pylibcudf-cu12==25.2.* (from cudf-cu12)\n",
            "  Downloading pylibcudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting pynvjitlink-cu12 (from cudf-cu12)\n",
            "  Using cached pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting rich (from cudf-cu12)\n",
            "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rmm-cu12==25.2.* (from cudf-cu12)\n",
            "  Downloading rmm_cu12-25.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions>=4.0.0 (from cudf-cu12)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting libkvikio-cu12==25.2.* (from libcudf-cu12==25.2.*->cudf-cu12)\n",
            "  Downloading libkvikio_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting nvidia-nvcomp-cu12==4.2.0.11 (from libcudf-cu12==25.2.*->cudf-cu12)\n",
            "  Downloading nvidia_nvcomp_cu12-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl.metadata (863 bytes)\n",
            "Collecting cuvs-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading cuvs_cu12-25.2.1.tar.gz (1.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dask-cuda==25.2.* (from cuml-cu12)\n",
            "  Downloading dask_cuda-25.2.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting dask-cudf-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading dask_cudf_cu12-25.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting joblib>=0.11 (from cuml-cu12)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting libcuml-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading libcuml_cu12-25.2.1.tar.gz (4.1 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting pylibraft-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading pylibraft_cu12-25.2.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting raft-dask-cu12==25.2.* (from cuml-cu12)\n",
            "  Downloading raft_dask_cu12-25.2.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy>=1.8.0 (from cuml-cu12)\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting treelite==4.4.1 (from cuml-cu12)\n",
            "  Downloading treelite-4.4.1-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting dask==2024.12.1 (from rapids-dask-dependency)\n",
            "  Downloading dask-2024.12.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting distributed==2024.12.1 (from rapids-dask-dependency)\n",
            "  Downloading distributed-2024.12.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting dask-expr==1.1.21 (from rapids-dask-dependency)\n",
            "  Downloading dask_expr-1.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting libcuvs-cu12==25.2.* (from cuvs-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading libcuvs_cu12-25.2.1.tar.gz (4.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click>=8.1 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle>=3.0.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting partd>=1.4.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml>=5.3.1 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting toolz>=0.10.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting importlib_metadata>=4.13.0 (from dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pynvml<13.0.0a0,>=12.0.0 (from dask-cuda==25.2.*->cuml-cu12)\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting zict>=2.0.0 (from dask-cuda==25.2.*->cuml-cu12)\n",
            "  Using cached zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting jinja2>=2.10.3 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting locket>=1.0.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting msgpack>=1.0.2 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting psutil>=5.8.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tornado>=6.2.0 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting urllib3>=1.26.5 (from distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting libraft-cu12==25.2.* (from libcuml-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading libraft_cu12-25.2.0.tar.gz (5.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting distributed-ucxx-cu12==0.42.* (from raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading distributed_ucxx_cu12-0.42.0.tar.gz (997 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucx-py-cu12==0.42.* (from raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading ucx_py_cu12-0.42.0.tar.gz (1.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucxx-cu12==0.42.* (from distributed-ucxx-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading ucxx_cu12-0.42.0.tar.gz (3.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting libucx-cu12<1.19,>=1.15.0 (from ucx-py-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading libucx_cu12-1.18.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting libucxx-cu12==0.42.* (from ucxx-cu12==0.42.*->distributed-ucxx-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12)\n",
            "  Downloading libucxx_cu12-0.42.0.tar.gz (3.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cuda-bindings~=12.8.0 (from cuda-python<13.0a0,>=12.6.2->cudf-cu12)\n",
            "  Downloading cuda_bindings-12.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x>=12.0.0->cudf-cu12)\n",
            "  Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba<0.61.0a0,>=0.59.1->cudf-cu12)\n",
            "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12)\n",
            "  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12->cuml-cu12)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->cudf-cu12)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->cudf-cu12)\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting zipp>=3.20 (from importlib_metadata>=4.13.0->dask==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.10.3->distributed==2024.12.1->rapids-dask-dependency)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->cudf-cu12)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml<13.0.0a0,>=12.0.0->dask-cuda==25.2.*->cuml-cu12)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<2.2.4dev0,>=2.0->cudf-cu12)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading cudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcudf_cu12-25.2.2-py3-none-manylinux_2_28_x86_64.whl (557.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.7/557.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylibcudf_cu12-25.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rmm_cu12-25.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libkvikio_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvcomp_cu12-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl (46.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapids_dask_dependency-25.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading dask-2024.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cuda-25.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cudf_cu12-25.2.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_expr-1.1.21-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distributed-2024.12.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading treelite-4.4.1-py3-none-manylinux2014_x86_64.whl (922 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.8/922.8 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_python-12.8.0-py3-none-any.whl (11 kB)\n",
            "Using cached cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba_cuda-0.2.0-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.7/443.7 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Using cached nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pynvjitlink_cu12-0.5.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (46.2 MB)\n",
            "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading cuda_bindings-12.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "Using cached partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
            "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libucx_cu12-1.18.0-py3-none-manylinux_2_28_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: cuml-cu12, cuvs-cu12, libcuml-cu12, pylibraft-cu12, raft-dask-cu12, distributed-ucxx-cu12, libcuvs-cu12, libraft-cu12, ucx-py-cu12, ucxx-cu12, libucxx-cu12\n",
            "  Building wheel for cuml-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuml-cu12: filename=cuml_cu12-25.2.1-cp311-cp311-manylinux_2_28_x86_64.whl size=9708883 sha256=645732a1e89bff0eaf5832e2d9b9277ed5ad55802935deaa4f36cf2c848305bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/05/99/2ba4d47fa6b7433c469a53a0be406737d3e703866a37b00d1f\n",
            "  Building wheel for cuvs-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuvs-cu12: filename=cuvs_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl size=2317704 sha256=5fc01ad6fcc84e66c5d3dd89690e1fdca64299a55c9bc37ee2a1ba2ddd6107a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/f4/6e/2b1349b6608494674dcab7a67caf6e92572b467e31b94c5ccb\n",
            "  Building wheel for libcuml-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libcuml-cu12: filename=libcuml_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl size=405006204 sha256=36630506b77f92066d4a19de8a4d52dd32d8bcc8597a93de44f58f8832bc8ece\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/dd/bb/be110f3f4dce61cdd3575d757f9bfa91c60e3c6d7e37ce0490\n",
            "  Building wheel for pylibraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylibraft-cu12: filename=pylibraft_cu12-25.2.0-cp311-cp311-manylinux_2_28_x86_64.whl size=851210 sha256=62186880220c3704e195ee3386774b48d7d340e310efd9d02c0b69d2057d8d6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/c8/f2/b134085eaa02b2a75d8bdd9ed640b4719ab22ce879889ff3b5\n",
            "  Building wheel for raft-dask-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for raft-dask-cu12: filename=raft_dask_cu12-25.2.0-cp311-cp311-manylinux_2_28_x86_64.whl size=293515763 sha256=e8180027a9a0d2830c555d54398059a04294b5e655aa40b88c416eec4a3a908b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/3a/ec/7def1e0bb02ac32c18f0f8234e4c692f73ea9c12744129969f\n",
            "  Building wheel for distributed-ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distributed-ucxx-cu12: filename=distributed_ucxx_cu12-0.42.0-py3-none-any.whl size=24814 sha256=24b4a9541965904448582b805c1b66c8f3d5a319fb86d73b2656877cc3a15694\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/6f/c8/218f0214f308d7f7308daffa946c2ae614a09478732659bd74\n",
            "  Building wheel for libcuvs-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libcuvs-cu12: filename=libcuvs_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl size=1184487347 sha256=eb4791a3aeb57c06898276b021e47267bb37b7f345c7a528a859c0b7370eb8e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/07/b8/5ef838697bece6ef046ece66c8259fd8c74013fbcf16db2a5e\n",
            "  Building wheel for libraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libraft-cu12: filename=libraft_cu12-25.2.0-py3-none-manylinux_2_28_x86_64.whl size=22311914 sha256=ef9ac99deec9fd2b5b67b88e8c84135a963cda553677048b01a99e1e8fac866b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/eb/f8/7221f323f4db20f7a2b52a432aaf57db5a91ace04c298ae06e\n",
            "  Building wheel for ucx-py-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucx-py-cu12: filename=ucx_py_cu12-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl size=2288214 sha256=4550e781576b8b855600f4731a489c2b124e55f7dfcb8438e76dea876c47c958\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/33/ec/770cb565db452511ae7e3a7dca0576463d566fe357c8ed7b59\n",
            "  Building wheel for ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucxx-cu12: filename=ucxx_cu12-0.42.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl size=725335 sha256=f3173262ad032899a7bbe7bcb1aec346246fdda3e84eaa909f2519b5b702b105\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/c9/73/d230d4204c9d12079812778542f992372f3739ef5c0322f38c\n",
            "  Building wheel for libucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libucxx-cu12: filename=libucxx_cu12-0.42.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl size=514759 sha256=852a1247b2e40ead703ebc7f4cc87c885787854fa89a01556c3403e1e2c5b120\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/70/6d/c8257996440e62cf9db49618493e7cf3187dd225321711eeae\n",
            "Successfully built cuml-cu12 cuvs-cu12 libcuml-cu12 pylibraft-cu12 raft-dask-cu12 distributed-ucxx-cu12 libcuvs-cu12 libraft-cu12 ucx-py-cu12 ucxx-cu12 libucxx-cu12\n",
            "Installing collected packages: sortedcontainers, pytz, nvtx, nvidia-ml-py, libkvikio-cu12, fastrlock, cuda-bindings, zipp, zict, urllib3, tzdata, typing_extensions, tornado, toolz, tblib, six, pyyaml, pynvml, pynvjitlink-cu12, pygments, pyarrow, psutil, packaging, nvidia-nvjitlink-cu12, nvidia-nvcomp-cu12, nvidia-curand-cu12, nvidia-cublas-cu12, numpy, msgpack, mdurl, MarkupSafe, locket, llvmlite, libucx-cu12, joblib, fsspec, cuda-python, cloudpickle, click, cachetools, ucx-py-cu12, scipy, rmm-cu12, python-dateutil, partd, nvidia-cusparse-cu12, nvidia-cufft-cu12, numba, markdown-it-py, libucxx-cu12, libcudf-cu12, jinja2, importlib_metadata, cupy-cuda12x, ucxx-cu12, treelite, rich, pylibcudf-cu12, pandas, nvidia-cusolver-cu12, numba-cuda, dask, libraft-cu12, distributed, dask-expr, cudf-cu12, rapids-dask-dependency, pylibraft-cu12, libcuvs-cu12, libcuml-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, cuvs-cu12, raft-dask-cu12, cuml-cu12\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: nvtx\n",
            "    Found existing installation: nvtx 0.2.11\n",
            "    Uninstalling nvtx-0.2.11:\n",
            "      Successfully uninstalled nvtx-0.2.11\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 12.570.86\n",
            "    Uninstalling nvidia-ml-py-12.570.86:\n",
            "      Successfully uninstalled nvidia-ml-py-12.570.86\n",
            "  Attempting uninstall: libkvikio-cu12\n",
            "    Found existing installation: libkvikio-cu12 24.12.1\n",
            "    Uninstalling libkvikio-cu12-24.12.1:\n",
            "      Successfully uninstalled libkvikio-cu12-24.12.1\n",
            "  Attempting uninstall: fastrlock\n",
            "    Found existing installation: fastrlock 0.8.3\n",
            "    Uninstalling fastrlock-0.8.3:\n",
            "      Successfully uninstalled fastrlock-0.8.3\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.21.0\n",
            "    Uninstalling zipp-3.21.0:\n",
            "      Successfully uninstalled zipp-3.21.0\n",
            "  Attempting uninstall: zict\n",
            "    Found existing installation: zict 3.0.0\n",
            "    Uninstalling zict-3.0.0:\n",
            "      Successfully uninstalled zict-3.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.4.2\n",
            "    Uninstalling tornado-6.4.2:\n",
            "      Successfully uninstalled tornado-6.4.2\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 1.0.0\n",
            "    Uninstalling toolz-1.0.0:\n",
            "      Successfully uninstalled toolz-1.0.0\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.4.1\n",
            "    Uninstalling pynvml-11.4.1:\n",
            "      Successfully uninstalled pynvml-11.4.1\n",
            "  Attempting uninstall: pynvjitlink-cu12\n",
            "    Found existing installation: pynvjitlink-cu12 0.5.2\n",
            "    Uninstalling pynvjitlink-cu12-0.5.2:\n",
            "      Successfully uninstalled pynvjitlink-cu12-0.5.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 7.0.0\n",
            "    Uninstalling psutil-7.0.0:\n",
            "      Successfully uninstalled psutil-7.0.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvcomp-cu12\n",
            "    Found existing installation: nvidia-nvcomp-cu12 4.1.0.6\n",
            "    Uninstalling nvidia-nvcomp-cu12-4.1.0.6:\n",
            "      Successfully uninstalled nvidia-nvcomp-cu12-4.1.0.6\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: locket\n",
            "    Found existing installation: locket 1.0.0\n",
            "    Uninstalling locket-1.0.0:\n",
            "      Successfully uninstalled locket-1.0.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.44.0\n",
            "    Uninstalling llvmlite-0.44.0:\n",
            "      Successfully uninstalled llvmlite-0.44.0\n",
            "  Attempting uninstall: libucx-cu12\n",
            "    Found existing installation: libucx-cu12 1.17.0.post1\n",
            "    Uninstalling libucx-cu12-1.17.0.post1:\n",
            "      Successfully uninstalled libucx-cu12-1.17.0.post1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: cuda-python\n",
            "    Found existing installation: cuda-python 12.6.0\n",
            "    Uninstalling cuda-python-12.6.0:\n",
            "      Successfully uninstalled cuda-python-12.6.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: ucx-py-cu12\n",
            "    Found existing installation: ucx-py-cu12 0.41.0\n",
            "    Uninstalling ucx-py-cu12-0.41.0:\n",
            "      Successfully uninstalled ucx-py-cu12-0.41.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: rmm-cu12\n",
            "    Found existing installation: rmm-cu12 24.12.1\n",
            "    Uninstalling rmm-cu12-24.12.1:\n",
            "      Successfully uninstalled rmm-cu12-24.12.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: partd\n",
            "    Found existing installation: partd 1.4.2\n",
            "    Uninstalling partd-1.4.2:\n",
            "      Successfully uninstalled partd-1.4.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.61.0\n",
            "    Uninstalling numba-0.61.0:\n",
            "      Successfully uninstalled numba-0.61.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: libucxx-cu12\n",
            "    Found existing installation: libucxx-cu12 0.41.0\n",
            "    Uninstalling libucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled libucxx-cu12-0.41.0\n",
            "  Attempting uninstall: libcudf-cu12\n",
            "    Found existing installation: libcudf-cu12 24.12.0\n",
            "    Uninstalling libcudf-cu12-24.12.0:\n",
            "      Successfully uninstalled libcudf-cu12-24.12.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: cupy-cuda12x\n",
            "    Found existing installation: cupy-cuda12x 13.4.0\n",
            "    Uninstalling cupy-cuda12x-13.4.0:\n",
            "      Successfully uninstalled cupy-cuda12x-13.4.0\n",
            "  Attempting uninstall: ucxx-cu12\n",
            "    Found existing installation: ucxx-cu12 0.41.0\n",
            "    Uninstalling ucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled ucxx-cu12-0.41.0\n",
            "  Attempting uninstall: treelite\n",
            "    Found existing installation: treelite 4.3.0\n",
            "    Uninstalling treelite-4.3.0:\n",
            "      Successfully uninstalled treelite-4.3.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pylibcudf-cu12\n",
            "    Found existing installation: pylibcudf-cu12 24.12.0\n",
            "    Uninstalling pylibcudf-cu12-24.12.0:\n",
            "      Successfully uninstalled pylibcudf-cu12-24.12.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: numba-cuda\n",
            "    Found existing installation: numba-cuda 0.0.17.1\n",
            "    Uninstalling numba-cuda-0.0.17.1:\n",
            "      Successfully uninstalled numba-cuda-0.0.17.1\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.11.2\n",
            "    Uninstalling dask-2024.11.2:\n",
            "      Successfully uninstalled dask-2024.11.2\n",
            "  Attempting uninstall: libraft-cu12\n",
            "    Found existing installation: libraft-cu12 25.2.0\n",
            "    Uninstalling libraft-cu12-25.2.0:\n",
            "      Successfully uninstalled libraft-cu12-25.2.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.11.2\n",
            "    Uninstalling distributed-2024.11.2:\n",
            "      Successfully uninstalled distributed-2024.11.2\n",
            "  Attempting uninstall: dask-expr\n",
            "    Found existing installation: dask-expr 1.1.19\n",
            "    Uninstalling dask-expr-1.1.19:\n",
            "      Successfully uninstalled dask-expr-1.1.19\n",
            "  Attempting uninstall: cudf-cu12\n",
            "    Found existing installation: cudf-cu12 24.12.0\n",
            "    Uninstalling cudf-cu12-24.12.0:\n",
            "      Successfully uninstalled cudf-cu12-24.12.0\n",
            "  Attempting uninstall: rapids-dask-dependency\n",
            "    Found existing installation: rapids-dask-dependency 24.12.0\n",
            "    Uninstalling rapids-dask-dependency-24.12.0:\n",
            "      Successfully uninstalled rapids-dask-dependency-24.12.0\n",
            "  Attempting uninstall: pylibraft-cu12\n",
            "    Found existing installation: pylibraft-cu12 24.12.0\n",
            "    Uninstalling pylibraft-cu12-24.12.0:\n",
            "      Successfully uninstalled pylibraft-cu12-24.12.0\n",
            "  Attempting uninstall: libcuvs-cu12\n",
            "    Found existing installation: libcuvs-cu12 25.2.1\n",
            "    Uninstalling libcuvs-cu12-25.2.1:\n",
            "      Successfully uninstalled libcuvs-cu12-25.2.1\n",
            "  Attempting uninstall: libcuml-cu12\n",
            "    Found existing installation: libcuml-cu12 25.2.1\n",
            "    Uninstalling libcuml-cu12-25.2.1:\n",
            "      Successfully uninstalled libcuml-cu12-25.2.1\n",
            "  Attempting uninstall: distributed-ucxx-cu12\n",
            "    Found existing installation: distributed-ucxx-cu12 0.41.0\n",
            "    Uninstalling distributed-ucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled distributed-ucxx-cu12-0.41.0\n",
            "  Attempting uninstall: dask-cudf-cu12\n",
            "    Found existing installation: dask-cudf-cu12 24.12.0\n",
            "    Uninstalling dask-cudf-cu12-24.12.0:\n",
            "      Successfully uninstalled dask-cudf-cu12-24.12.0\n",
            "  Attempting uninstall: dask-cuda\n",
            "    Found existing installation: dask-cuda 24.12.0\n",
            "    Uninstalling dask-cuda-24.12.0:\n",
            "      Successfully uninstalled dask-cuda-24.12.0\n",
            "  Attempting uninstall: cuvs-cu12\n",
            "    Found existing installation: cuvs-cu12 24.12.0\n",
            "    Uninstalling cuvs-cu12-24.12.0:\n",
            "      Successfully uninstalled cuvs-cu12-24.12.0\n",
            "  Attempting uninstall: raft-dask-cu12\n",
            "    Found existing installation: raft-dask-cu12 24.12.0\n",
            "    Uninstalling raft-dask-cu12-24.12.0:\n",
            "      Successfully uninstalled raft-dask-cu12-24.12.0\n",
            "  Attempting uninstall: cuml-cu12\n",
            "    Found existing installation: cuml-cu12 24.12.0\n",
            "    Uninstalling cuml-cu12-24.12.0:\n",
            "      Successfully uninstalled cuml-cu12-24.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "torch 2.6.0 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
            "torch 2.6.0 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 cuda-bindings-12.8.0 cuda-python-12.8.0 cudf-cu12-25.2.2 cuml-cu12-25.2.1 cupy-cuda12x-13.4.0 cuvs-cu12-25.2.1 dask-2024.12.1 dask-cuda-25.2.0 dask-cudf-cu12-25.2.2 dask-expr-1.1.21 distributed-2024.12.1 distributed-ucxx-cu12-0.42.0 fastrlock-0.8.3 fsspec-2025.3.0 importlib_metadata-8.6.1 jinja2-3.1.6 joblib-1.4.2 libcudf-cu12-25.2.2 libcuml-cu12-25.2.1 libcuvs-cu12-25.2.1 libkvikio-cu12-25.2.1 libraft-cu12-25.2.0 libucx-cu12-1.18.0 libucxx-cu12-0.42.0 llvmlite-0.43.0 locket-1.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.1.0 numba-0.60.0 numba-cuda-0.2.0 numpy-2.0.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cufft-cu12-11.3.3.83 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-ml-py-12.570.86 nvidia-nvcomp-cu12-4.2.0.11 nvidia-nvjitlink-cu12-12.8.93 nvtx-0.2.11 packaging-24.2 pandas-2.2.3 partd-1.4.2 psutil-7.0.0 pyarrow-19.0.1 pygments-2.19.1 pylibcudf-cu12-25.2.2 pylibraft-cu12-25.2.0 pynvjitlink-cu12-0.5.2 pynvml-12.0.0 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 raft-dask-cu12-25.2.0 rapids-dask-dependency-25.2.0 rich-13.9.4 rmm-cu12-25.2.0 scipy-1.15.2 six-1.17.0 sortedcontainers-2.4.0 tblib-3.0.0 toolz-1.0.0 tornado-6.4.2 treelite-4.4.1 typing_extensions-4.12.2 tzdata-2025.1 ucx-py-cu12-0.42.0 ucxx-cu12-0.42.0 urllib3-2.3.0 zict-3.0.0 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "importlib_metadata",
                  "psutil",
                  "rapids_dask_dependency",
                  "six",
                  "tornado",
                  "zipp"
                ]
              },
              "id": "949ba7c7e7b842078c6ec6b2d4353139"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install --force-reinstall cudf-cu12 cuml-cu12 rapids-dask-dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BxX4NtYJaEE",
        "outputId": "c7501d1a-0ba9-4b3d-9edf-e4abbc0434cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuDF Version: 25.02.02\n",
            "cuML Version: 25.02.01\n",
            "Dask Version: 2024.12.1\n",
            "Stable Baselines3 Installed: 2.5.0\n",
            "Gymnasium Version: 0.29.1\n",
            "NumPy Version: 2.0.2\n",
            "SciPy Version: 1.15.2\n",
            "Pandas Version: 2.2.3\n",
            "Mon Mar 17 16:02:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#Core Libraries\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import numba\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "#Machine Learning & Data Processing\n",
        "import xgboost as xgb\n",
        "import yfinance as yf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#RAPIDS Libraries (cuDF & cuML for GPU acceleration)\n",
        "import cudf\n",
        "import cuml\n",
        "import dask\n",
        "\n",
        "#Reinforcement Learning (Stable Baselines3)\n",
        "import torch\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import A2C, PPO, DDPG\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "#Gym & Trading Environments\n",
        "import gymnasium as gym  #Use Gymnasium instead of Gym\n",
        "from gymnasium.spaces import Discrete, Box\n",
        "from gymnasium.wrappers import TimeLimit\n",
        "import gym_anytrading\n",
        "from gym_anytrading.envs import StocksEnv\n",
        "\n",
        "#TensorFlow & GPU Optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "#Set CUDA Paths\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-11.8'\n",
        "os.environ['PATH'] += ':/usr/local/cuda-11.8/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda-11.8/lib64'\n",
        "\n",
        "#Print Version Check\n",
        "print(\"cuDF Version:\", cudf.__version__)\n",
        "print(\"cuML Version:\", cuml.__version__)\n",
        "print(\"Dask Version:\", dask.__version__)\n",
        "print(\"Stable Baselines3 Installed:\", stable_baselines3.__version__)\n",
        "print(\"Gymnasium Version:\", gym.__version__)\n",
        "print(\"NumPy Version:\", np.__version__)\n",
        "print(\"SciPy Version:\", scipy.__version__)\n",
        "print(\"Pandas Version:\", pd.__version__)\n",
        "\n",
        "#GPU Check\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Discrete Trading Environment\n",
        "class DiscreteTradingEnv(gym.Env):\n",
        "    def __init__(self, df, frame_bound=(10, 100), window_size=10, verbose=False):\n",
        "        super(DiscreteTradingEnv, self).__init__()\n",
        "        self.df = df\n",
        "        self.frame_bound = frame_bound\n",
        "        self.window_size = window_size\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "        self.verbose = verbose\n",
        "\n",
        "        #Portfolio & Trading Variables\n",
        "        self.initial_balance = 100000\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "        self.position_size = 0.1  # 10% of the portfolio per trade\n",
        "\n",
        "        #Logging Trades & Rewards\n",
        "        self.trade_log = []\n",
        "        self.rewards_log = []\n",
        "\n",
        "        #Define Action and Observation Space\n",
        "        self.action_space = Discrete(3)  # Actions: 0 = SELL, 1 = HOLD, 2 = BUY\n",
        "        self.observation_space = Box(low=-np.inf, high=np.inf, shape=(window_size + 2,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "\n",
        "        #Reset Portfolio\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "\n",
        "        #Clear Logs\n",
        "        self.trade_log.clear()\n",
        "        self.rewards_log.clear()\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            self.done = True\n",
        "            return self._next_observation(), 0, self.done, False, {}\n",
        "\n",
        "        self.current_step += 1\n",
        "        new_price = self.df['Close'].iloc[self.current_step]\n",
        "\n",
        "        reward = 0  # Default reward\n",
        "        executed = False  # Track if a trade was executed\n",
        "\n",
        "        #BUY ACTION (Require a Bigger Price Drop Before Buying)\n",
        "        if action == 2:\n",
        "            allocated_funds = min(self.portfolio_value * self.position_size, self.portfolio_value * 0.3)\n",
        "            if self.portfolio_value >= allocated_funds:\n",
        "                shares_bought = allocated_funds / new_price\n",
        "                self.shares_held += shares_bought\n",
        "                self.portfolio_value -= shares_bought * new_price\n",
        "                self.last_trade_price = new_price\n",
        "                executed = True\n",
        "\n",
        "                #Adjusted Reward Logic for Better Training\n",
        "                price_change = (self.df['Close'].iloc[self.current_step - 1] - new_price) / max(new_price, 1e-6)\n",
        "                if price_change > 0.01:  # 1%+ Drop → High Reward\n",
        "                    reward = price_change * 80\n",
        "                elif price_change > 0.005:  # 0.5%+ Drop → Moderate Reward\n",
        "                    reward = price_change * 60\n",
        "                else:\n",
        "                    reward = 0.003  #No negative BUY rewards!\n",
        "\n",
        "        #SELL ACTION (Encourage Profitable Selling)\n",
        "        elif action == 0 and self.shares_held > 0:\n",
        "            sell_value = self.shares_held * new_price\n",
        "            profit = (new_price - self.last_trade_price) * self.shares_held\n",
        "\n",
        "            #Require at Least 2% Profit Before Selling\n",
        "            profit_percent = (new_price - self.last_trade_price) / max(self.last_trade_price, 1e-6)\n",
        "            if profit_percent > 0.02:\n",
        "                reward = profit_percent * 350  # Strong reward for good sales\n",
        "            else:\n",
        "                reward = profit_percent * 10  # Reduce penalty for small losses\n",
        "\n",
        "            #Reset portfolio after calculation\n",
        "            self.portfolio_value += sell_value\n",
        "            self.shares_held = 0\n",
        "            self.last_trade_price = 0\n",
        "            executed = True\n",
        "\n",
        "        #HOLD ACTION (Encourage Holding If Profitable)\n",
        "        else:\n",
        "            unrealized_profit = (new_price - self.last_trade_price) * self.shares_held\n",
        "            reward = np.tanh(unrealized_profit / self.initial_balance) * 5\n",
        "\n",
        "        #Log Trade\n",
        "        self.trade_log.append({\n",
        "            \"Step\": self.current_step,\n",
        "            \"Action\": [\"SELL\", \"HOLD\", \"BUY\"][action],\n",
        "            \"Shares Held\": self.shares_held,\n",
        "            \"Portfolio Value\": self.portfolio_value,\n",
        "            \"Stock Price\": new_price,\n",
        "            \"Reward\": reward\n",
        "        })\n",
        "\n",
        "        self.rewards_log.append(reward)\n",
        "\n",
        "        return self._next_observation(), reward, self.done, False, {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        stock_prices = np.array(self.df['Close'].iloc[self.current_step - self.window_size:self.current_step], dtype=np.float32)\n",
        "        return np.concatenate(([self.portfolio_value], stock_prices, [self.shares_held]))\n"
      ],
      "metadata": {
        "id": "1CVQi1kty22q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKG932vFKBfA",
        "outputId": "8af11fe6-0a36-4c82-9561-ed7ff49e24c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow GPU memory growth enabled\n",
            "Attempt 1: Downloading AAPL stock data...\n",
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded stock data!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Ensure TensorFlow GPU Memory Allocation is Configured\n",
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)  # Prevents full allocation\n",
        "        print(\"TensorFlow GPU memory growth enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"TensorFlow GPU memory issue: {e}\")\n",
        "\n",
        "#CUDA Paths\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-11.8'\n",
        "os.environ['PATH'] += ':/usr/local/cuda-11.8/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda-11.8/lib64'\n",
        "\n",
        "\n",
        "\n",
        "def download_stock_data(ticker, period=\"720d\", interval=\"1h\", max_retries=5):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt}: Downloading {ticker} stock data...\")\n",
        "            df_live = yf.download(ticker, period=period, interval=interval)\n",
        "            if not df_live.empty:\n",
        "                print(\"Successfully downloaded stock data!\")\n",
        "                df_live.reset_index(inplace=True)\n",
        "                return df_live\n",
        "            raise ValueError(\"Downloaded data is empty. Retrying...\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}. Retrying in {attempt * 5} seconds...\")\n",
        "            time.sleep(attempt * 5)\n",
        "    print(\"Failed to download stock data after multiple attempts.\")\n",
        "    return None\n",
        "\n",
        "df_live = download_stock_data(\"AAPL\")\n",
        "if df_live is None:\n",
        "    print(\"Using previously saved dataset instead.\")\n",
        "    file_path = '/content/drive/My Drive/aaplfeature_engineered_dataset.csv'\n",
        "    df_live = pd.read_csv(file_path)\n",
        "\n",
        "df = df_live.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p9Iyp3gMLizz"
      },
      "outputs": [],
      "source": [
        "#Fix Missing Index\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MiabhGq1Lz-n"
      },
      "outputs": [],
      "source": [
        "#Step 3: Feature Engineering\n",
        "def compute_technical_indicators(df):\n",
        "    #Simple Moving Average (SMA) & Bollinger Bands\n",
        "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
        "    df['STD_20'] = df['Close'].rolling(window=20).std()\n",
        "\n",
        "    df['Upper_Band'] = df['SMA_20'] + 2 * df['STD_20']\n",
        "    df['Lower_Band'] = df['SMA_20'] - 2 * df['STD_20']  #Added Lower Band\n",
        "\n",
        "    #Stochastic Oscillator\n",
        "    df['Lowest_Low'] = df['Low'].rolling(window=14).min()\n",
        "    df['Highest_High'] = df['High'].rolling(window=14).max()\n",
        "    df['Stoch'] = ((df['Close'] - df['Lowest_Low']) / (df['Highest_High'] - df['Lowest_Low'])) * 100\n",
        "\n",
        "    #Rolling Volatility Feature\n",
        "    df['volatility'] = df['Close'].pct_change().rolling(20).std()\n",
        "\n",
        "    #Drop NA values after feature calculations\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "#Step 4: Labeling (Buy/Sell Signals)\n",
        "def generate_trade_labels(df, lookahead=10, threshold_factor=2):\n",
        "    #Ensure 'Close' column exists\n",
        "    if 'Close' not in df.columns:\n",
        "        raise KeyError(\"'Close' column is missing. Cannot generate trade labels.\")\n",
        "\n",
        "    #Generate future price shift\n",
        "    df['Future_Close'] = df['Close'].shift(-lookahead)\n",
        "    df['Price_Change'] = (df['Future_Close'] - df['Close']) / df['Close']\n",
        "\n",
        "    #Primary Target Label: Binary Classification (Buy = 1, Sell = 0)\n",
        "    df['Target'] = np.where(df['Price_Change'] > 0.03, 1, 0)\n",
        "\n",
        "    #Volatility-Adjusted Dynamic Labels\n",
        "    buy_threshold = df['volatility'] * threshold_factor\n",
        "    sell_threshold = -df['volatility'] * threshold_factor\n",
        "\n",
        "    df['Dynamic_Label'] = np.where(df['Price_Change'] > buy_threshold, 1,\n",
        "                            np.where(df['Price_Change'] < sell_threshold, -1, 0))\n",
        "\n",
        "    #Drop NaN values after target calculations\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "#Apply Feature Engineering & Target Labeling\n",
        "df = compute_technical_indicators(df)  #Compute Features\n",
        "df = generate_trade_labels(df)  #Generate 'Target' Column\n",
        "\n",
        "#Check if 'Target' exists before training\n",
        "if 'Target' not in df.columns:\n",
        "    raise KeyError(\"'Target' column is missing after feature engineering. Check generate_trade_labels(df).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhbHD6ibMJuR",
        "outputId": "bb8a5a5d-79a1-40a3-a06c-e19b65a604d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Accuracy Across Time Splits: 0.9048\n",
            "\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.97      0.97       808\n",
            "         1.0       0.00      0.00      0.00        22\n",
            "\n",
            "    accuracy                           0.95       830\n",
            "   macro avg       0.49      0.49      0.49       830\n",
            "weighted avg       0.95      0.95      0.95       830\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def train_walk_forward(df, features, label='Target'):\n",
        "    (((\"\\\((\"\\\"Train a Random Forest model using time-based walk-forward validation.(((\"\\\\"(((\"\\\\n",
        "\n",
        "    #Ensure train-test splits are time-based\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(df):\n",
        "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
        "\n",
        "        #Convert pandas to cudf for GPU acceleration (ensure float32)\n",
        "        X_train = cudf.DataFrame.from_pandas(train[features]).astype(np.float32)\n",
        "        y_train = cudf.Series(train[label].astype(np.float32))\n",
        "\n",
        "        X_test = cudf.DataFrame.from_pandas(test[features]).astype(np.float32)\n",
        "        y_test = cudf.Series(test[label].astype(np.float32))\n",
        "\n",
        "        #Convert to Pandas before using SMOTE\n",
        "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train.to_pandas(), y_train.to_pandas())\n",
        "\n",
        "        #Convert back to cuDF\n",
        "        X_train = cudf.DataFrame.from_pandas(X_resampled)\n",
        "        y_train = cudf.Series(y_resampled)\n",
        "\n",
        "        #Ensure data is available before training\n",
        "        if X_train.shape[0] == 0:\n",
        "            raise ValueError(\"No training data available! Ensure features are correctly calculated.\")\n",
        "\n",
        "        #Convert X_train and y_train back to Pandas before fitting\n",
        "        model = RandomForestClassifier(n_estimators=100)\n",
        "        model.fit(X_train.to_pandas(), y_train.to_pandas())  #Explicit conversion\n",
        "\n",
        "        #Convert X_test to Pandas before prediction\n",
        "        probs = model.predict_proba(X_test.to_pandas())  #Fix: Convert before calling predict_proba\n",
        "        custom_threshold = 0.4  # Adjust if needed\n",
        "        preds = (probs[:, 1] > custom_threshold).astype(int)\n",
        "\n",
        "        #Convert y_test to Pandas before using NumPy functions\n",
        "        y_test = y_test.to_pandas().to_numpy()  #Fix: Convert cuDF Series → Pandas → NumPy\n",
        "\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        accuracy_scores.append(acc)\n",
        "\n",
        "    print(f\"Avg Accuracy Across Time Splits: {np.mean(accuracy_scores):.4f}\")\n",
        "\n",
        "    #Print Classification Report\n",
        "    print((((\"\\\\\nRandom Forest Classification Report:\")\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "    return model\n",
        "\n",
        "#Run the corrected function\n",
        "features = ['SMA_20', 'STD_20', 'Upper_Band', 'Lower_Band', 'Stoch', 'volatility']\n",
        "model = train_walk_forward(df, features, label='Target')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ZTff0SMNx4",
        "outputId": "66f9edeb-0c69-4faa-cfb6-02d1ccb3be5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features and labels are ready for XGBoost training.\n"
          ]
        }
      ],
      "source": [
        "#Ensure Feature Engineering is Applied Before Training\n",
        "if \"SMA_20\" not in df.columns:  # Prevent recomputation\n",
        "    df = compute_technical_indicators(df)\n",
        "\n",
        "df = generate_trade_labels(df)  #Generate Buy/Sell Labels\n",
        "\n",
        "#Ensure Features & Trade Signals Exist\n",
        "required_features = ['SMA_20', 'STD_20', 'Upper_Band', 'Lower_Band', 'Stoch', 'volatility']\n",
        "if not all(feature in df.columns for feature in required_features):\n",
        "    raise ValueError(f\"Missing Features: {set(required_features) - set(df.columns)}. Run feature engineering first!\")\n",
        "\n",
        "if 'Target' not in df.columns:\n",
        "    raise ValueError(\"Target column is missing! Run generate_trade_labels(df) first!\")\n",
        "\n",
        "print(\"Features and labels are ready for XGBoost training.\")\n",
        "\n",
        "#Drop NaN Values Before Training\n",
        "df.dropna(subset=required_features + ['Target'], inplace=True)\n",
        "\n",
        "#Define Feature Columns & Target\n",
        "feature_columns = required_features\n",
        "target_column = 'Target'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_xgboost(df, features, label='Target'):\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(df):\n",
        "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
        "\n",
        "        #Keep data on GPU\n",
        "        X_train = cudf.DataFrame(train[features]).astype(np.float32)\n",
        "        y_train = cudf.Series(train[label].astype(np.float32))\n",
        "\n",
        "        X_test = cudf.DataFrame(test[features]).astype(np.float32)\n",
        "        y_test = cudf.Series(test[label].astype(np.float32))\n",
        "\n",
        "        #Fix scale_pos_weight calculation\n",
        "        scale_pos_weight = (sum(y_train.to_numpy() == 0) / (sum(y_train.to_numpy() == 1) + 1e-6))\n",
        "\n",
        "        #Use latest GPU-optimized settings\n",
        "        params = {\n",
        "            'objective': 'binary:logistic',\n",
        "            'learning_rate': 0.1,\n",
        "            'n_estimators': 50,\n",
        "            'tree_method': 'hist',  #Use \"hist\" instead of \"gpu_hist(((\"\\\\n",
        "            'device': 'cuda',       #Explicitly set GPU device\n",
        "            'scale_pos_weight': scale_pos_weight,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        #Convert cuDF to NumPy for XGBoost compatibility\n",
        "        X_train_np = X_train.to_numpy()\n",
        "        y_train_np = y_train.to_numpy()\n",
        "\n",
        "        X_test_np = X_test.to_numpy()\n",
        "        y_test_np = y_test.to_numpy()\n",
        "\n",
        "        #Train model\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        model.fit(X_train_np, y_train_np)\n",
        "\n",
        "        #Use probability threshold for better predictions\n",
        "        probs = model.predict_proba(X_test_np)\n",
        "        custom_threshold = 0.4  #Adjust if needed\n",
        "        preds = (probs[:, 1] > custom_threshold).astype(int)\n",
        "\n",
        "        acc = accuracy_score(y_test_np, preds)\n",
        "        accuracy_scores.append(acc)\n",
        "\n",
        "    print(f\"Avg Accuracy Across Time Splits: {np.mean(accuracy_scores):.4f}\")\n",
        "\n",
        "    #Print Classification Report\n",
        "    print((((\"\\\\\nXGBoost Classification Report:\")\n",
        "    print(classification_report(y_test_np, preds))\n",
        "\n",
        "    return model\n",
        "\n",
        "#Run XGBoost Training with New Features\n",
        "xgb_model = train_xgboost(df, feature_columns, label=target_column)\n",
        "\n",
        "#Free Memory\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXwGIbbrMEmU",
        "outputId": "cb63be52-e385-4aeb-f59e-0cf1d9c292df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:02:12] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Accuracy Across Time Splits: 0.9184\n",
            "\n",
            "XGBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.97      0.97       800\n",
            "         1.0       0.05      0.04      0.04        28\n",
            "\n",
            "    accuracy                           0.94       828\n",
            "   macro avg       0.51      0.50      0.51       828\n",
            "weighted avg       0.94      0.94      0.94       828\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "275"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Discrete Trading Environment\n",
        "class DiscreteTradingEnv(gym.Env):\n",
        "    def __init__(self, df, frame_bound=(10, 100), window_size=10, verbose=False):\n",
        "        super(DiscreteTradingEnv, self).__init__()\n",
        "        self.df = df\n",
        "        self.frame_bound = frame_bound\n",
        "        self.window_size = window_size\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "        self.verbose = verbose\n",
        "\n",
        "        #Portfolio & Trading Variables\n",
        "        self.initial_balance = 100000\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "        self.position_size = 0.1  # 10% of the portfolio per trade\n",
        "\n",
        "        #Logging Trades & Rewards\n",
        "        self.trade_log = []\n",
        "        self.rewards_log = []\n",
        "\n",
        "        #Define Action and Observation Space\n",
        "        self.action_space = Discrete(3)  # Actions: 0 = SELL, 1 = HOLD, 2 = BUY\n",
        "        self.observation_space = Box(low=-np.inf, high=np.inf, shape=(window_size + 2,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.done = False\n",
        "\n",
        "        #Reset Portfolio\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.last_trade_price = 0\n",
        "\n",
        "        #Clear Logs\n",
        "        self.trade_log.clear()\n",
        "        self.rewards_log.clear()\n",
        "\n",
        "        return self._next_observation(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            self.done = True\n",
        "            return self._next_observation(), 0, self.done, False, {}\n",
        "\n",
        "        self.current_step += 1\n",
        "        new_price = self.df['Close'].iloc[self.current_step]\n",
        "\n",
        "        reward = 0  # Default reward\n",
        "        executed = False  # Track if a trade was executed\n",
        "\n",
        "        #BUY ACTION (Require a Bigger Price Drop Before Buying)\n",
        "        if action == 2:\n",
        "            allocated_funds = min(self.portfolio_value * self.position_size, self.portfolio_value * 0.3)\n",
        "            if self.portfolio_value >= allocated_funds:\n",
        "                shares_bought = allocated_funds / new_price\n",
        "                self.shares_held += shares_bought\n",
        "                self.portfolio_value -= shares_bought * new_price\n",
        "                self.last_trade_price = new_price\n",
        "                executed = True\n",
        "\n",
        "                #Adjusted Reward Logic for Better Training\n",
        "                price_change = (self.df['Close'].iloc[self.current_step - 1] - new_price) / max(new_price, 1e-6)\n",
        "                if price_change > 0.01:  # 1%+ Drop → High Reward\n",
        "                    reward = price_change * 80\n",
        "                elif price_change > 0.005:  # 0.5%+ Drop → Moderate Reward\n",
        "                    reward = price_change * 60\n",
        "                else:\n",
        "                    reward = 0.003  #No negative BUY rewards!\n",
        "\n",
        "        #SELL ACTION (Encourage Profitable Selling)\n",
        "        elif action == 0 and self.shares_held > 0:\n",
        "            sell_value = self.shares_held * new_price\n",
        "            profit = (new_price - self.last_trade_price) * self.shares_held\n",
        "\n",
        "            #Require at Least 2% Profit Before Selling\n",
        "            profit_percent = (new_price - self.last_trade_price) / max(self.last_trade_price, 1e-6)\n",
        "            if profit_percent > 0.02:\n",
        "                reward = profit_percent * 350  # Strong reward for good sales\n",
        "            else:\n",
        "                reward = profit_percent * 10  # Reduce penalty for small losses\n",
        "\n",
        "            #Reset portfolio after calculation\n",
        "            self.portfolio_value += sell_value\n",
        "            self.shares_held = 0\n",
        "            self.last_trade_price = 0\n",
        "            executed = True\n",
        "\n",
        "        #HOLD ACTION (Encourage Holding If Profitable)\n",
        "        else:\n",
        "            unrealized_profit = (new_price - self.last_trade_price) * self.shares_held\n",
        "            reward = np.tanh(unrealized_profit / self.initial_balance) * 5\n",
        "\n",
        "        #Log Trade\n",
        "        self.trade_log.append({\n",
        "            \"Step\": self.current_step,\n",
        "            \"Action\": [\"SELL\", \"HOLD\", \"BUY\"][action],\n",
        "            \"Shares Held\": self.shares_held,\n",
        "            \"Portfolio Value\": self.portfolio_value,\n",
        "            \"Stock Price\": new_price,\n",
        "            \"Reward\": reward\n",
        "        })\n",
        "\n",
        "        self.rewards_log.append(reward)\n",
        "\n",
        "        return self._next_observation(), reward, self.done, False, {}\n",
        "\n",
        "    def _next_observation(self):\n",
        "        stock_prices = np.array(self.df['Close'].iloc[self.current_step - self.window_size:self.current_step], dtype=np.float32)\n",
        "        return np.concatenate(([self.portfolio_value], stock_prices, [self.shares_held]))\n",
        "\n",
        "#Step 1: Define Environment Creation Function\n",
        "def make_env():\n",
        "    return gym.wrappers.TimeLimit(\n",
        "        DiscreteTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10),\n",
        "        max_episode_steps=1000\n",
        "    )\n",
        "\n",
        "#Step 2: Properly Create Vectorized Environment\n",
        "env_discrete = make_vec_env(make_env, n_envs=1)\n",
        "\n",
        "#Step 3: Normalize Environment (Fixed Method)\n",
        "env_discrete = VecNormalize(env_discrete, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
        "\n",
        "#Step 4: Debugging Action Space\n",
        "print(f\"Action Space: {env_discrete.action_space}\")\n",
        "print(f\"Sample Action: {env_discrete.action_space.sample()}\")\n",
        "\n",
        "#Step 5: Train PPO Model\n",
        "print((((\"\\\\\nTraining PPO Model...\")\n",
        "ppo_model = PPO(\"MlpPolicy\", env_discrete, verbose=1, device=\"cuda\")\n",
        "ppo_model.learn(total_timesteps=100000)\n",
        "ppo_model.save(\"ppo_trading_model\")\n",
        "print((((\"\\\\\nPPO Training Complete!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf8dSzkExUSP",
        "outputId": "efa85f95-777e-4ee0-be4f-88c45c1af7d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(3)\n",
            "Sample Action: 0\n",
            "\n",
            "Training PPO Model...\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 111      |\n",
            "| time/              |          |\n",
            "|    fps             | 399      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 107          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 303          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069961855 |\n",
            "|    clip_fraction        | 0.0439       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | -0.023       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.132        |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0051      |\n",
            "|    value_loss           | 0.693        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 115         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 280         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007931207 |\n",
            "|    clip_fraction        | 0.0431      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | 0.103       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.072       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00542    |\n",
            "|    value_loss           | 0.171       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 117         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 271         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011266355 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | 0.196       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.091       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00891    |\n",
            "|    value_loss           | 0.169       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 119         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 288         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009263654 |\n",
            "|    clip_fraction        | 0.0794      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.31        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0351      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00467    |\n",
            "|    value_loss           | 0.147       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 123         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 298         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009098198 |\n",
            "|    clip_fraction        | 0.0684      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0.203       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.091       |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00522    |\n",
            "|    value_loss           | 0.148       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 124         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 287         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 49          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012346653 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.982      |\n",
            "|    explained_variance   | 0.361       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.168       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.011      |\n",
            "|    value_loss           | 0.18        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 124        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 283        |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 57         |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00783537 |\n",
            "|    clip_fraction        | 0.0759     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.938     |\n",
            "|    explained_variance   | 0.38       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0465     |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | -0.00588   |\n",
            "|    value_loss           | 0.141      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 128         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 290         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 63          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006892103 |\n",
            "|    clip_fraction        | 0.0574      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.891      |\n",
            "|    explained_variance   | 0.428       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0652      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00517    |\n",
            "|    value_loss           | 0.148       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 131          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 279          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048858877 |\n",
            "|    clip_fraction        | 0.0452       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.904       |\n",
            "|    explained_variance   | 0.385        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0886       |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00428     |\n",
            "|    value_loss           | 0.222        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 134         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 284         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 79          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005672479 |\n",
            "|    clip_fraction        | 0.0396      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.875      |\n",
            "|    explained_variance   | 0.493       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.209       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00321    |\n",
            "|    value_loss           | 0.187       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 136          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 288          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047495086 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.844       |\n",
            "|    explained_variance   | 0.557        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0566       |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00234     |\n",
            "|    value_loss           | 0.17         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 137         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 292         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 91          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004459939 |\n",
            "|    clip_fraction        | 0.0386      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.848      |\n",
            "|    explained_variance   | 0.443       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0592      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00386    |\n",
            "|    value_loss           | 0.223       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 139         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 297         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 96          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004768815 |\n",
            "|    clip_fraction        | 0.0453      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.827      |\n",
            "|    explained_variance   | 0.455       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.13        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00505    |\n",
            "|    value_loss           | 0.177       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 141          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 299          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 102          |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067307334 |\n",
            "|    clip_fraction        | 0.0414       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.841       |\n",
            "|    explained_variance   | 0.463        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0886       |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00398     |\n",
            "|    value_loss           | 0.194        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 142          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 303          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 107          |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045763548 |\n",
            "|    clip_fraction        | 0.0338       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.796       |\n",
            "|    explained_variance   | 0.449        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0311       |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    value_loss           | 0.225        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 145          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 305          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 113          |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037864656 |\n",
            "|    clip_fraction        | 0.0583       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.754       |\n",
            "|    explained_variance   | 0.6          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0467       |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00359     |\n",
            "|    value_loss           | 0.0918       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 148         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 309         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 119         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004408599 |\n",
            "|    clip_fraction        | 0.0366      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.742      |\n",
            "|    explained_variance   | 0.494       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.062       |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00186    |\n",
            "|    value_loss           | 0.191       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 149         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 311         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 124         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005469066 |\n",
            "|    clip_fraction        | 0.0472      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.717      |\n",
            "|    explained_variance   | 0.46        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.17        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00422    |\n",
            "|    value_loss           | 0.248       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 150          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 315          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 129          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038788929 |\n",
            "|    clip_fraction        | 0.0355       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.677       |\n",
            "|    explained_variance   | 0.585        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0563       |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00355     |\n",
            "|    value_loss           | 0.158        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 152         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 317         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 135         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004860753 |\n",
            "|    clip_fraction        | 0.0566      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.661      |\n",
            "|    explained_variance   | 0.6         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0582      |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00374    |\n",
            "|    value_loss           | 0.16        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 153         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 320         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 140         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004710652 |\n",
            "|    clip_fraction        | 0.0375      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.652      |\n",
            "|    explained_variance   | 0.602       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0825      |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00431    |\n",
            "|    value_loss           | 0.133       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 154         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 322         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 145         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003772779 |\n",
            "|    clip_fraction        | 0.035       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.602      |\n",
            "|    explained_variance   | 0.665       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0592      |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00218    |\n",
            "|    value_loss           | 0.131       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 156         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 324         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 151         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003066088 |\n",
            "|    clip_fraction        | 0.0413      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.57       |\n",
            "|    explained_variance   | 0.545       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0905      |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00259    |\n",
            "|    value_loss           | 0.203       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 157         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 326         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 156         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004161762 |\n",
            "|    clip_fraction        | 0.0463      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.551      |\n",
            "|    explained_variance   | 0.573       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.189       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00461    |\n",
            "|    value_loss           | 0.226       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 158          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 327          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 162          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038619218 |\n",
            "|    clip_fraction        | 0.0405       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.515       |\n",
            "|    explained_variance   | 0.704        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.072        |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00329     |\n",
            "|    value_loss           | 0.126        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 158          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 329          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 167          |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021983783 |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.529       |\n",
            "|    explained_variance   | 0.593        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.102        |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00151     |\n",
            "|    value_loss           | 0.22         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 160         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 330         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 173         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004446051 |\n",
            "|    clip_fraction        | 0.0383      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.521      |\n",
            "|    explained_variance   | 0.657       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.102       |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00328    |\n",
            "|    value_loss           | 0.154       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 161          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 178          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041507445 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.5         |\n",
            "|    explained_variance   | 0.645        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0646       |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    value_loss           | 0.148        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 163          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 332          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 184          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020286948 |\n",
            "|    clip_fraction        | 0.0193       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.499       |\n",
            "|    explained_variance   | 0.611        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0818       |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    value_loss           | 0.174        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 163          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 334          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 189          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028122843 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.501       |\n",
            "|    explained_variance   | 0.59         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0686       |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    value_loss           | 0.177        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 164         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 335         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 195         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004544377 |\n",
            "|    clip_fraction        | 0.0467      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.507      |\n",
            "|    explained_variance   | 0.676       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0315      |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.00353    |\n",
            "|    value_loss           | 0.111       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 165          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 336          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 200          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034975675 |\n",
            "|    clip_fraction        | 0.0295       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.463       |\n",
            "|    explained_variance   | 0.572        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0852       |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00185     |\n",
            "|    value_loss           | 0.201        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 166          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 336          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 206          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026854507 |\n",
            "|    clip_fraction        | 0.0352       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.423       |\n",
            "|    explained_variance   | 0.627        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.122        |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00362     |\n",
            "|    value_loss           | 0.138        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 168          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 337          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 212          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020934418 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.42        |\n",
            "|    explained_variance   | 0.574        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0368       |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.0014      |\n",
            "|    value_loss           | 0.155        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 168         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 217         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003978448 |\n",
            "|    clip_fraction        | 0.0361      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.439      |\n",
            "|    explained_variance   | 0.524       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0909      |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.00383    |\n",
            "|    value_loss           | 0.213       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 169          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 339          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 223          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031345189 |\n",
            "|    clip_fraction        | 0.0348       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.442       |\n",
            "|    explained_variance   | 0.573        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0356       |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00347     |\n",
            "|    value_loss           | 0.181        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 170          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 228          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025284938 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.446       |\n",
            "|    explained_variance   | 0.637        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0749       |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.0035      |\n",
            "|    value_loss           | 0.154        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 171         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 233         |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002906313 |\n",
            "|    clip_fraction        | 0.0392      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.439      |\n",
            "|    explained_variance   | 0.559       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0659      |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.00263    |\n",
            "|    value_loss           | 0.194       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 172          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 239          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030306738 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.429       |\n",
            "|    explained_variance   | 0.676        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0665       |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    value_loss           | 0.164        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 172          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 343          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 244          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026442145 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.427       |\n",
            "|    explained_variance   | 0.646        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.132        |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    value_loss           | 0.142        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 174         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 344         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 249         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002255838 |\n",
            "|    clip_fraction        | 0.0413      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.4        |\n",
            "|    explained_variance   | 0.672       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0544      |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00253    |\n",
            "|    value_loss           | 0.145       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 175          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 344          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 255          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014450056 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.421       |\n",
            "|    explained_variance   | 0.607        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.109        |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    value_loss           | 0.208        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 176          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 345          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 260          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029918007 |\n",
            "|    clip_fraction        | 0.0255       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.391       |\n",
            "|    explained_variance   | 0.65         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0727       |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    value_loss           | 0.167        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 176          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 266          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022310535 |\n",
            "|    clip_fraction        | 0.0251       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.388       |\n",
            "|    explained_variance   | 0.597        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0914       |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.00187     |\n",
            "|    value_loss           | 0.191        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 176          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 271          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038233725 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.341       |\n",
            "|    explained_variance   | 0.695        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0235       |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00349     |\n",
            "|    value_loss           | 0.119        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 177          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 276          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030638091 |\n",
            "|    clip_fraction        | 0.028        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.334       |\n",
            "|    explained_variance   | 0.697        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0643       |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    value_loss           | 0.137        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 178          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 282          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024566199 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.343       |\n",
            "|    explained_variance   | 0.631        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0746       |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    value_loss           | 0.138        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 179          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 288          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044960333 |\n",
            "|    clip_fraction        | 0.045        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.311       |\n",
            "|    explained_variance   | 0.694        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0927       |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00424     |\n",
            "|    value_loss           | 0.161        |\n",
            "------------------------------------------\n",
            "\n",
            "PPO Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Define Environment Creation Function\n",
        "def make_env():\n",
        "    return gym.wrappers.TimeLimit(\n",
        "        DiscreteTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10),\n",
        "        max_episode_steps=1000\n",
        "    )\n",
        "\n",
        "#Step 2: Properly Create Vectorized Environment\n",
        "env_discrete = make_vec_env(make_env, n_envs=1)\n",
        "\n",
        "#Step 3: Normalize Environment (Fixed Method)\n",
        "env_discrete = VecNormalize(env_discrete, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
        "\n",
        "#Step 4: Debugging Action Space\n",
        "print(f\"Action Space: {env_discrete.action_space}\")\n",
        "print(f\"Sample Action: {env_discrete.action_space.sample()}\")\n",
        "\n",
        "#Step 5: Train PPO Model\n",
        "print((((\"\\\\\nTraining PPO Model...\")\n",
        "ppo_model = PPO(\"MlpPolicy\", env_discrete, verbose=1, device=\"cuda\")\n",
        "ppo_model.learn(total_timesteps=100000)\n",
        "ppo_model.save(\"ppo_trading_model\")\n",
        "print((((\"\\\\\nPPO Training Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVBf5Gro_gSf",
        "outputId": "4f9c914c-ae9f-46e0-9d75-e3bbb6871ed1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(3)\n",
            "Sample Action: 0\n",
            "\n",
            "Training PPO Model...\n",
            "Using cuda device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 94       |\n",
            "| time/              |          |\n",
            "|    fps             | 484      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 94.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012436818 |\n",
            "|    clip_fraction        | 0.093       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | -0.0322     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0835      |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00614    |\n",
            "|    value_loss           | 0.701       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 111          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 407          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057455925 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | 0.318        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0655       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    value_loss           | 0.152        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 111         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 403         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004799199 |\n",
            "|    clip_fraction        | 0.0148      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.265       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.126       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00199    |\n",
            "|    value_loss           | 0.301       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 115        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 394        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 25         |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00689264 |\n",
            "|    clip_fraction        | 0.0472     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.06      |\n",
            "|    explained_variance   | 0.422      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0406     |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00449   |\n",
            "|    value_loss           | 0.142      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 118          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 395          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067372834 |\n",
            "|    clip_fraction        | 0.0571       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.03        |\n",
            "|    explained_variance   | 0.36         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0609       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00401     |\n",
            "|    value_loss           | 0.17         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 120          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 393          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 36           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061337072 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.02        |\n",
            "|    explained_variance   | 0.295        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0545       |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00361     |\n",
            "|    value_loss           | 0.209        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 118         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 391         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006899406 |\n",
            "|    clip_fraction        | 0.0482      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.985      |\n",
            "|    explained_variance   | 0.301       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.226       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00358    |\n",
            "|    value_loss           | 0.261       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 124         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 391         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 47          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011186525 |\n",
            "|    clip_fraction        | 0.0479      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.945      |\n",
            "|    explained_variance   | 0.481       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0419      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00417    |\n",
            "|    value_loss           | 0.13        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 121         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 388         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008603178 |\n",
            "|    clip_fraction        | 0.0666      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.897      |\n",
            "|    explained_variance   | 0.392       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0367      |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00483    |\n",
            "|    value_loss           | 0.233       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 126          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037746378 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.887       |\n",
            "|    explained_variance   | 0.612        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0534       |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00276     |\n",
            "|    value_loss           | 0.0939       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 131        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 385        |\n",
            "|    iterations           | 12         |\n",
            "|    time_elapsed         | 63         |\n",
            "|    total_timesteps      | 24576      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00517556 |\n",
            "|    clip_fraction        | 0.0189     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.873     |\n",
            "|    explained_variance   | 0.441      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.116      |\n",
            "|    n_updates            | 110        |\n",
            "|    policy_gradient_loss | -0.00247   |\n",
            "|    value_loss           | 0.212      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 133          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 386          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 68           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052717454 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.845       |\n",
            "|    explained_variance   | 0.474        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0844       |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00252     |\n",
            "|    value_loss           | 0.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 135          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 383          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055470746 |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.807       |\n",
            "|    explained_variance   | 0.579        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0765       |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    value_loss           | 0.148        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 138         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 384         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 79          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005226986 |\n",
            "|    clip_fraction        | 0.0633      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.773      |\n",
            "|    explained_variance   | 0.522       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0448      |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00676    |\n",
            "|    value_loss           | 0.131       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 142          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 382          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050001256 |\n",
            "|    clip_fraction        | 0.055        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.719       |\n",
            "|    explained_variance   | 0.475        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0409       |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00442     |\n",
            "|    value_loss           | 0.186        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 143         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 383         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004173847 |\n",
            "|    clip_fraction        | 0.0468      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.671      |\n",
            "|    explained_variance   | 0.524       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.063       |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00383    |\n",
            "|    value_loss           | 0.211       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 146          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 382          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 96           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027308408 |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.664       |\n",
            "|    explained_variance   | 0.448        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0616       |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.0023      |\n",
            "|    value_loss           | 0.189        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 146         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 380         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003182324 |\n",
            "|    clip_fraction        | 0.0473      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.635      |\n",
            "|    explained_variance   | 0.498       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.128       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00313    |\n",
            "|    value_loss           | 0.194       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 147          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 380          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 107          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027519008 |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.617       |\n",
            "|    explained_variance   | 0.587        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.093        |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.0015      |\n",
            "|    value_loss           | 0.164        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 151          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 379          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 113          |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025624237 |\n",
            "|    clip_fraction        | 0.042        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.621       |\n",
            "|    explained_variance   | 0.632        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.041        |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00572     |\n",
            "|    value_loss           | 0.144        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 152         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 379         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 118         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003497193 |\n",
            "|    clip_fraction        | 0.0293      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.628      |\n",
            "|    explained_variance   | 0.601       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0782      |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00254    |\n",
            "|    value_loss           | 0.204       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 153         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 378         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 124         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005381526 |\n",
            "|    clip_fraction        | 0.0523      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.62       |\n",
            "|    explained_variance   | 0.629       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0484      |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00477    |\n",
            "|    value_loss           | 0.147       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 157          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 129          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033497969 |\n",
            "|    clip_fraction        | 0.0364       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.641       |\n",
            "|    explained_variance   | 0.555        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0794       |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00444     |\n",
            "|    value_loss           | 0.187        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 157          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 377          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 135          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030837674 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0.568        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0702       |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00212     |\n",
            "|    value_loss           | 0.202        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 158          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 140          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028690165 |\n",
            "|    clip_fraction        | 0.032        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.659       |\n",
            "|    explained_variance   | 0.649        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0776       |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00229     |\n",
            "|    value_loss           | 0.156        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 159          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 377          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 146          |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019807038 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.675       |\n",
            "|    explained_variance   | 0.61         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0851       |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    value_loss           | 0.173        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 159         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 378         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 151         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003387344 |\n",
            "|    clip_fraction        | 0.0239      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.612      |\n",
            "|    explained_variance   | 0.533       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0841      |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00114    |\n",
            "|    value_loss           | 0.164       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 160          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 377          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037702222 |\n",
            "|    clip_fraction        | 0.0478       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.609       |\n",
            "|    explained_variance   | 0.664        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0362       |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00361     |\n",
            "|    value_loss           | 0.113        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 160         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 378         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 162         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003584555 |\n",
            "|    clip_fraction        | 0.0338      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.583      |\n",
            "|    explained_variance   | 0.6         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0535      |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.00332    |\n",
            "|    value_loss           | 0.118       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 160          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 167          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053496165 |\n",
            "|    clip_fraction        | 0.0548       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.542       |\n",
            "|    explained_variance   | 0.649        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0527       |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00467     |\n",
            "|    value_loss           | 0.0941       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 160          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 173          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030102655 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.571       |\n",
            "|    explained_variance   | 0.648        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.035        |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00325     |\n",
            "|    value_loss           | 0.143        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 161         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 378         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 178         |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004774291 |\n",
            "|    clip_fraction        | 0.0346      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.55       |\n",
            "|    explained_variance   | 0.667       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0322      |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0039     |\n",
            "|    value_loss           | 0.106       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 162          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 184          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049237176 |\n",
            "|    clip_fraction        | 0.0384       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.541       |\n",
            "|    explained_variance   | 0.533        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.127        |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00245     |\n",
            "|    value_loss           | 0.191        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 162         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 377         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 189         |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001925736 |\n",
            "|    clip_fraction        | 0.0156      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.524      |\n",
            "|    explained_variance   | 0.609       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0733      |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.0011     |\n",
            "|    value_loss           | 0.157       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 163          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 195          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041275914 |\n",
            "|    clip_fraction        | 0.0485       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.476       |\n",
            "|    explained_variance   | 0.721        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0382       |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00452     |\n",
            "|    value_loss           | 0.13         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 164          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 201          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027664474 |\n",
            "|    clip_fraction        | 0.0371       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.453       |\n",
            "|    explained_variance   | 0.533        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0902       |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00278     |\n",
            "|    value_loss           | 0.152        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 164          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 206          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021789558 |\n",
            "|    clip_fraction        | 0.0247       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.453       |\n",
            "|    explained_variance   | 0.608        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0837       |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00081     |\n",
            "|    value_loss           | 0.142        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 165          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 212          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045189504 |\n",
            "|    clip_fraction        | 0.0442       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.431       |\n",
            "|    explained_variance   | 0.567        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0338       |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00331     |\n",
            "|    value_loss           | 0.112        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 166          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 375          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 217          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029858071 |\n",
            "|    clip_fraction        | 0.0339       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.431       |\n",
            "|    explained_variance   | 0.591        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0443       |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00246     |\n",
            "|    value_loss           | 0.118        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 167          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 223          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024673184 |\n",
            "|    clip_fraction        | 0.0413       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.424       |\n",
            "|    explained_variance   | 0.568        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0625       |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00305     |\n",
            "|    value_loss           | 0.142        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 167          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 228          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025045122 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.438       |\n",
            "|    explained_variance   | 0.625        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0873       |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00224     |\n",
            "|    value_loss           | 0.122        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 167         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 376         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 234         |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003426982 |\n",
            "|    clip_fraction        | 0.0262      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.438      |\n",
            "|    explained_variance   | 0.603       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0567      |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.00141    |\n",
            "|    value_loss           | 0.156       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 167         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 376         |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 239         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004471001 |\n",
            "|    clip_fraction        | 0.0429      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.43       |\n",
            "|    explained_variance   | 0.699       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0518      |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    value_loss           | 0.103       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 168          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 244          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029519338 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.415       |\n",
            "|    explained_variance   | 0.726        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0552       |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.00252     |\n",
            "|    value_loss           | 0.108        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 169          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 250          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034713326 |\n",
            "|    clip_fraction        | 0.0512       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.395       |\n",
            "|    explained_variance   | 0.604        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0936       |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.0033      |\n",
            "|    value_loss           | 0.165        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 169          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 255          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034551807 |\n",
            "|    clip_fraction        | 0.0503       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.369       |\n",
            "|    explained_variance   | 0.642        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.114        |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00357     |\n",
            "|    value_loss           | 0.129        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 170          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 260          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021728333 |\n",
            "|    clip_fraction        | 0.0217       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.356       |\n",
            "|    explained_variance   | 0.609        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0708       |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    value_loss           | 0.147        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | 170          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 266          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029060983 |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.362       |\n",
            "|    explained_variance   | 0.617        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0761       |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    value_loss           | 0.167        |\n",
            "------------------------------------------\n",
            "\n",
            "PPO Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrain A2C Model with Higher Entropy Regularization\n",
        "print((((\"\\\\\nRetraining A2C Model with Higher Entropy Regularization...\")\n",
        "a2c_model = A2C(\n",
        "    \"MlpPolicy\",\n",
        "    env_discrete,\n",
        "    learning_rate=0.0005,  #Lower learning rate for more stable updates\n",
        "    gamma=0.98,  #Encourage slightly longer-term rewards\n",
        "    vf_coef=0.4,  #Balance value function loss\n",
        "    ent_coef=0.01,  #Increase entropy for better exploration\n",
        "    verbose=1,\n",
        "    device=\"cuda(((\"\\\\n",
        ")\n",
        "\n",
        "print((((\"\\\\\nRetraining A2C Model with Adjusted Parameters...\")\n",
        "a2c_model.learn(total_timesteps=100000)  #Train for 100000 timesteps\n",
        "a2c_model.save(\"a2c_trading_model\")\n",
        "print((((\"\\\\\nA2C Training Complete!\")\n"
      ],
      "metadata": {
        "id": "9FLsWZ7NK1vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Model Evaluation Function (Fixed for VecEnv)\n",
        "def evaluate_model(model, env, num_steps=100):\n",
        "    (((\"\\\((\"\\\"Evaluates a trained model and logs actions taken.(((\"\\\\"(((\"\\\\n",
        "    obs = env.reset()  #FIX: No unpacking for VecEnv reset\n",
        "    action_history = []\n",
        "    total_rewards = np.zeros(env.num_envs)  #VecEnv handles multiple environments\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        action, _ = model.predict(obs)\n",
        "        action = int(action.item())  #Convert to integer (Discrete Action)\n",
        "\n",
        "        print(f\"Executing action: {action}\")  # Debugging\n",
        "\n",
        "        obs, reward, done, _ = env.step([action])  #FIX: Wrap action in list for VecEnv\n",
        "        action_history.append(action)\n",
        "        total_rewards += reward  #Correctly sum rewards across all environments\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}: Action: {action}, Reward: {reward.mean():.4f}\")\n",
        "\n",
        "        if done.any():  #FIX: `done` is an array in VecEnv\n",
        "            obs = env.reset()\n",
        "\n",
        "    #Print action history and total test reward\n",
        "    unique_actions = set(action_history)\n",
        "    print(f\"Actions Taken: {action_history if action_history else 'No trades executed.'}\")\n",
        "    print(f\"Total Test Reward: {total_rewards.sum():.4f}\")  #FIX: Sum over VecEnv rewards\n",
        "\n",
        "    if len(unique_actions) < 3:\n",
        "        print(\"Agent might not be exploring all actions properly.\")\n",
        "\n",
        "#Evaluate PPO Model\n",
        "print((((\"\\\\\nEvaluating PPO Model...\")\n",
        "evaluate_model(ppo_model, env_discrete)\n",
        "\n",
        "#Evaluate A2C Model\n",
        "print((((\"\\\\\nEvaluating A2C Model...\")\n",
        "evaluate_model(a2c_model, env_discrete)\n",
        "\n",
        "print((((\"\\\\\nPPO & A2C Evaluation Complete!\")\n",
        "\n",
        "#Get the first (and only) wrapped discrete environment\n",
        "wrapped_env = env_discrete.envs[0]\n",
        "\n",
        "#Properly Access Trade Log (Backward Compatible)\n",
        "if hasattr(env_discrete, \"get_wrapper_attr\"):\n",
        "    trade_log_ppo = env_discrete.get_wrapper_attr(\"trade_log\")\n",
        "    rewards_log_ppo = env_discrete.get_wrapper_attr(\"rewards_log\")\n",
        "\n",
        "    trade_log_a2c = env_discrete.get_wrapper_attr(\"trade_log\")\n",
        "    rewards_log_a2c = env_discrete.get_wrapper_attr(\"rewards_log\")\n",
        "else:\n",
        "    trade_log_ppo = wrapped_env.unwrapped.trade_log if hasattr(wrapped_env, \"trade_log\") else []\n",
        "    rewards_log_ppo = wrapped_env.unwrapped.rewards_log if hasattr(wrapped_env, \"rewards_log\") else []\n",
        "\n",
        "    trade_log_a2c = wrapped_env.unwrapped.trade_log if hasattr(wrapped_env, \"trade_log\") else []\n",
        "    rewards_log_a2c = wrapped_env.unwrapped.rewards_log if hasattr(wrapped_env, \"rewards_log\") else []\n",
        "\n",
        "#Summarize Trade Results\n",
        "num_trades_ppo = len(trade_log_ppo)\n",
        "num_rewards_ppo = len(rewards_log_ppo)\n",
        "num_trades_a2c = len(trade_log_a2c)\n",
        "num_rewards_a2c = len(rewards_log_a2c)\n",
        "\n",
        "print(f\"Number of Trades Logged (PPO): {num_trades_ppo}\")\n",
        "print(f\"Number of Rewards Logged (PPO): {num_rewards_ppo}\")\n",
        "\n",
        "#Log Mean & Max Rewards (More Insight)\n",
        "if rewards_log_ppo:\n",
        "    print(f\"PPO Mean Reward: {np.mean(rewards_log_ppo):.4f}, Max Reward: {np.max(rewards_log_ppo):.4f}\")\n",
        "\n",
        "if num_trades_ppo == 0:\n",
        "    print(\"No trades recorded. The PPO agent might not be executing actions.\")\n",
        "if num_rewards_ppo == 0:\n",
        "    print(\"No rewards recorded. The PPO environment might not be returning meaningful rewards.\")\n",
        "\n",
        "print(f\"Number of Trades Logged (A2C): {num_trades_a2c}\")\n",
        "print(f\"Number of Rewards Logged (A2C): {num_rewards_a2c}\")\n",
        "\n",
        "if rewards_log_a2c:\n",
        "    print(f\"A2C Mean Reward: {np.mean(rewards_log_a2c):.4f}, Max Reward: {np.max(rewards_log_a2c):.4f}\")\n",
        "\n",
        "if num_trades_a2c == 0:\n",
        "    print(\"No trades recorded. The A2C agent might not be executing actions.\")\n",
        "if num_rewards_a2c == 0:\n",
        "    print(\"No rewards recorded. The A2C environment might not be returning meaningful rewards.\")\n",
        "\n",
        "#Detect Stagnant Portfolio Value\n",
        "if num_trades_ppo > 0:\n",
        "    portfolio_changes = [t[\"Portfolio Value\"] for t in trade_log_ppo]\n",
        "    if len(set(portfolio_changes)) == 1:\n",
        "        print(\"PPO agent's portfolio value is not changing. Possible issue with trading logic.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qfSVGSo2K_K",
        "outputId": "16911338-e556-45b9-e8cb-64bb6b9d38c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating PPO Model...\n",
            "Executing action: 2\n",
            "Step 0: Action: 2, Reward: 0.0004\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Step 10: Action: 2, Reward: 0.0004\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Step 20: Action: 2, Reward: 0.2466\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Step 30: Action: 0, Reward: 0.0205\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Step 40: Action: 0, Reward: 0.0043\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Step 50: Action: 0, Reward: -0.0218\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Step 60: Action: 2, Reward: 0.0004\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Step 70: Action: 2, Reward: 0.0004\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Step 80: Action: 1, Reward: 0.0006\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 90: Action: 2, Reward: 0.0004\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Actions Taken: [2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 1, 1, 0, 2, 2, 2, 0, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 1, 2, 0, 2, 2, 1, 1, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2]\n",
            "Total Test Reward: 2.2845\n",
            "\n",
            "Evaluating A2C Model...\n",
            "Executing action: 1\n",
            "Step 0: Action: 1, Reward: 0.0000\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Step 10: Action: 0, Reward: 0.0000\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 20: Action: 2, Reward: 0.2466\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Step 30: Action: 0, Reward: 0.0205\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Step 40: Action: 0, Reward: 0.0043\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 50: Action: 2, Reward: 0.0504\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 60: Action: 2, Reward: 0.0004\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 70: Action: 2, Reward: 0.0004\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 1\n",
            "Executing action: 0\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Step 80: Action: 2, Reward: 0.0004\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Step 90: Action: 2, Reward: 0.0004\n",
            "Executing action: 1\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 2\n",
            "Executing action: 0\n",
            "Executing action: 2\n",
            "Actions Taken: [1, 2, 2, 2, 2, 1, 2, 2, 0, 0, 0, 2, 0, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2]\n",
            "Total Test Reward: 2.1651\n",
            "\n",
            "PPO & A2C Evaluation Complete!\n",
            "Number of Trades Logged (PPO): 100\n",
            "Number of Rewards Logged (PPO): 100\n",
            "PPO Mean Reward: 0.1581, Max Reward: 2.0111\n",
            "Number of Trades Logged (A2C): 100\n",
            "Number of Rewards Logged (A2C): 100\n",
            "A2C Mean Reward: 0.1581, Max Reward: 2.0111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.trade_log to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.trade_log` for environment variables or `env.get_wrapper_attr('trade_log')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.rewards_log to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.rewards_log` for environment variables or `env.get_wrapper_attr('rewards_log')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-jVIK3X4hVj2"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SARSAAgent:\n",
        "    def __init__(self, env, alpha=0.1, gamma=0.99, epsilon=1.0, epsilon_decay=0.999, min_epsilon=0.01):\n",
        "        (((\"\\\((\"\\\"SARSA agent for discrete action space trading.(((\"\\\\"(((\"\\\\n",
        "        self.env = env\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.min_epsilon = min_epsilon\n",
        "\n",
        "        self.q_table = defaultdict(lambda: np.zeros(env.action_space.n))  # Q-table initialization\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        (((\"\\\((\"\\\"Epsilon-greedy action selection.(((\"\\\\"(((\"\\\\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return self.env.action_space.sample()  # Explore\n",
        "        return np.argmax(self.q_table[state])  # Exploit\n",
        "\n",
        "    def train(self, num_episodes=100000):\n",
        "        (((\"\\\((\"\\\"Train the SARSA agent.(((\"\\\\"(((\"\\\\n",
        "        for episode in range(num_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            state = tuple(state.flatten())  # Convert state to a tuple (hashable)\n",
        "            action = self.choose_action(state)\n",
        "            total_reward = 0\n",
        "\n",
        "            for step in range(1000):\n",
        "                next_state, reward, done, _, _ = self.env.step(action)\n",
        "                next_state = tuple(next_state.flatten())\n",
        "\n",
        "                next_action = self.choose_action(next_state)  # SARSA selects next action\n",
        "\n",
        "                #SARSA Update Rule\n",
        "                self.q_table[state][action] += self.alpha * (\n",
        "                    reward + self.gamma * self.q_table[next_state][next_action] - self.q_table[state][action]\n",
        "                )\n",
        "\n",
        "                state, action = next_state, next_action\n",
        "                total_reward += reward\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            #Adjust Epsilon Decay\n",
        "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "            if episode % 100 == 0:\n",
        "                print(f\"Episode {episode}/{num_episodes}, Total Reward: {total_reward:.2f}\")\n",
        "\n",
        "        print((((\"\\\\\nSARSA Training Complete!\")\n",
        "\n",
        "    def evaluate(self, num_episodes=100):\n",
        "        (((\"\\\((\"\\\"Evaluate the trained SARSA agent.(((\"\\\\"(((\"\\\\n",
        "        total_rewards = []\n",
        "        action_counts = {\"SELL\": 0, \"HOLD\": 0, \"BUY\": 0}\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            state = tuple(state.flatten())\n",
        "            total_reward = 0\n",
        "\n",
        "            for step in range(1000):\n",
        "                action = np.argmax(self.q_table[state])\n",
        "                next_state, reward, done, _, _ = self.env.step(action)\n",
        "                next_state = tuple(next_state.flatten())\n",
        "\n",
        "                total_reward += reward\n",
        "                state = next_state\n",
        "\n",
        "                #Log Actions\n",
        "                if action == 0:\n",
        "                    action_counts[\"SELL\"] += 1\n",
        "                elif action == 1:\n",
        "                    action_counts[\"HOLD\"] += 1\n",
        "                else:\n",
        "                    action_counts[\"BUY\"] += 1\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            total_rewards.append(total_reward)\n",
        "            print(f\"Episode {episode+1}/{num_episodes}, Reward: {total_reward:.2f}\")\n",
        "\n",
        "        avg_reward = np.mean(total_rewards)\n",
        "        print(f(((\"\\\\\nAverage Test Reward: {avg_reward:.2f}\")\n",
        "        print((((\"\\\\\nAction Distribution:\")\n",
        "        print(f\"SELL: {action_counts['SELL']}\")\n",
        "        print(f\"HOLD: {action_counts['HOLD']}\")\n",
        "        print(f\"BUY: {action_counts['BUY']}\")\n",
        "\n",
        "        #Detect Imbalance in Action Distribution\n",
        "        if action_counts[\"SELL\"] > action_counts[\"BUY\"] * 5:\n",
        "            print(\"Warning: Too much selling compared to buying! Adjust reward incentives.\")"
      ],
      "metadata": {
        "id": "Cz9_Oo1jUXLE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate SARSA Agent with Adjusted Reward Function\n",
        "env_discrete_sarsa = DiscreteTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10)\n",
        "sarsa_agent = SARSAAgent(env_discrete_sarsa)\n",
        "\n",
        "#Train SARSA Model\n",
        "print((((\"\\\\\nTraining SARSA Model...\")\n",
        "sarsa_agent.train(num_episodes=100000)\n",
        "\n",
        "#Evaluate SARSA Model\n",
        "print((((\"\\\\\nEvaluating SARSA Model...\")\n",
        "sarsa_agent.evaluate(num_episodes=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR2Lu40IET4_",
        "outputId": "5adf84bd-870a-4790-ed7f-d9e9aeca34cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training SARSA Model...\n",
            "Episode 0/10000, Total Reward: 112.74\n",
            "Episode 100/10000, Total Reward: 70.87\n",
            "Episode 200/10000, Total Reward: 72.45\n",
            "Episode 300/10000, Total Reward: 73.44\n",
            "Episode 400/10000, Total Reward: 61.68\n",
            "Episode 500/10000, Total Reward: 69.24\n",
            "Episode 600/10000, Total Reward: 72.91\n",
            "Episode 700/10000, Total Reward: 81.99\n",
            "Episode 800/10000, Total Reward: 41.36\n",
            "Episode 900/10000, Total Reward: 52.45\n",
            "Episode 1000/10000, Total Reward: 50.49\n",
            "Episode 1100/10000, Total Reward: 33.84\n",
            "Episode 1200/10000, Total Reward: 27.07\n",
            "Episode 1300/10000, Total Reward: 60.40\n",
            "Episode 1400/10000, Total Reward: 18.79\n",
            "Episode 1500/10000, Total Reward: 47.07\n",
            "Episode 1600/10000, Total Reward: 30.06\n",
            "Episode 1700/10000, Total Reward: 54.74\n",
            "Episode 1800/10000, Total Reward: 17.31\n",
            "Episode 1900/10000, Total Reward: 16.03\n",
            "Episode 2000/10000, Total Reward: 5.48\n",
            "Episode 2100/10000, Total Reward: 32.10\n",
            "Episode 2200/10000, Total Reward: 9.94\n",
            "Episode 2300/10000, Total Reward: 35.32\n",
            "Episode 2400/10000, Total Reward: 30.24\n",
            "Episode 2500/10000, Total Reward: 37.38\n",
            "Episode 2600/10000, Total Reward: 34.08\n",
            "Episode 2700/10000, Total Reward: 16.18\n",
            "Episode 2800/10000, Total Reward: 12.83\n",
            "Episode 2900/10000, Total Reward: 2.30\n",
            "Episode 3000/10000, Total Reward: 28.26\n",
            "Episode 3100/10000, Total Reward: 32.90\n",
            "Episode 3200/10000, Total Reward: 29.14\n",
            "Episode 3300/10000, Total Reward: 14.74\n",
            "Episode 3400/10000, Total Reward: 37.19\n",
            "Episode 3500/10000, Total Reward: 14.84\n",
            "Episode 3600/10000, Total Reward: 15.33\n",
            "Episode 3700/10000, Total Reward: 39.42\n",
            "Episode 3800/10000, Total Reward: 16.83\n",
            "Episode 3900/10000, Total Reward: 39.18\n",
            "Episode 4000/10000, Total Reward: 28.99\n",
            "Episode 4100/10000, Total Reward: 25.39\n",
            "Episode 4200/10000, Total Reward: 39.22\n",
            "Episode 4300/10000, Total Reward: 64.54\n",
            "Episode 4400/10000, Total Reward: 26.82\n",
            "Episode 4500/10000, Total Reward: 60.17\n",
            "Episode 4600/10000, Total Reward: 35.48\n",
            "Episode 4700/10000, Total Reward: 59.53\n",
            "Episode 4800/10000, Total Reward: 8.45\n",
            "Episode 4900/10000, Total Reward: 28.99\n",
            "Episode 5000/10000, Total Reward: 33.58\n",
            "Episode 5100/10000, Total Reward: 32.79\n",
            "Episode 5200/10000, Total Reward: 50.66\n",
            "Episode 5300/10000, Total Reward: 52.07\n",
            "Episode 5400/10000, Total Reward: 64.54\n",
            "Episode 5500/10000, Total Reward: 64.30\n",
            "Episode 5600/10000, Total Reward: 41.67\n",
            "Episode 5700/10000, Total Reward: 36.95\n",
            "Episode 5800/10000, Total Reward: 17.50\n",
            "Episode 5900/10000, Total Reward: 69.14\n",
            "Episode 6000/10000, Total Reward: 34.81\n",
            "Episode 6100/10000, Total Reward: 66.93\n",
            "Episode 6200/10000, Total Reward: 67.37\n",
            "Episode 6300/10000, Total Reward: 16.90\n",
            "Episode 6400/10000, Total Reward: 45.64\n",
            "Episode 6500/10000, Total Reward: 49.55\n",
            "Episode 6600/10000, Total Reward: 38.55\n",
            "Episode 6700/10000, Total Reward: 62.88\n",
            "Episode 6800/10000, Total Reward: 74.93\n",
            "Episode 6900/10000, Total Reward: 68.30\n",
            "Episode 7000/10000, Total Reward: 45.33\n",
            "Episode 7100/10000, Total Reward: 67.64\n",
            "Episode 7200/10000, Total Reward: 67.88\n",
            "Episode 7300/10000, Total Reward: 38.01\n",
            "Episode 7400/10000, Total Reward: 28.79\n",
            "Episode 7500/10000, Total Reward: 70.88\n",
            "Episode 7600/10000, Total Reward: 69.68\n",
            "Episode 7700/10000, Total Reward: 77.37\n",
            "Episode 7800/10000, Total Reward: 69.67\n",
            "Episode 7900/10000, Total Reward: 77.26\n",
            "Episode 8000/10000, Total Reward: 17.33\n",
            "Episode 8100/10000, Total Reward: 39.75\n",
            "Episode 8200/10000, Total Reward: 33.83\n",
            "Episode 8300/10000, Total Reward: 13.60\n",
            "Episode 8400/10000, Total Reward: 34.10\n",
            "Episode 8500/10000, Total Reward: 47.88\n",
            "Episode 8600/10000, Total Reward: 95.78\n",
            "Episode 8700/10000, Total Reward: 86.57\n",
            "Episode 8800/10000, Total Reward: 38.74\n",
            "Episode 8900/10000, Total Reward: 87.65\n",
            "Episode 9000/10000, Total Reward: 36.83\n",
            "Episode 9100/10000, Total Reward: 87.60\n",
            "Episode 9200/10000, Total Reward: 17.63\n",
            "Episode 9300/10000, Total Reward: 34.68\n",
            "Episode 9400/10000, Total Reward: 63.56\n",
            "Episode 9500/10000, Total Reward: 38.57\n",
            "Episode 9600/10000, Total Reward: 32.43\n",
            "Episode 9700/10000, Total Reward: 64.67\n",
            "Episode 9800/10000, Total Reward: 38.95\n",
            "Episode 9900/10000, Total Reward: 51.30\n",
            "\n",
            "SARSA Training Complete!\n",
            "\n",
            "Evaluating SARSA Model...\n",
            "Episode 1/100, Reward: 90.38\n",
            "Episode 2/100, Reward: 90.38\n",
            "Episode 3/100, Reward: 90.38\n",
            "Episode 4/100, Reward: 90.38\n",
            "Episode 5/100, Reward: 90.38\n",
            "Episode 6/100, Reward: 90.38\n",
            "Episode 7/100, Reward: 90.38\n",
            "Episode 8/100, Reward: 90.38\n",
            "Episode 9/100, Reward: 90.38\n",
            "Episode 10/100, Reward: 90.38\n",
            "Episode 11/100, Reward: 90.38\n",
            "Episode 12/100, Reward: 90.38\n",
            "Episode 13/100, Reward: 90.38\n",
            "Episode 14/100, Reward: 90.38\n",
            "Episode 15/100, Reward: 90.38\n",
            "Episode 16/100, Reward: 90.38\n",
            "Episode 17/100, Reward: 90.38\n",
            "Episode 18/100, Reward: 90.38\n",
            "Episode 19/100, Reward: 90.38\n",
            "Episode 20/100, Reward: 90.38\n",
            "Episode 21/100, Reward: 90.38\n",
            "Episode 22/100, Reward: 90.38\n",
            "Episode 23/100, Reward: 90.38\n",
            "Episode 24/100, Reward: 90.38\n",
            "Episode 25/100, Reward: 90.38\n",
            "Episode 26/100, Reward: 90.38\n",
            "Episode 27/100, Reward: 90.38\n",
            "Episode 28/100, Reward: 90.38\n",
            "Episode 29/100, Reward: 90.38\n",
            "Episode 30/100, Reward: 90.38\n",
            "Episode 31/100, Reward: 90.38\n",
            "Episode 32/100, Reward: 90.38\n",
            "Episode 33/100, Reward: 90.38\n",
            "Episode 34/100, Reward: 90.38\n",
            "Episode 35/100, Reward: 90.38\n",
            "Episode 36/100, Reward: 90.38\n",
            "Episode 37/100, Reward: 90.38\n",
            "Episode 38/100, Reward: 90.38\n",
            "Episode 39/100, Reward: 90.38\n",
            "Episode 40/100, Reward: 90.38\n",
            "Episode 41/100, Reward: 90.38\n",
            "Episode 42/100, Reward: 90.38\n",
            "Episode 43/100, Reward: 90.38\n",
            "Episode 44/100, Reward: 90.38\n",
            "Episode 45/100, Reward: 90.38\n",
            "Episode 46/100, Reward: 90.38\n",
            "Episode 47/100, Reward: 90.38\n",
            "Episode 48/100, Reward: 90.38\n",
            "Episode 49/100, Reward: 90.38\n",
            "Episode 50/100, Reward: 90.38\n",
            "Episode 51/100, Reward: 90.38\n",
            "Episode 52/100, Reward: 90.38\n",
            "Episode 53/100, Reward: 90.38\n",
            "Episode 54/100, Reward: 90.38\n",
            "Episode 55/100, Reward: 90.38\n",
            "Episode 56/100, Reward: 90.38\n",
            "Episode 57/100, Reward: 90.38\n",
            "Episode 58/100, Reward: 90.38\n",
            "Episode 59/100, Reward: 90.38\n",
            "Episode 60/100, Reward: 90.38\n",
            "Episode 61/100, Reward: 90.38\n",
            "Episode 62/100, Reward: 90.38\n",
            "Episode 63/100, Reward: 90.38\n",
            "Episode 64/100, Reward: 90.38\n",
            "Episode 65/100, Reward: 90.38\n",
            "Episode 66/100, Reward: 90.38\n",
            "Episode 67/100, Reward: 90.38\n",
            "Episode 68/100, Reward: 90.38\n",
            "Episode 69/100, Reward: 90.38\n",
            "Episode 70/100, Reward: 90.38\n",
            "Episode 71/100, Reward: 90.38\n",
            "Episode 72/100, Reward: 90.38\n",
            "Episode 73/100, Reward: 90.38\n",
            "Episode 74/100, Reward: 90.38\n",
            "Episode 75/100, Reward: 90.38\n",
            "Episode 76/100, Reward: 90.38\n",
            "Episode 77/100, Reward: 90.38\n",
            "Episode 78/100, Reward: 90.38\n",
            "Episode 79/100, Reward: 90.38\n",
            "Episode 80/100, Reward: 90.38\n",
            "Episode 81/100, Reward: 90.38\n",
            "Episode 82/100, Reward: 90.38\n",
            "Episode 83/100, Reward: 90.38\n",
            "Episode 84/100, Reward: 90.38\n",
            "Episode 85/100, Reward: 90.38\n",
            "Episode 86/100, Reward: 90.38\n",
            "Episode 87/100, Reward: 90.38\n",
            "Episode 88/100, Reward: 90.38\n",
            "Episode 89/100, Reward: 90.38\n",
            "Episode 90/100, Reward: 90.38\n",
            "Episode 91/100, Reward: 90.38\n",
            "Episode 92/100, Reward: 90.38\n",
            "Episode 93/100, Reward: 90.38\n",
            "Episode 94/100, Reward: 90.38\n",
            "Episode 95/100, Reward: 90.38\n",
            "Episode 96/100, Reward: 90.38\n",
            "Episode 97/100, Reward: 90.38\n",
            "Episode 98/100, Reward: 90.38\n",
            "Episode 99/100, Reward: 90.38\n",
            "Episode 100/100, Reward: 90.38\n",
            "\n",
            "Average Test Reward: 90.38\n",
            "\n",
            "Action Distribution:\n",
            "SELL: 86100\n",
            "HOLD: 1600\n",
            "BUY: 12300\n",
            "Warning: Too much selling compared to buying! Adjust reward incentives.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f(((\"\\\\\nInitial Portfolio Value: {env_discrete_sarsa.initial_balance}\")\n",
        "print(f\"Final Portfolio Value After Evaluation: {env_discrete_sarsa.portfolio_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUiR8q-B--Ls",
        "outputId": "672f6954-ea48-40bd-91c3-4acf2d5a0b4c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial Portfolio Value: 100000\n",
            "Final Portfolio Value After Evaluation: 96156.93821210679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_counts = {0: 0, 1: 0, 2: 0}  # Sell, Hold, Buy\n",
        "\n",
        "for state in sarsa_agent.q_table.keys():\n",
        "    action = np.argmax(sarsa_agent.q_table[state])\n",
        "    action_counts[action] += 1\n",
        "\n",
        "print((((\"\\\\\nAction Distribution:\")\n",
        "print(f\"SELL: {action_counts[0]}\")\n",
        "print(f\"HOLD: {action_counts[1]}\")\n",
        "print(f\"BUY: {action_counts[2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slxOynA_-_VI",
        "outputId": "bea2235e-d6ab-4f31-a034-cc1b5c63861a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Action Distribution:\n",
            "SELL: 7738873\n",
            "HOLD: 170236\n",
            "BUY: 343860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_volatility = df.copy()\n",
        "df_volatility['Close'] = df_volatility['Close'] * np.random.uniform(0.9, 1.1, len(df))  # Simulated high volatility\n",
        "\n",
        "env_stress = DiscreteTradingEnv(df=df_volatility, frame_bound=(10, len(df_volatility)), window_size=10)\n",
        "sarsa_stress_test = SARSAAgent(env_stress)\n",
        "\n",
        "print((((\"\\\\\nStress Testing SARSA Model...\")\n",
        "sarsa_stress_test.evaluate(num_episodes=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjGzXPwiQ59F",
        "outputId": "95e65e07-79ad-4ad2-ea48-15d135aab84a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stress Testing SARSA Model...\n",
            "Episode 1/100, Reward: 0.00\n",
            "Episode 2/100, Reward: 0.00\n",
            "Episode 3/100, Reward: 0.00\n",
            "Episode 4/100, Reward: 0.00\n",
            "Episode 5/100, Reward: 0.00\n",
            "Episode 6/100, Reward: 0.00\n",
            "Episode 7/100, Reward: 0.00\n",
            "Episode 8/100, Reward: 0.00\n",
            "Episode 9/100, Reward: 0.00\n",
            "Episode 10/100, Reward: 0.00\n",
            "Episode 11/100, Reward: 0.00\n",
            "Episode 12/100, Reward: 0.00\n",
            "Episode 13/100, Reward: 0.00\n",
            "Episode 14/100, Reward: 0.00\n",
            "Episode 15/100, Reward: 0.00\n",
            "Episode 16/100, Reward: 0.00\n",
            "Episode 17/100, Reward: 0.00\n",
            "Episode 18/100, Reward: 0.00\n",
            "Episode 19/100, Reward: 0.00\n",
            "Episode 20/100, Reward: 0.00\n",
            "Episode 21/100, Reward: 0.00\n",
            "Episode 22/100, Reward: 0.00\n",
            "Episode 23/100, Reward: 0.00\n",
            "Episode 24/100, Reward: 0.00\n",
            "Episode 25/100, Reward: 0.00\n",
            "Episode 26/100, Reward: 0.00\n",
            "Episode 27/100, Reward: 0.00\n",
            "Episode 28/100, Reward: 0.00\n",
            "Episode 29/100, Reward: 0.00\n",
            "Episode 30/100, Reward: 0.00\n",
            "Episode 31/100, Reward: 0.00\n",
            "Episode 32/100, Reward: 0.00\n",
            "Episode 33/100, Reward: 0.00\n",
            "Episode 34/100, Reward: 0.00\n",
            "Episode 35/100, Reward: 0.00\n",
            "Episode 36/100, Reward: 0.00\n",
            "Episode 37/100, Reward: 0.00\n",
            "Episode 38/100, Reward: 0.00\n",
            "Episode 39/100, Reward: 0.00\n",
            "Episode 40/100, Reward: 0.00\n",
            "Episode 41/100, Reward: 0.00\n",
            "Episode 42/100, Reward: 0.00\n",
            "Episode 43/100, Reward: 0.00\n",
            "Episode 44/100, Reward: 0.00\n",
            "Episode 45/100, Reward: 0.00\n",
            "Episode 46/100, Reward: 0.00\n",
            "Episode 47/100, Reward: 0.00\n",
            "Episode 48/100, Reward: 0.00\n",
            "Episode 49/100, Reward: 0.00\n",
            "Episode 50/100, Reward: 0.00\n",
            "Episode 51/100, Reward: 0.00\n",
            "Episode 52/100, Reward: 0.00\n",
            "Episode 53/100, Reward: 0.00\n",
            "Episode 54/100, Reward: 0.00\n",
            "Episode 55/100, Reward: 0.00\n",
            "Episode 56/100, Reward: 0.00\n",
            "Episode 57/100, Reward: 0.00\n",
            "Episode 58/100, Reward: 0.00\n",
            "Episode 59/100, Reward: 0.00\n",
            "Episode 60/100, Reward: 0.00\n",
            "Episode 61/100, Reward: 0.00\n",
            "Episode 62/100, Reward: 0.00\n",
            "Episode 63/100, Reward: 0.00\n",
            "Episode 64/100, Reward: 0.00\n",
            "Episode 65/100, Reward: 0.00\n",
            "Episode 66/100, Reward: 0.00\n",
            "Episode 67/100, Reward: 0.00\n",
            "Episode 68/100, Reward: 0.00\n",
            "Episode 69/100, Reward: 0.00\n",
            "Episode 70/100, Reward: 0.00\n",
            "Episode 71/100, Reward: 0.00\n",
            "Episode 72/100, Reward: 0.00\n",
            "Episode 73/100, Reward: 0.00\n",
            "Episode 74/100, Reward: 0.00\n",
            "Episode 75/100, Reward: 0.00\n",
            "Episode 76/100, Reward: 0.00\n",
            "Episode 77/100, Reward: 0.00\n",
            "Episode 78/100, Reward: 0.00\n",
            "Episode 79/100, Reward: 0.00\n",
            "Episode 80/100, Reward: 0.00\n",
            "Episode 81/100, Reward: 0.00\n",
            "Episode 82/100, Reward: 0.00\n",
            "Episode 83/100, Reward: 0.00\n",
            "Episode 84/100, Reward: 0.00\n",
            "Episode 85/100, Reward: 0.00\n",
            "Episode 86/100, Reward: 0.00\n",
            "Episode 87/100, Reward: 0.00\n",
            "Episode 88/100, Reward: 0.00\n",
            "Episode 89/100, Reward: 0.00\n",
            "Episode 90/100, Reward: 0.00\n",
            "Episode 91/100, Reward: 0.00\n",
            "Episode 92/100, Reward: 0.00\n",
            "Episode 93/100, Reward: 0.00\n",
            "Episode 94/100, Reward: 0.00\n",
            "Episode 95/100, Reward: 0.00\n",
            "Episode 96/100, Reward: 0.00\n",
            "Episode 97/100, Reward: 0.00\n",
            "Episode 98/100, Reward: 0.00\n",
            "Episode 99/100, Reward: 0.00\n",
            "Episode 100/100, Reward: 0.00\n",
            "\n",
            "Average Test Reward: 0.00\n",
            "\n",
            "Action Distribution:\n",
            "SELL: 100000\n",
            "HOLD: 0\n",
            "BUY: 0\n",
            "Warning: Too much selling compared to buying! Adjust reward incentives.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_values = [np.max(sarsa_agent.q_table[state]) for state in sarsa_agent.q_table.keys()]\n",
        "plt.plot(q_values)\n",
        "plt.xlabel(\"State Index\")\n",
        "plt.ylabel(\"Max Q-Value\")\n",
        "plt.title(\"📉 Q-Value Convergence\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "gXYTzId4Q_Go",
        "outputId": "e6236066-69dd-4317-d22c-bb21df3df1ee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 128201 (\\N{CHART WITH DOWNWARDS TREND}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((((\"\\\\\nLong-Term Test (1,000 Episodes)...\")\n",
        "sarsa_agent.evaluate(num_episodes=1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTVlG8kW_NYz",
        "outputId": "ef42b1dc-7a1e-4e6d-abf5-11af33f7ed6f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Long-Term Test (1,000 Episodes)...\n",
            "Episode 1/1000, Reward: 90.38\n",
            "Episode 2/1000, Reward: 90.38\n",
            "Episode 3/1000, Reward: 90.38\n",
            "Episode 4/1000, Reward: 90.38\n",
            "Episode 5/1000, Reward: 90.38\n",
            "Episode 6/1000, Reward: 90.38\n",
            "Episode 7/1000, Reward: 90.38\n",
            "Episode 8/1000, Reward: 90.38\n",
            "Episode 9/1000, Reward: 90.38\n",
            "Episode 10/1000, Reward: 90.38\n",
            "Episode 11/1000, Reward: 90.38\n",
            "Episode 12/1000, Reward: 90.38\n",
            "Episode 13/1000, Reward: 90.38\n",
            "Episode 14/1000, Reward: 90.38\n",
            "Episode 15/1000, Reward: 90.38\n",
            "Episode 16/1000, Reward: 90.38\n",
            "Episode 17/1000, Reward: 90.38\n",
            "Episode 18/1000, Reward: 90.38\n",
            "Episode 19/1000, Reward: 90.38\n",
            "Episode 20/1000, Reward: 90.38\n",
            "Episode 21/1000, Reward: 90.38\n",
            "Episode 22/1000, Reward: 90.38\n",
            "Episode 23/1000, Reward: 90.38\n",
            "Episode 24/1000, Reward: 90.38\n",
            "Episode 25/1000, Reward: 90.38\n",
            "Episode 26/1000, Reward: 90.38\n",
            "Episode 27/1000, Reward: 90.38\n",
            "Episode 28/1000, Reward: 90.38\n",
            "Episode 29/1000, Reward: 90.38\n",
            "Episode 30/1000, Reward: 90.38\n",
            "Episode 31/1000, Reward: 90.38\n",
            "Episode 32/1000, Reward: 90.38\n",
            "Episode 33/1000, Reward: 90.38\n",
            "Episode 34/1000, Reward: 90.38\n",
            "Episode 35/1000, Reward: 90.38\n",
            "Episode 36/1000, Reward: 90.38\n",
            "Episode 37/1000, Reward: 90.38\n",
            "Episode 38/1000, Reward: 90.38\n",
            "Episode 39/1000, Reward: 90.38\n",
            "Episode 40/1000, Reward: 90.38\n",
            "Episode 41/1000, Reward: 90.38\n",
            "Episode 42/1000, Reward: 90.38\n",
            "Episode 43/1000, Reward: 90.38\n",
            "Episode 44/1000, Reward: 90.38\n",
            "Episode 45/1000, Reward: 90.38\n",
            "Episode 46/1000, Reward: 90.38\n",
            "Episode 47/1000, Reward: 90.38\n",
            "Episode 48/1000, Reward: 90.38\n",
            "Episode 49/1000, Reward: 90.38\n",
            "Episode 50/1000, Reward: 90.38\n",
            "Episode 51/1000, Reward: 90.38\n",
            "Episode 52/1000, Reward: 90.38\n",
            "Episode 53/1000, Reward: 90.38\n",
            "Episode 54/1000, Reward: 90.38\n",
            "Episode 55/1000, Reward: 90.38\n",
            "Episode 56/1000, Reward: 90.38\n",
            "Episode 57/1000, Reward: 90.38\n",
            "Episode 58/1000, Reward: 90.38\n",
            "Episode 59/1000, Reward: 90.38\n",
            "Episode 60/1000, Reward: 90.38\n",
            "Episode 61/1000, Reward: 90.38\n",
            "Episode 62/1000, Reward: 90.38\n",
            "Episode 63/1000, Reward: 90.38\n",
            "Episode 64/1000, Reward: 90.38\n",
            "Episode 65/1000, Reward: 90.38\n",
            "Episode 66/1000, Reward: 90.38\n",
            "Episode 67/1000, Reward: 90.38\n",
            "Episode 68/1000, Reward: 90.38\n",
            "Episode 69/1000, Reward: 90.38\n",
            "Episode 70/1000, Reward: 90.38\n",
            "Episode 71/1000, Reward: 90.38\n",
            "Episode 72/1000, Reward: 90.38\n",
            "Episode 73/1000, Reward: 90.38\n",
            "Episode 74/1000, Reward: 90.38\n",
            "Episode 75/1000, Reward: 90.38\n",
            "Episode 76/1000, Reward: 90.38\n",
            "Episode 77/1000, Reward: 90.38\n",
            "Episode 78/1000, Reward: 90.38\n",
            "Episode 79/1000, Reward: 90.38\n",
            "Episode 80/1000, Reward: 90.38\n",
            "Episode 81/1000, Reward: 90.38\n",
            "Episode 82/1000, Reward: 90.38\n",
            "Episode 83/1000, Reward: 90.38\n",
            "Episode 84/1000, Reward: 90.38\n",
            "Episode 85/1000, Reward: 90.38\n",
            "Episode 86/1000, Reward: 90.38\n",
            "Episode 87/1000, Reward: 90.38\n",
            "Episode 88/1000, Reward: 90.38\n",
            "Episode 89/1000, Reward: 90.38\n",
            "Episode 90/1000, Reward: 90.38\n",
            "Episode 91/1000, Reward: 90.38\n",
            "Episode 92/1000, Reward: 90.38\n",
            "Episode 93/1000, Reward: 90.38\n",
            "Episode 94/1000, Reward: 90.38\n",
            "Episode 95/1000, Reward: 90.38\n",
            "Episode 96/1000, Reward: 90.38\n",
            "Episode 97/1000, Reward: 90.38\n",
            "Episode 98/1000, Reward: 90.38\n",
            "Episode 99/1000, Reward: 90.38\n",
            "Episode 100/1000, Reward: 90.38\n",
            "Episode 101/1000, Reward: 90.38\n",
            "Episode 102/1000, Reward: 90.38\n",
            "Episode 103/1000, Reward: 90.38\n",
            "Episode 104/1000, Reward: 90.38\n",
            "Episode 105/1000, Reward: 90.38\n",
            "Episode 106/1000, Reward: 90.38\n",
            "Episode 107/1000, Reward: 90.38\n",
            "Episode 108/1000, Reward: 90.38\n",
            "Episode 109/1000, Reward: 90.38\n",
            "Episode 110/1000, Reward: 90.38\n",
            "Episode 111/1000, Reward: 90.38\n",
            "Episode 112/1000, Reward: 90.38\n",
            "Episode 113/1000, Reward: 90.38\n",
            "Episode 114/1000, Reward: 90.38\n",
            "Episode 115/1000, Reward: 90.38\n",
            "Episode 116/1000, Reward: 90.38\n",
            "Episode 117/1000, Reward: 90.38\n",
            "Episode 118/1000, Reward: 90.38\n",
            "Episode 119/1000, Reward: 90.38\n",
            "Episode 120/1000, Reward: 90.38\n",
            "Episode 121/1000, Reward: 90.38\n",
            "Episode 122/1000, Reward: 90.38\n",
            "Episode 123/1000, Reward: 90.38\n",
            "Episode 124/1000, Reward: 90.38\n",
            "Episode 125/1000, Reward: 90.38\n",
            "Episode 126/1000, Reward: 90.38\n",
            "Episode 127/1000, Reward: 90.38\n",
            "Episode 128/1000, Reward: 90.38\n",
            "Episode 129/1000, Reward: 90.38\n",
            "Episode 130/1000, Reward: 90.38\n",
            "Episode 131/1000, Reward: 90.38\n",
            "Episode 132/1000, Reward: 90.38\n",
            "Episode 133/1000, Reward: 90.38\n",
            "Episode 134/1000, Reward: 90.38\n",
            "Episode 135/1000, Reward: 90.38\n",
            "Episode 136/1000, Reward: 90.38\n",
            "Episode 137/1000, Reward: 90.38\n",
            "Episode 138/1000, Reward: 90.38\n",
            "Episode 139/1000, Reward: 90.38\n",
            "Episode 140/1000, Reward: 90.38\n",
            "Episode 141/1000, Reward: 90.38\n",
            "Episode 142/1000, Reward: 90.38\n",
            "Episode 143/1000, Reward: 90.38\n",
            "Episode 144/1000, Reward: 90.38\n",
            "Episode 145/1000, Reward: 90.38\n",
            "Episode 146/1000, Reward: 90.38\n",
            "Episode 147/1000, Reward: 90.38\n",
            "Episode 148/1000, Reward: 90.38\n",
            "Episode 149/1000, Reward: 90.38\n",
            "Episode 150/1000, Reward: 90.38\n",
            "Episode 151/1000, Reward: 90.38\n",
            "Episode 152/1000, Reward: 90.38\n",
            "Episode 153/1000, Reward: 90.38\n",
            "Episode 154/1000, Reward: 90.38\n",
            "Episode 155/1000, Reward: 90.38\n",
            "Episode 156/1000, Reward: 90.38\n",
            "Episode 157/1000, Reward: 90.38\n",
            "Episode 158/1000, Reward: 90.38\n",
            "Episode 159/1000, Reward: 90.38\n",
            "Episode 160/1000, Reward: 90.38\n",
            "Episode 161/1000, Reward: 90.38\n",
            "Episode 162/1000, Reward: 90.38\n",
            "Episode 163/1000, Reward: 90.38\n",
            "Episode 164/1000, Reward: 90.38\n",
            "Episode 165/1000, Reward: 90.38\n",
            "Episode 166/1000, Reward: 90.38\n",
            "Episode 167/1000, Reward: 90.38\n",
            "Episode 168/1000, Reward: 90.38\n",
            "Episode 169/1000, Reward: 90.38\n",
            "Episode 170/1000, Reward: 90.38\n",
            "Episode 171/1000, Reward: 90.38\n",
            "Episode 172/1000, Reward: 90.38\n",
            "Episode 173/1000, Reward: 90.38\n",
            "Episode 174/1000, Reward: 90.38\n",
            "Episode 175/1000, Reward: 90.38\n",
            "Episode 176/1000, Reward: 90.38\n",
            "Episode 177/1000, Reward: 90.38\n",
            "Episode 178/1000, Reward: 90.38\n",
            "Episode 179/1000, Reward: 90.38\n",
            "Episode 180/1000, Reward: 90.38\n",
            "Episode 181/1000, Reward: 90.38\n",
            "Episode 182/1000, Reward: 90.38\n",
            "Episode 183/1000, Reward: 90.38\n",
            "Episode 184/1000, Reward: 90.38\n",
            "Episode 185/1000, Reward: 90.38\n",
            "Episode 186/1000, Reward: 90.38\n",
            "Episode 187/1000, Reward: 90.38\n",
            "Episode 188/1000, Reward: 90.38\n",
            "Episode 189/1000, Reward: 90.38\n",
            "Episode 190/1000, Reward: 90.38\n",
            "Episode 191/1000, Reward: 90.38\n",
            "Episode 192/1000, Reward: 90.38\n",
            "Episode 193/1000, Reward: 90.38\n",
            "Episode 194/1000, Reward: 90.38\n",
            "Episode 195/1000, Reward: 90.38\n",
            "Episode 196/1000, Reward: 90.38\n",
            "Episode 197/1000, Reward: 90.38\n",
            "Episode 198/1000, Reward: 90.38\n",
            "Episode 199/1000, Reward: 90.38\n",
            "Episode 200/1000, Reward: 90.38\n",
            "Episode 201/1000, Reward: 90.38\n",
            "Episode 202/1000, Reward: 90.38\n",
            "Episode 203/1000, Reward: 90.38\n",
            "Episode 204/1000, Reward: 90.38\n",
            "Episode 205/1000, Reward: 90.38\n",
            "Episode 206/1000, Reward: 90.38\n",
            "Episode 207/1000, Reward: 90.38\n",
            "Episode 208/1000, Reward: 90.38\n",
            "Episode 209/1000, Reward: 90.38\n",
            "Episode 210/1000, Reward: 90.38\n",
            "Episode 211/1000, Reward: 90.38\n",
            "Episode 212/1000, Reward: 90.38\n",
            "Episode 213/1000, Reward: 90.38\n",
            "Episode 214/1000, Reward: 90.38\n",
            "Episode 215/1000, Reward: 90.38\n",
            "Episode 216/1000, Reward: 90.38\n",
            "Episode 217/1000, Reward: 90.38\n",
            "Episode 218/1000, Reward: 90.38\n",
            "Episode 219/1000, Reward: 90.38\n",
            "Episode 220/1000, Reward: 90.38\n",
            "Episode 221/1000, Reward: 90.38\n",
            "Episode 222/1000, Reward: 90.38\n",
            "Episode 223/1000, Reward: 90.38\n",
            "Episode 224/1000, Reward: 90.38\n",
            "Episode 225/1000, Reward: 90.38\n",
            "Episode 226/1000, Reward: 90.38\n",
            "Episode 227/1000, Reward: 90.38\n",
            "Episode 228/1000, Reward: 90.38\n",
            "Episode 229/1000, Reward: 90.38\n",
            "Episode 230/1000, Reward: 90.38\n",
            "Episode 231/1000, Reward: 90.38\n",
            "Episode 232/1000, Reward: 90.38\n",
            "Episode 233/1000, Reward: 90.38\n",
            "Episode 234/1000, Reward: 90.38\n",
            "Episode 235/1000, Reward: 90.38\n",
            "Episode 236/1000, Reward: 90.38\n",
            "Episode 237/1000, Reward: 90.38\n",
            "Episode 238/1000, Reward: 90.38\n",
            "Episode 239/1000, Reward: 90.38\n",
            "Episode 240/1000, Reward: 90.38\n",
            "Episode 241/1000, Reward: 90.38\n",
            "Episode 242/1000, Reward: 90.38\n",
            "Episode 243/1000, Reward: 90.38\n",
            "Episode 244/1000, Reward: 90.38\n",
            "Episode 245/1000, Reward: 90.38\n",
            "Episode 246/1000, Reward: 90.38\n",
            "Episode 247/1000, Reward: 90.38\n",
            "Episode 248/1000, Reward: 90.38\n",
            "Episode 249/1000, Reward: 90.38\n",
            "Episode 250/1000, Reward: 90.38\n",
            "Episode 251/1000, Reward: 90.38\n",
            "Episode 252/1000, Reward: 90.38\n",
            "Episode 253/1000, Reward: 90.38\n",
            "Episode 254/1000, Reward: 90.38\n",
            "Episode 255/1000, Reward: 90.38\n",
            "Episode 256/1000, Reward: 90.38\n",
            "Episode 257/1000, Reward: 90.38\n",
            "Episode 258/1000, Reward: 90.38\n",
            "Episode 259/1000, Reward: 90.38\n",
            "Episode 260/1000, Reward: 90.38\n",
            "Episode 261/1000, Reward: 90.38\n",
            "Episode 262/1000, Reward: 90.38\n",
            "Episode 263/1000, Reward: 90.38\n",
            "Episode 264/1000, Reward: 90.38\n",
            "Episode 265/1000, Reward: 90.38\n",
            "Episode 266/1000, Reward: 90.38\n",
            "Episode 267/1000, Reward: 90.38\n",
            "Episode 268/1000, Reward: 90.38\n",
            "Episode 269/1000, Reward: 90.38\n",
            "Episode 270/1000, Reward: 90.38\n",
            "Episode 271/1000, Reward: 90.38\n",
            "Episode 272/1000, Reward: 90.38\n",
            "Episode 273/1000, Reward: 90.38\n",
            "Episode 274/1000, Reward: 90.38\n",
            "Episode 275/1000, Reward: 90.38\n",
            "Episode 276/1000, Reward: 90.38\n",
            "Episode 277/1000, Reward: 90.38\n",
            "Episode 278/1000, Reward: 90.38\n",
            "Episode 279/1000, Reward: 90.38\n",
            "Episode 280/1000, Reward: 90.38\n",
            "Episode 281/1000, Reward: 90.38\n",
            "Episode 282/1000, Reward: 90.38\n",
            "Episode 283/1000, Reward: 90.38\n",
            "Episode 284/1000, Reward: 90.38\n",
            "Episode 285/1000, Reward: 90.38\n",
            "Episode 286/1000, Reward: 90.38\n",
            "Episode 287/1000, Reward: 90.38\n",
            "Episode 288/1000, Reward: 90.38\n",
            "Episode 289/1000, Reward: 90.38\n",
            "Episode 290/1000, Reward: 90.38\n",
            "Episode 291/1000, Reward: 90.38\n",
            "Episode 292/1000, Reward: 90.38\n",
            "Episode 293/1000, Reward: 90.38\n",
            "Episode 294/1000, Reward: 90.38\n",
            "Episode 295/1000, Reward: 90.38\n",
            "Episode 296/1000, Reward: 90.38\n",
            "Episode 297/1000, Reward: 90.38\n",
            "Episode 298/1000, Reward: 90.38\n",
            "Episode 299/1000, Reward: 90.38\n",
            "Episode 300/1000, Reward: 90.38\n",
            "Episode 301/1000, Reward: 90.38\n",
            "Episode 302/1000, Reward: 90.38\n",
            "Episode 303/1000, Reward: 90.38\n",
            "Episode 304/1000, Reward: 90.38\n",
            "Episode 305/1000, Reward: 90.38\n",
            "Episode 306/1000, Reward: 90.38\n",
            "Episode 307/1000, Reward: 90.38\n",
            "Episode 308/1000, Reward: 90.38\n",
            "Episode 309/1000, Reward: 90.38\n",
            "Episode 310/1000, Reward: 90.38\n",
            "Episode 311/1000, Reward: 90.38\n",
            "Episode 312/1000, Reward: 90.38\n",
            "Episode 313/1000, Reward: 90.38\n",
            "Episode 314/1000, Reward: 90.38\n",
            "Episode 315/1000, Reward: 90.38\n",
            "Episode 316/1000, Reward: 90.38\n",
            "Episode 317/1000, Reward: 90.38\n",
            "Episode 318/1000, Reward: 90.38\n",
            "Episode 319/1000, Reward: 90.38\n",
            "Episode 320/1000, Reward: 90.38\n",
            "Episode 321/1000, Reward: 90.38\n",
            "Episode 322/1000, Reward: 90.38\n",
            "Episode 323/1000, Reward: 90.38\n",
            "Episode 324/1000, Reward: 90.38\n",
            "Episode 325/1000, Reward: 90.38\n",
            "Episode 326/1000, Reward: 90.38\n",
            "Episode 327/1000, Reward: 90.38\n",
            "Episode 328/1000, Reward: 90.38\n",
            "Episode 329/1000, Reward: 90.38\n",
            "Episode 330/1000, Reward: 90.38\n",
            "Episode 331/1000, Reward: 90.38\n",
            "Episode 332/1000, Reward: 90.38\n",
            "Episode 333/1000, Reward: 90.38\n",
            "Episode 334/1000, Reward: 90.38\n",
            "Episode 335/1000, Reward: 90.38\n",
            "Episode 336/1000, Reward: 90.38\n",
            "Episode 337/1000, Reward: 90.38\n",
            "Episode 338/1000, Reward: 90.38\n",
            "Episode 339/1000, Reward: 90.38\n",
            "Episode 340/1000, Reward: 90.38\n",
            "Episode 341/1000, Reward: 90.38\n",
            "Episode 342/1000, Reward: 90.38\n",
            "Episode 343/1000, Reward: 90.38\n",
            "Episode 344/1000, Reward: 90.38\n",
            "Episode 345/1000, Reward: 90.38\n",
            "Episode 346/1000, Reward: 90.38\n",
            "Episode 347/1000, Reward: 90.38\n",
            "Episode 348/1000, Reward: 90.38\n",
            "Episode 349/1000, Reward: 90.38\n",
            "Episode 350/1000, Reward: 90.38\n",
            "Episode 351/1000, Reward: 90.38\n",
            "Episode 352/1000, Reward: 90.38\n",
            "Episode 353/1000, Reward: 90.38\n",
            "Episode 354/1000, Reward: 90.38\n",
            "Episode 355/1000, Reward: 90.38\n",
            "Episode 356/1000, Reward: 90.38\n",
            "Episode 357/1000, Reward: 90.38\n",
            "Episode 358/1000, Reward: 90.38\n",
            "Episode 359/1000, Reward: 90.38\n",
            "Episode 360/1000, Reward: 90.38\n",
            "Episode 361/1000, Reward: 90.38\n",
            "Episode 362/1000, Reward: 90.38\n",
            "Episode 363/1000, Reward: 90.38\n",
            "Episode 364/1000, Reward: 90.38\n",
            "Episode 365/1000, Reward: 90.38\n",
            "Episode 366/1000, Reward: 90.38\n",
            "Episode 367/1000, Reward: 90.38\n",
            "Episode 368/1000, Reward: 90.38\n",
            "Episode 369/1000, Reward: 90.38\n",
            "Episode 370/1000, Reward: 90.38\n",
            "Episode 371/1000, Reward: 90.38\n",
            "Episode 372/1000, Reward: 90.38\n",
            "Episode 373/1000, Reward: 90.38\n",
            "Episode 374/1000, Reward: 90.38\n",
            "Episode 375/1000, Reward: 90.38\n",
            "Episode 376/1000, Reward: 90.38\n",
            "Episode 377/1000, Reward: 90.38\n",
            "Episode 378/1000, Reward: 90.38\n",
            "Episode 379/1000, Reward: 90.38\n",
            "Episode 380/1000, Reward: 90.38\n",
            "Episode 381/1000, Reward: 90.38\n",
            "Episode 382/1000, Reward: 90.38\n",
            "Episode 383/1000, Reward: 90.38\n",
            "Episode 384/1000, Reward: 90.38\n",
            "Episode 385/1000, Reward: 90.38\n",
            "Episode 386/1000, Reward: 90.38\n",
            "Episode 387/1000, Reward: 90.38\n",
            "Episode 388/1000, Reward: 90.38\n",
            "Episode 389/1000, Reward: 90.38\n",
            "Episode 390/1000, Reward: 90.38\n",
            "Episode 391/1000, Reward: 90.38\n",
            "Episode 392/1000, Reward: 90.38\n",
            "Episode 393/1000, Reward: 90.38\n",
            "Episode 394/1000, Reward: 90.38\n",
            "Episode 395/1000, Reward: 90.38\n",
            "Episode 396/1000, Reward: 90.38\n",
            "Episode 397/1000, Reward: 90.38\n",
            "Episode 398/1000, Reward: 90.38\n",
            "Episode 399/1000, Reward: 90.38\n",
            "Episode 400/1000, Reward: 90.38\n",
            "Episode 401/1000, Reward: 90.38\n",
            "Episode 402/1000, Reward: 90.38\n",
            "Episode 403/1000, Reward: 90.38\n",
            "Episode 404/1000, Reward: 90.38\n",
            "Episode 405/1000, Reward: 90.38\n",
            "Episode 406/1000, Reward: 90.38\n",
            "Episode 407/1000, Reward: 90.38\n",
            "Episode 408/1000, Reward: 90.38\n",
            "Episode 409/1000, Reward: 90.38\n",
            "Episode 410/1000, Reward: 90.38\n",
            "Episode 411/1000, Reward: 90.38\n",
            "Episode 412/1000, Reward: 90.38\n",
            "Episode 413/1000, Reward: 90.38\n",
            "Episode 414/1000, Reward: 90.38\n",
            "Episode 415/1000, Reward: 90.38\n",
            "Episode 416/1000, Reward: 90.38\n",
            "Episode 417/1000, Reward: 90.38\n",
            "Episode 418/1000, Reward: 90.38\n",
            "Episode 419/1000, Reward: 90.38\n",
            "Episode 420/1000, Reward: 90.38\n",
            "Episode 421/1000, Reward: 90.38\n",
            "Episode 422/1000, Reward: 90.38\n",
            "Episode 423/1000, Reward: 90.38\n",
            "Episode 424/1000, Reward: 90.38\n",
            "Episode 425/1000, Reward: 90.38\n",
            "Episode 426/1000, Reward: 90.38\n",
            "Episode 427/1000, Reward: 90.38\n",
            "Episode 428/1000, Reward: 90.38\n",
            "Episode 429/1000, Reward: 90.38\n",
            "Episode 430/1000, Reward: 90.38\n",
            "Episode 431/1000, Reward: 90.38\n",
            "Episode 432/1000, Reward: 90.38\n",
            "Episode 433/1000, Reward: 90.38\n",
            "Episode 434/1000, Reward: 90.38\n",
            "Episode 435/1000, Reward: 90.38\n",
            "Episode 436/1000, Reward: 90.38\n",
            "Episode 437/1000, Reward: 90.38\n",
            "Episode 438/1000, Reward: 90.38\n",
            "Episode 439/1000, Reward: 90.38\n",
            "Episode 440/1000, Reward: 90.38\n",
            "Episode 441/1000, Reward: 90.38\n",
            "Episode 442/1000, Reward: 90.38\n",
            "Episode 443/1000, Reward: 90.38\n",
            "Episode 444/1000, Reward: 90.38\n",
            "Episode 445/1000, Reward: 90.38\n",
            "Episode 446/1000, Reward: 90.38\n",
            "Episode 447/1000, Reward: 90.38\n",
            "Episode 448/1000, Reward: 90.38\n",
            "Episode 449/1000, Reward: 90.38\n",
            "Episode 450/1000, Reward: 90.38\n",
            "Episode 451/1000, Reward: 90.38\n",
            "Episode 452/1000, Reward: 90.38\n",
            "Episode 453/1000, Reward: 90.38\n",
            "Episode 454/1000, Reward: 90.38\n",
            "Episode 455/1000, Reward: 90.38\n",
            "Episode 456/1000, Reward: 90.38\n",
            "Episode 457/1000, Reward: 90.38\n",
            "Episode 458/1000, Reward: 90.38\n",
            "Episode 459/1000, Reward: 90.38\n",
            "Episode 460/1000, Reward: 90.38\n",
            "Episode 461/1000, Reward: 90.38\n",
            "Episode 462/1000, Reward: 90.38\n",
            "Episode 463/1000, Reward: 90.38\n",
            "Episode 464/1000, Reward: 90.38\n",
            "Episode 465/1000, Reward: 90.38\n",
            "Episode 466/1000, Reward: 90.38\n",
            "Episode 467/1000, Reward: 90.38\n",
            "Episode 468/1000, Reward: 90.38\n",
            "Episode 469/1000, Reward: 90.38\n",
            "Episode 470/1000, Reward: 90.38\n",
            "Episode 471/1000, Reward: 90.38\n",
            "Episode 472/1000, Reward: 90.38\n",
            "Episode 473/1000, Reward: 90.38\n",
            "Episode 474/1000, Reward: 90.38\n",
            "Episode 475/1000, Reward: 90.38\n",
            "Episode 476/1000, Reward: 90.38\n",
            "Episode 477/1000, Reward: 90.38\n",
            "Episode 478/1000, Reward: 90.38\n",
            "Episode 479/1000, Reward: 90.38\n",
            "Episode 480/1000, Reward: 90.38\n",
            "Episode 481/1000, Reward: 90.38\n",
            "Episode 482/1000, Reward: 90.38\n",
            "Episode 483/1000, Reward: 90.38\n",
            "Episode 484/1000, Reward: 90.38\n",
            "Episode 485/1000, Reward: 90.38\n",
            "Episode 486/1000, Reward: 90.38\n",
            "Episode 487/1000, Reward: 90.38\n",
            "Episode 488/1000, Reward: 90.38\n",
            "Episode 489/1000, Reward: 90.38\n",
            "Episode 490/1000, Reward: 90.38\n",
            "Episode 491/1000, Reward: 90.38\n",
            "Episode 492/1000, Reward: 90.38\n",
            "Episode 493/1000, Reward: 90.38\n",
            "Episode 494/1000, Reward: 90.38\n",
            "Episode 495/1000, Reward: 90.38\n",
            "Episode 496/1000, Reward: 90.38\n",
            "Episode 497/1000, Reward: 90.38\n",
            "Episode 498/1000, Reward: 90.38\n",
            "Episode 499/1000, Reward: 90.38\n",
            "Episode 500/1000, Reward: 90.38\n",
            "Episode 501/1000, Reward: 90.38\n",
            "Episode 502/1000, Reward: 90.38\n",
            "Episode 503/1000, Reward: 90.38\n",
            "Episode 504/1000, Reward: 90.38\n",
            "Episode 505/1000, Reward: 90.38\n",
            "Episode 506/1000, Reward: 90.38\n",
            "Episode 507/1000, Reward: 90.38\n",
            "Episode 508/1000, Reward: 90.38\n",
            "Episode 509/1000, Reward: 90.38\n",
            "Episode 510/1000, Reward: 90.38\n",
            "Episode 511/1000, Reward: 90.38\n",
            "Episode 512/1000, Reward: 90.38\n",
            "Episode 513/1000, Reward: 90.38\n",
            "Episode 514/1000, Reward: 90.38\n",
            "Episode 515/1000, Reward: 90.38\n",
            "Episode 516/1000, Reward: 90.38\n",
            "Episode 517/1000, Reward: 90.38\n",
            "Episode 518/1000, Reward: 90.38\n",
            "Episode 519/1000, Reward: 90.38\n",
            "Episode 520/1000, Reward: 90.38\n",
            "Episode 521/1000, Reward: 90.38\n",
            "Episode 522/1000, Reward: 90.38\n",
            "Episode 523/1000, Reward: 90.38\n",
            "Episode 524/1000, Reward: 90.38\n",
            "Episode 525/1000, Reward: 90.38\n",
            "Episode 526/1000, Reward: 90.38\n",
            "Episode 527/1000, Reward: 90.38\n",
            "Episode 528/1000, Reward: 90.38\n",
            "Episode 529/1000, Reward: 90.38\n",
            "Episode 530/1000, Reward: 90.38\n",
            "Episode 531/1000, Reward: 90.38\n",
            "Episode 532/1000, Reward: 90.38\n",
            "Episode 533/1000, Reward: 90.38\n",
            "Episode 534/1000, Reward: 90.38\n",
            "Episode 535/1000, Reward: 90.38\n",
            "Episode 536/1000, Reward: 90.38\n",
            "Episode 537/1000, Reward: 90.38\n",
            "Episode 538/1000, Reward: 90.38\n",
            "Episode 539/1000, Reward: 90.38\n",
            "Episode 540/1000, Reward: 90.38\n",
            "Episode 541/1000, Reward: 90.38\n",
            "Episode 542/1000, Reward: 90.38\n",
            "Episode 543/1000, Reward: 90.38\n",
            "Episode 544/1000, Reward: 90.38\n",
            "Episode 545/1000, Reward: 90.38\n",
            "Episode 546/1000, Reward: 90.38\n",
            "Episode 547/1000, Reward: 90.38\n",
            "Episode 548/1000, Reward: 90.38\n",
            "Episode 549/1000, Reward: 90.38\n",
            "Episode 550/1000, Reward: 90.38\n",
            "Episode 551/1000, Reward: 90.38\n",
            "Episode 552/1000, Reward: 90.38\n",
            "Episode 553/1000, Reward: 90.38\n",
            "Episode 554/1000, Reward: 90.38\n",
            "Episode 555/1000, Reward: 90.38\n",
            "Episode 556/1000, Reward: 90.38\n",
            "Episode 557/1000, Reward: 90.38\n",
            "Episode 558/1000, Reward: 90.38\n",
            "Episode 559/1000, Reward: 90.38\n",
            "Episode 560/1000, Reward: 90.38\n",
            "Episode 561/1000, Reward: 90.38\n",
            "Episode 562/1000, Reward: 90.38\n",
            "Episode 563/1000, Reward: 90.38\n",
            "Episode 564/1000, Reward: 90.38\n",
            "Episode 565/1000, Reward: 90.38\n",
            "Episode 566/1000, Reward: 90.38\n",
            "Episode 567/1000, Reward: 90.38\n",
            "Episode 568/1000, Reward: 90.38\n",
            "Episode 569/1000, Reward: 90.38\n",
            "Episode 570/1000, Reward: 90.38\n",
            "Episode 571/1000, Reward: 90.38\n",
            "Episode 572/1000, Reward: 90.38\n",
            "Episode 573/1000, Reward: 90.38\n",
            "Episode 574/1000, Reward: 90.38\n",
            "Episode 575/1000, Reward: 90.38\n",
            "Episode 576/1000, Reward: 90.38\n",
            "Episode 577/1000, Reward: 90.38\n",
            "Episode 578/1000, Reward: 90.38\n",
            "Episode 579/1000, Reward: 90.38\n",
            "Episode 580/1000, Reward: 90.38\n",
            "Episode 581/1000, Reward: 90.38\n",
            "Episode 582/1000, Reward: 90.38\n",
            "Episode 583/1000, Reward: 90.38\n",
            "Episode 584/1000, Reward: 90.38\n",
            "Episode 585/1000, Reward: 90.38\n",
            "Episode 586/1000, Reward: 90.38\n",
            "Episode 587/1000, Reward: 90.38\n",
            "Episode 588/1000, Reward: 90.38\n",
            "Episode 589/1000, Reward: 90.38\n",
            "Episode 590/1000, Reward: 90.38\n",
            "Episode 591/1000, Reward: 90.38\n",
            "Episode 592/1000, Reward: 90.38\n",
            "Episode 593/1000, Reward: 90.38\n",
            "Episode 594/1000, Reward: 90.38\n",
            "Episode 595/1000, Reward: 90.38\n",
            "Episode 596/1000, Reward: 90.38\n",
            "Episode 597/1000, Reward: 90.38\n",
            "Episode 598/1000, Reward: 90.38\n",
            "Episode 599/1000, Reward: 90.38\n",
            "Episode 600/1000, Reward: 90.38\n",
            "Episode 601/1000, Reward: 90.38\n",
            "Episode 602/1000, Reward: 90.38\n",
            "Episode 603/1000, Reward: 90.38\n",
            "Episode 604/1000, Reward: 90.38\n",
            "Episode 605/1000, Reward: 90.38\n",
            "Episode 606/1000, Reward: 90.38\n",
            "Episode 607/1000, Reward: 90.38\n",
            "Episode 608/1000, Reward: 90.38\n",
            "Episode 609/1000, Reward: 90.38\n",
            "Episode 610/1000, Reward: 90.38\n",
            "Episode 611/1000, Reward: 90.38\n",
            "Episode 612/1000, Reward: 90.38\n",
            "Episode 613/1000, Reward: 90.38\n",
            "Episode 614/1000, Reward: 90.38\n",
            "Episode 615/1000, Reward: 90.38\n",
            "Episode 616/1000, Reward: 90.38\n",
            "Episode 617/1000, Reward: 90.38\n",
            "Episode 618/1000, Reward: 90.38\n",
            "Episode 619/1000, Reward: 90.38\n",
            "Episode 620/1000, Reward: 90.38\n",
            "Episode 621/1000, Reward: 90.38\n",
            "Episode 622/1000, Reward: 90.38\n",
            "Episode 623/1000, Reward: 90.38\n",
            "Episode 624/1000, Reward: 90.38\n",
            "Episode 625/1000, Reward: 90.38\n",
            "Episode 626/1000, Reward: 90.38\n",
            "Episode 627/1000, Reward: 90.38\n",
            "Episode 628/1000, Reward: 90.38\n",
            "Episode 629/1000, Reward: 90.38\n",
            "Episode 630/1000, Reward: 90.38\n",
            "Episode 631/1000, Reward: 90.38\n",
            "Episode 632/1000, Reward: 90.38\n",
            "Episode 633/1000, Reward: 90.38\n",
            "Episode 634/1000, Reward: 90.38\n",
            "Episode 635/1000, Reward: 90.38\n",
            "Episode 636/1000, Reward: 90.38\n",
            "Episode 637/1000, Reward: 90.38\n",
            "Episode 638/1000, Reward: 90.38\n",
            "Episode 639/1000, Reward: 90.38\n",
            "Episode 640/1000, Reward: 90.38\n",
            "Episode 641/1000, Reward: 90.38\n",
            "Episode 642/1000, Reward: 90.38\n",
            "Episode 643/1000, Reward: 90.38\n",
            "Episode 644/1000, Reward: 90.38\n",
            "Episode 645/1000, Reward: 90.38\n",
            "Episode 646/1000, Reward: 90.38\n",
            "Episode 647/1000, Reward: 90.38\n",
            "Episode 648/1000, Reward: 90.38\n",
            "Episode 649/1000, Reward: 90.38\n",
            "Episode 650/1000, Reward: 90.38\n",
            "Episode 651/1000, Reward: 90.38\n",
            "Episode 652/1000, Reward: 90.38\n",
            "Episode 653/1000, Reward: 90.38\n",
            "Episode 654/1000, Reward: 90.38\n",
            "Episode 655/1000, Reward: 90.38\n",
            "Episode 656/1000, Reward: 90.38\n",
            "Episode 657/1000, Reward: 90.38\n",
            "Episode 658/1000, Reward: 90.38\n",
            "Episode 659/1000, Reward: 90.38\n",
            "Episode 660/1000, Reward: 90.38\n",
            "Episode 661/1000, Reward: 90.38\n",
            "Episode 662/1000, Reward: 90.38\n",
            "Episode 663/1000, Reward: 90.38\n",
            "Episode 664/1000, Reward: 90.38\n",
            "Episode 665/1000, Reward: 90.38\n",
            "Episode 666/1000, Reward: 90.38\n",
            "Episode 667/1000, Reward: 90.38\n",
            "Episode 668/1000, Reward: 90.38\n",
            "Episode 669/1000, Reward: 90.38\n",
            "Episode 670/1000, Reward: 90.38\n",
            "Episode 671/1000, Reward: 90.38\n",
            "Episode 672/1000, Reward: 90.38\n",
            "Episode 673/1000, Reward: 90.38\n",
            "Episode 674/1000, Reward: 90.38\n",
            "Episode 675/1000, Reward: 90.38\n",
            "Episode 676/1000, Reward: 90.38\n",
            "Episode 677/1000, Reward: 90.38\n",
            "Episode 678/1000, Reward: 90.38\n",
            "Episode 679/1000, Reward: 90.38\n",
            "Episode 680/1000, Reward: 90.38\n",
            "Episode 681/1000, Reward: 90.38\n",
            "Episode 682/1000, Reward: 90.38\n",
            "Episode 683/1000, Reward: 90.38\n",
            "Episode 684/1000, Reward: 90.38\n",
            "Episode 685/1000, Reward: 90.38\n",
            "Episode 686/1000, Reward: 90.38\n",
            "Episode 687/1000, Reward: 90.38\n",
            "Episode 688/1000, Reward: 90.38\n",
            "Episode 689/1000, Reward: 90.38\n",
            "Episode 690/1000, Reward: 90.38\n",
            "Episode 691/1000, Reward: 90.38\n",
            "Episode 692/1000, Reward: 90.38\n",
            "Episode 693/1000, Reward: 90.38\n",
            "Episode 694/1000, Reward: 90.38\n",
            "Episode 695/1000, Reward: 90.38\n",
            "Episode 696/1000, Reward: 90.38\n",
            "Episode 697/1000, Reward: 90.38\n",
            "Episode 698/1000, Reward: 90.38\n",
            "Episode 699/1000, Reward: 90.38\n",
            "Episode 700/1000, Reward: 90.38\n",
            "Episode 701/1000, Reward: 90.38\n",
            "Episode 702/1000, Reward: 90.38\n",
            "Episode 703/1000, Reward: 90.38\n",
            "Episode 704/1000, Reward: 90.38\n",
            "Episode 705/1000, Reward: 90.38\n",
            "Episode 706/1000, Reward: 90.38\n",
            "Episode 707/1000, Reward: 90.38\n",
            "Episode 708/1000, Reward: 90.38\n",
            "Episode 709/1000, Reward: 90.38\n",
            "Episode 710/1000, Reward: 90.38\n",
            "Episode 711/1000, Reward: 90.38\n",
            "Episode 712/1000, Reward: 90.38\n",
            "Episode 713/1000, Reward: 90.38\n",
            "Episode 714/1000, Reward: 90.38\n",
            "Episode 715/1000, Reward: 90.38\n",
            "Episode 716/1000, Reward: 90.38\n",
            "Episode 717/1000, Reward: 90.38\n",
            "Episode 718/1000, Reward: 90.38\n",
            "Episode 719/1000, Reward: 90.38\n",
            "Episode 720/1000, Reward: 90.38\n",
            "Episode 721/1000, Reward: 90.38\n",
            "Episode 722/1000, Reward: 90.38\n",
            "Episode 723/1000, Reward: 90.38\n",
            "Episode 724/1000, Reward: 90.38\n",
            "Episode 725/1000, Reward: 90.38\n",
            "Episode 726/1000, Reward: 90.38\n",
            "Episode 727/1000, Reward: 90.38\n",
            "Episode 728/1000, Reward: 90.38\n",
            "Episode 729/1000, Reward: 90.38\n",
            "Episode 730/1000, Reward: 90.38\n",
            "Episode 731/1000, Reward: 90.38\n",
            "Episode 732/1000, Reward: 90.38\n",
            "Episode 733/1000, Reward: 90.38\n",
            "Episode 734/1000, Reward: 90.38\n",
            "Episode 735/1000, Reward: 90.38\n",
            "Episode 736/1000, Reward: 90.38\n",
            "Episode 737/1000, Reward: 90.38\n",
            "Episode 738/1000, Reward: 90.38\n",
            "Episode 739/1000, Reward: 90.38\n",
            "Episode 740/1000, Reward: 90.38\n",
            "Episode 741/1000, Reward: 90.38\n",
            "Episode 742/1000, Reward: 90.38\n",
            "Episode 743/1000, Reward: 90.38\n",
            "Episode 744/1000, Reward: 90.38\n",
            "Episode 745/1000, Reward: 90.38\n",
            "Episode 746/1000, Reward: 90.38\n",
            "Episode 747/1000, Reward: 90.38\n",
            "Episode 748/1000, Reward: 90.38\n",
            "Episode 749/1000, Reward: 90.38\n",
            "Episode 750/1000, Reward: 90.38\n",
            "Episode 751/1000, Reward: 90.38\n",
            "Episode 752/1000, Reward: 90.38\n",
            "Episode 753/1000, Reward: 90.38\n",
            "Episode 754/1000, Reward: 90.38\n",
            "Episode 755/1000, Reward: 90.38\n",
            "Episode 756/1000, Reward: 90.38\n",
            "Episode 757/1000, Reward: 90.38\n",
            "Episode 758/1000, Reward: 90.38\n",
            "Episode 759/1000, Reward: 90.38\n",
            "Episode 760/1000, Reward: 90.38\n",
            "Episode 761/1000, Reward: 90.38\n",
            "Episode 762/1000, Reward: 90.38\n",
            "Episode 763/1000, Reward: 90.38\n",
            "Episode 764/1000, Reward: 90.38\n",
            "Episode 765/1000, Reward: 90.38\n",
            "Episode 766/1000, Reward: 90.38\n",
            "Episode 767/1000, Reward: 90.38\n",
            "Episode 768/1000, Reward: 90.38\n",
            "Episode 769/1000, Reward: 90.38\n",
            "Episode 770/1000, Reward: 90.38\n",
            "Episode 771/1000, Reward: 90.38\n",
            "Episode 772/1000, Reward: 90.38\n",
            "Episode 773/1000, Reward: 90.38\n",
            "Episode 774/1000, Reward: 90.38\n",
            "Episode 775/1000, Reward: 90.38\n",
            "Episode 776/1000, Reward: 90.38\n",
            "Episode 777/1000, Reward: 90.38\n",
            "Episode 778/1000, Reward: 90.38\n",
            "Episode 779/1000, Reward: 90.38\n",
            "Episode 780/1000, Reward: 90.38\n",
            "Episode 781/1000, Reward: 90.38\n",
            "Episode 782/1000, Reward: 90.38\n",
            "Episode 783/1000, Reward: 90.38\n",
            "Episode 784/1000, Reward: 90.38\n",
            "Episode 785/1000, Reward: 90.38\n",
            "Episode 786/1000, Reward: 90.38\n",
            "Episode 787/1000, Reward: 90.38\n",
            "Episode 788/1000, Reward: 90.38\n",
            "Episode 789/1000, Reward: 90.38\n",
            "Episode 790/1000, Reward: 90.38\n",
            "Episode 791/1000, Reward: 90.38\n",
            "Episode 792/1000, Reward: 90.38\n",
            "Episode 793/1000, Reward: 90.38\n",
            "Episode 794/1000, Reward: 90.38\n",
            "Episode 795/1000, Reward: 90.38\n",
            "Episode 796/1000, Reward: 90.38\n",
            "Episode 797/1000, Reward: 90.38\n",
            "Episode 798/1000, Reward: 90.38\n",
            "Episode 799/1000, Reward: 90.38\n",
            "Episode 800/1000, Reward: 90.38\n",
            "Episode 801/1000, Reward: 90.38\n",
            "Episode 802/1000, Reward: 90.38\n",
            "Episode 803/1000, Reward: 90.38\n",
            "Episode 804/1000, Reward: 90.38\n",
            "Episode 805/1000, Reward: 90.38\n",
            "Episode 806/1000, Reward: 90.38\n",
            "Episode 807/1000, Reward: 90.38\n",
            "Episode 808/1000, Reward: 90.38\n",
            "Episode 809/1000, Reward: 90.38\n",
            "Episode 810/1000, Reward: 90.38\n",
            "Episode 811/1000, Reward: 90.38\n",
            "Episode 812/1000, Reward: 90.38\n",
            "Episode 813/1000, Reward: 90.38\n",
            "Episode 814/1000, Reward: 90.38\n",
            "Episode 815/1000, Reward: 90.38\n",
            "Episode 816/1000, Reward: 90.38\n",
            "Episode 817/1000, Reward: 90.38\n",
            "Episode 818/1000, Reward: 90.38\n",
            "Episode 819/1000, Reward: 90.38\n",
            "Episode 820/1000, Reward: 90.38\n",
            "Episode 821/1000, Reward: 90.38\n",
            "Episode 822/1000, Reward: 90.38\n",
            "Episode 823/1000, Reward: 90.38\n",
            "Episode 824/1000, Reward: 90.38\n",
            "Episode 825/1000, Reward: 90.38\n",
            "Episode 826/1000, Reward: 90.38\n",
            "Episode 827/1000, Reward: 90.38\n",
            "Episode 828/1000, Reward: 90.38\n",
            "Episode 829/1000, Reward: 90.38\n",
            "Episode 830/1000, Reward: 90.38\n",
            "Episode 831/1000, Reward: 90.38\n",
            "Episode 832/1000, Reward: 90.38\n",
            "Episode 833/1000, Reward: 90.38\n",
            "Episode 834/1000, Reward: 90.38\n",
            "Episode 835/1000, Reward: 90.38\n",
            "Episode 836/1000, Reward: 90.38\n",
            "Episode 837/1000, Reward: 90.38\n",
            "Episode 838/1000, Reward: 90.38\n",
            "Episode 839/1000, Reward: 90.38\n",
            "Episode 840/1000, Reward: 90.38\n",
            "Episode 841/1000, Reward: 90.38\n",
            "Episode 842/1000, Reward: 90.38\n",
            "Episode 843/1000, Reward: 90.38\n",
            "Episode 844/1000, Reward: 90.38\n",
            "Episode 845/1000, Reward: 90.38\n",
            "Episode 846/1000, Reward: 90.38\n",
            "Episode 847/1000, Reward: 90.38\n",
            "Episode 848/1000, Reward: 90.38\n",
            "Episode 849/1000, Reward: 90.38\n",
            "Episode 850/1000, Reward: 90.38\n",
            "Episode 851/1000, Reward: 90.38\n",
            "Episode 852/1000, Reward: 90.38\n",
            "Episode 853/1000, Reward: 90.38\n",
            "Episode 854/1000, Reward: 90.38\n",
            "Episode 855/1000, Reward: 90.38\n",
            "Episode 856/1000, Reward: 90.38\n",
            "Episode 857/1000, Reward: 90.38\n",
            "Episode 858/1000, Reward: 90.38\n",
            "Episode 859/1000, Reward: 90.38\n",
            "Episode 860/1000, Reward: 90.38\n",
            "Episode 861/1000, Reward: 90.38\n",
            "Episode 862/1000, Reward: 90.38\n",
            "Episode 863/1000, Reward: 90.38\n",
            "Episode 864/1000, Reward: 90.38\n",
            "Episode 865/1000, Reward: 90.38\n",
            "Episode 866/1000, Reward: 90.38\n",
            "Episode 867/1000, Reward: 90.38\n",
            "Episode 868/1000, Reward: 90.38\n",
            "Episode 869/1000, Reward: 90.38\n",
            "Episode 870/1000, Reward: 90.38\n",
            "Episode 871/1000, Reward: 90.38\n",
            "Episode 872/1000, Reward: 90.38\n",
            "Episode 873/1000, Reward: 90.38\n",
            "Episode 874/1000, Reward: 90.38\n",
            "Episode 875/1000, Reward: 90.38\n",
            "Episode 876/1000, Reward: 90.38\n",
            "Episode 877/1000, Reward: 90.38\n",
            "Episode 878/1000, Reward: 90.38\n",
            "Episode 879/1000, Reward: 90.38\n",
            "Episode 880/1000, Reward: 90.38\n",
            "Episode 881/1000, Reward: 90.38\n",
            "Episode 882/1000, Reward: 90.38\n",
            "Episode 883/1000, Reward: 90.38\n",
            "Episode 884/1000, Reward: 90.38\n",
            "Episode 885/1000, Reward: 90.38\n",
            "Episode 886/1000, Reward: 90.38\n",
            "Episode 887/1000, Reward: 90.38\n",
            "Episode 888/1000, Reward: 90.38\n",
            "Episode 889/1000, Reward: 90.38\n",
            "Episode 890/1000, Reward: 90.38\n",
            "Episode 891/1000, Reward: 90.38\n",
            "Episode 892/1000, Reward: 90.38\n",
            "Episode 893/1000, Reward: 90.38\n",
            "Episode 894/1000, Reward: 90.38\n",
            "Episode 895/1000, Reward: 90.38\n",
            "Episode 896/1000, Reward: 90.38\n",
            "Episode 897/1000, Reward: 90.38\n",
            "Episode 898/1000, Reward: 90.38\n",
            "Episode 899/1000, Reward: 90.38\n",
            "Episode 900/1000, Reward: 90.38\n",
            "Episode 901/1000, Reward: 90.38\n",
            "Episode 902/1000, Reward: 90.38\n",
            "Episode 903/1000, Reward: 90.38\n",
            "Episode 904/1000, Reward: 90.38\n",
            "Episode 905/1000, Reward: 90.38\n",
            "Episode 906/1000, Reward: 90.38\n",
            "Episode 907/1000, Reward: 90.38\n",
            "Episode 908/1000, Reward: 90.38\n",
            "Episode 909/1000, Reward: 90.38\n",
            "Episode 910/1000, Reward: 90.38\n",
            "Episode 911/1000, Reward: 90.38\n",
            "Episode 912/1000, Reward: 90.38\n",
            "Episode 913/1000, Reward: 90.38\n",
            "Episode 914/1000, Reward: 90.38\n",
            "Episode 915/1000, Reward: 90.38\n",
            "Episode 916/1000, Reward: 90.38\n",
            "Episode 917/1000, Reward: 90.38\n",
            "Episode 918/1000, Reward: 90.38\n",
            "Episode 919/1000, Reward: 90.38\n",
            "Episode 920/1000, Reward: 90.38\n",
            "Episode 921/1000, Reward: 90.38\n",
            "Episode 922/1000, Reward: 90.38\n",
            "Episode 923/1000, Reward: 90.38\n",
            "Episode 924/1000, Reward: 90.38\n",
            "Episode 925/1000, Reward: 90.38\n",
            "Episode 926/1000, Reward: 90.38\n",
            "Episode 927/1000, Reward: 90.38\n",
            "Episode 928/1000, Reward: 90.38\n",
            "Episode 929/1000, Reward: 90.38\n",
            "Episode 930/1000, Reward: 90.38\n",
            "Episode 931/1000, Reward: 90.38\n",
            "Episode 932/1000, Reward: 90.38\n",
            "Episode 933/1000, Reward: 90.38\n",
            "Episode 934/1000, Reward: 90.38\n",
            "Episode 935/1000, Reward: 90.38\n",
            "Episode 936/1000, Reward: 90.38\n",
            "Episode 937/1000, Reward: 90.38\n",
            "Episode 938/1000, Reward: 90.38\n",
            "Episode 939/1000, Reward: 90.38\n",
            "Episode 940/1000, Reward: 90.38\n",
            "Episode 941/1000, Reward: 90.38\n",
            "Episode 942/1000, Reward: 90.38\n",
            "Episode 943/1000, Reward: 90.38\n",
            "Episode 944/1000, Reward: 90.38\n",
            "Episode 945/1000, Reward: 90.38\n",
            "Episode 946/1000, Reward: 90.38\n",
            "Episode 947/1000, Reward: 90.38\n",
            "Episode 948/1000, Reward: 90.38\n",
            "Episode 949/1000, Reward: 90.38\n",
            "Episode 950/1000, Reward: 90.38\n",
            "Episode 951/1000, Reward: 90.38\n",
            "Episode 952/1000, Reward: 90.38\n",
            "Episode 953/1000, Reward: 90.38\n",
            "Episode 954/1000, Reward: 90.38\n",
            "Episode 955/1000, Reward: 90.38\n",
            "Episode 956/1000, Reward: 90.38\n",
            "Episode 957/1000, Reward: 90.38\n",
            "Episode 958/1000, Reward: 90.38\n",
            "Episode 959/1000, Reward: 90.38\n",
            "Episode 960/1000, Reward: 90.38\n",
            "Episode 961/1000, Reward: 90.38\n",
            "Episode 962/1000, Reward: 90.38\n",
            "Episode 963/1000, Reward: 90.38\n",
            "Episode 964/1000, Reward: 90.38\n",
            "Episode 965/1000, Reward: 90.38\n",
            "Episode 966/1000, Reward: 90.38\n",
            "Episode 967/1000, Reward: 90.38\n",
            "Episode 968/1000, Reward: 90.38\n",
            "Episode 969/1000, Reward: 90.38\n",
            "Episode 970/1000, Reward: 90.38\n",
            "Episode 971/1000, Reward: 90.38\n",
            "Episode 972/1000, Reward: 90.38\n",
            "Episode 973/1000, Reward: 90.38\n",
            "Episode 974/1000, Reward: 90.38\n",
            "Episode 975/1000, Reward: 90.38\n",
            "Episode 976/1000, Reward: 90.38\n",
            "Episode 977/1000, Reward: 90.38\n",
            "Episode 978/1000, Reward: 90.38\n",
            "Episode 979/1000, Reward: 90.38\n",
            "Episode 980/1000, Reward: 90.38\n",
            "Episode 981/1000, Reward: 90.38\n",
            "Episode 982/1000, Reward: 90.38\n",
            "Episode 983/1000, Reward: 90.38\n",
            "Episode 984/1000, Reward: 90.38\n",
            "Episode 985/1000, Reward: 90.38\n",
            "Episode 986/1000, Reward: 90.38\n",
            "Episode 987/1000, Reward: 90.38\n",
            "Episode 988/1000, Reward: 90.38\n",
            "Episode 989/1000, Reward: 90.38\n",
            "Episode 990/1000, Reward: 90.38\n",
            "Episode 991/1000, Reward: 90.38\n",
            "Episode 992/1000, Reward: 90.38\n",
            "Episode 993/1000, Reward: 90.38\n",
            "Episode 994/1000, Reward: 90.38\n",
            "Episode 995/1000, Reward: 90.38\n",
            "Episode 996/1000, Reward: 90.38\n",
            "Episode 997/1000, Reward: 90.38\n",
            "Episode 998/1000, Reward: 90.38\n",
            "Episode 999/1000, Reward: 90.38\n",
            "Episode 1000/1000, Reward: 90.38\n",
            "\n",
            "Average Test Reward: 90.38\n",
            "\n",
            "Action Distribution:\n",
            "SELL: 861000\n",
            "HOLD: 16000\n",
            "BUY: 123000\n",
            "Warning: Too much selling compared to buying! Adjust reward incentives.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from gymnasium.spaces import Box\n",
        "from stable_baselines3 import TD3\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# Download Stock Data\n",
        "def download_stock_data(ticker, period=\"720d\", interval=\"1h\", max_retries=5):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt}: Downloading {ticker} stock data...\")\n",
        "            df_live = yf.download(ticker, period=period, interval=interval)\n",
        "            if not df_live.empty:\n",
        "                print(\"Successfully downloaded stock data!\")\n",
        "                df_live.reset_index(inplace=True)\n",
        "                return df_live\n",
        "            raise ValueError(\"Downloaded data is empty. Retrying...\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}. Retrying in {attempt * 5} seconds...\")\n",
        "            time.sleep(attempt * 5)\n",
        "    print(\"Failed to download stock data after multiple attempts.\")\n",
        "    return None\n",
        "\n",
        "df_live = download_stock_data(\"TSLA\")\n",
        "if df_live is None:\n",
        "    print(\"Using previously saved dataset instead.\")\n",
        "    file_path = '/content/drive/My Drive/teslafeature_engineered_dataset.csv'\n",
        "    df_live = pd.read_csv(file_path)\n",
        "\n",
        "# Prepare Dataset\n",
        "df = df_live.copy()\n",
        "\n",
        "# Fix Multi-Index Issues\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "# Feature Engineering\n",
        "df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
        "df['STD_20'] = df['Close'].rolling(window=20).std()\n",
        "df['Upper_Band'] = df['SMA_20'] + 2 * df['STD_20']\n",
        "df['Lower_Band'] = df['SMA_20'] - 2 * df['STD_20']\n",
        "df['Lowest_Low'] = df['Low'].rolling(window=14).min()\n",
        "df['Highest_High'] = df['High'].rolling(window=14).max()\n",
        "df['Stoch'] = ((df['Close'] - df['Lowest_Low']) / (df['Highest_High'] - df['Lowest_Low'])) * 100\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Create Trade Labels\n",
        "df['Future_Close'] = df['Close'].shift(-10)\n",
        "df['Price_Change'] = (df['Future_Close'] - df['Close']) / df['Close']\n",
        "df['Target'] = np.where(df['Price_Change'] > 0.03, 1, 0)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Define Trading Environment\n",
        "class ContinuousTradingEnv(gym.Env):\n",
        "    def __init__(self, df, frame_bound=(10, 100), window_size=10):\n",
        "        super().__init__()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.frame_bound = frame_bound\n",
        "        self.window_size = window_size\n",
        "        self.current_step = self.frame_bound[0]\n",
        "\n",
        "        self.action_space = Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = Box(low=-np.inf, high=np.inf, shape=(13,), dtype=np.float32)\n",
        "\n",
        "        self.initial_balance = 10_000\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "\n",
        "    def _next_observation(self):\n",
        "        stock_prices = self.df['Close'].iloc[max(0, self.current_step - self.window_size):self.current_step].values\n",
        "        if len(stock_prices) < self.window_size:\n",
        "            stock_prices = np.pad(stock_prices, (self.window_size - len(stock_prices), 0), mode='edge')\n",
        "\n",
        "        ema_10 = self.df['EMA_10'].iloc[self.current_step] if 'EMA_10' in self.df.columns else 0\n",
        "        ema_50 = self.df['EMA_50'].iloc[self.current_step] if 'EMA_50' in self.df.columns else 0\n",
        "\n",
        "        obs = np.concatenate(([self.portfolio_value], stock_prices, [self.shares_held, ema_10, ema_50]), dtype=np.float32)\n",
        "        obs = obs[:13] if len(obs) > 13 else np.pad(obs, (0, 13 - len(obs)), mode='edge')\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.current_step >= len(self.df) - 1:\n",
        "            return self._next_observation(), 0, True, False, {}\n",
        "\n",
        "        self.current_step += 1\n",
        "        stock_price = self.df['Close'].iloc[self.current_step]\n",
        "\n",
        "        trade_size = action[0] * 0.1 * self.portfolio_value\n",
        "        shares_traded = abs(trade_size) / max(stock_price, 1e-3)\n",
        "\n",
        "        reward = 0\n",
        "        if trade_size > 0 and self.portfolio_value >= shares_traded * stock_price:\n",
        "            self.shares_held += shares_traded\n",
        "            self.portfolio_value -= shares_traded * stock_price\n",
        "            reward += 0.2\n",
        "\n",
        "        elif trade_size < 0 and self.shares_held > 0:\n",
        "            shares_sold = min(shares_traded, self.shares_held)\n",
        "            self.shares_held -= shares_sold\n",
        "            self.portfolio_value += shares_sold * stock_price\n",
        "            profit_margin = (stock_price - self.df['Close'].iloc[self.current_step - 1]) / max(self.df['Close'].iloc[self.current_step - 1], 1e-6)\n",
        "            reward += profit_margin * 100 if profit_margin > 0.005 else -0.05\n",
        "\n",
        "        return self._next_observation(), reward, False, False, {}\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        self.current_step = self.frame_bound[0]\n",
        "        self.portfolio_value = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        return self._next_observation().astype(np.float32), {}\n",
        "\n",
        "# Initialize TD3 Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "env = DummyVecEnv([lambda: ContinuousTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10)])\n",
        "\n",
        "n_actions = env.action_space.shape[-1]\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "\n",
        "td3_model = TD3(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    action_noise=action_noise,\n",
        "    verbose=1,\n",
        "    learning_rate=0.0001,\n",
        "    batch_size=128,\n",
        "    gamma=0.99,\n",
        "    tau=0.01,\n",
        "    gradient_steps=2,\n",
        "    tensorboard_log=\"./td3_tensorboard/\",\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "td3_model.learn(total_timesteps=100000)\n",
        "td3_model.save(\"td3_trading_model_v1\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib28M8fOfpx4",
        "outputId": "751a5baf-2818-46b6-eb28-28d5abad8bfd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt 1: Downloading TSLA stock data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded stock data!\n",
            "Using cuda device\n",
            "Logging to ./td3_tensorboard/TD3_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store results in DataFrame\n",
        "df[\"TD3_Trade_Signal\"] = td3_trade_log\n",
        "df[\"Portfolio_Value\"] = portfolio_values\n",
        "df[\"Reward\"] = rewards\n",
        "\n",
        "# Print trade signal counts\n",
        "print((((\"\\\\\nTD3 Trade Signal Counts:\")\n",
        "print(df[\"TD3_Trade_Signal\"].value_counts())\n",
        "\n",
        "# Display first 20 trades\n",
        "print((((\"\\\\\nTD3 Trading Strategy Completed Successfully!\")\n",
        "print(df[[\"Close\", \"TD3_Trade_Signal\", \"Portfolio_Value\"]].head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxISOmOMjSqX",
        "outputId": "bfa91a1c-508a-4320-9bd2-0713225d7fc5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TD3 Trade Signal Counts:\n",
            "TD3_Trade_Signal\n",
            "HOLD    4984\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TD3 Trading Strategy Completed Successfully!\n",
            "Price       Close TD3_Trade_Signal  Portfolio_Value\n",
            "19     286.637634             HOLD          10000.0\n",
            "20     291.093353             HOLD          10000.0\n",
            "21     289.496674             HOLD          10000.0\n",
            "22     295.218353             HOLD          10000.0\n",
            "23     291.416656             HOLD          10000.0\n",
            "24     290.220001             HOLD          10000.0\n",
            "25     287.366669             HOLD          10000.0\n",
            "26     286.333344             HOLD          10000.0\n",
            "27     288.556671             HOLD          10000.0\n",
            "28     271.116669             HOLD          10000.0\n",
            "29     268.500000             HOLD          10000.0\n",
            "30     272.621674             HOLD          10000.0\n",
            "31     269.506683             HOLD          10000.0\n",
            "32     266.191620             HOLD          10000.0\n",
            "33     264.709991             HOLD          10000.0\n",
            "34     262.448334             HOLD          10000.0\n",
            "35     268.673340             HOLD          10000.0\n",
            "36     261.356659             HOLD          10000.0\n",
            "37     263.166656             HOLD          10000.0\n",
            "38     265.750732             HOLD          10000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import TD3, DDPG, PPO, A2C\n",
        "\n",
        "#Load trained models\n",
        "td3_model = TD3.load(\"td3_trading_model_v1\")\n",
        "ddpg_model = DDPG.load(\"ddpg_trading_model_v1\")\n",
        "ppo_model = PPO.load(\"ppo_trading_model_v1\")\n",
        "a2c_model = A2C.load(\"a2c_trading_model_v1\")\n",
        "\n",
        "#Initialize Evaluation Metrics\n",
        "def evaluate_model(model, env, df):\n",
        "    obs, _ = env.reset()\n",
        "    trade_log = []\n",
        "    portfolio_values = []\n",
        "    portfolio_value = 100000  # Initial balance\n",
        "    shares_held = 0\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "\n",
        "        if action < -0.3 and shares_held > 0:\n",
        "            trade_log.append(\"SELL\")\n",
        "            portfolio_value += shares_held * df[\"Close\"].iloc[i]\n",
        "            shares_held = 0\n",
        "        elif action > 0.3 and shares_held == 0:\n",
        "            trade_log.append(\"BUY\")\n",
        "            shares_held = portfolio_value / df[\"Close\"].iloc[i]\n",
        "            portfolio_value = 0\n",
        "        else:\n",
        "            trade_log.append(\"HOLD\")\n",
        "\n",
        "        portfolio_values.append(portfolio_value + (shares_held * df[\"Close\"].iloc[i]))\n",
        "        obs, _, done, _, _ = env.step(action)\n",
        "\n",
        "        if done:\n",
        "            obs, _ = env.reset()\n",
        "\n",
        "    final_value = portfolio_values[-1]\n",
        "    profit_loss = final_value - 100000\n",
        "    return trade_log, portfolio_values, final_value, profit_loss\n",
        "\n",
        "#Evaluate All Models\n",
        "td3_results = evaluate_model(td3_model, env, df)\n",
        "ddpg_results = evaluate_model(ddpg_model, env, df)\n",
        "ppo_results = evaluate_model(ppo_model, env, df)\n",
        "a2c_results = evaluate_model(a2c_model, env, df)\n",
        "\n",
        "#Rank Models Based on Profit/Loss\n",
        "model_performance = {\n",
        "    \"TD3\": td3_results[3],\n",
        "    \"DDPG\": ddpg_results[3],\n",
        "    \"PPO\": ppo_results[3],\n",
        "    \"A2C\": a2c_results[3]\n",
        "}\n",
        "\n",
        "sorted_models = sorted(model_performance.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print((((\"\\\\\nModel Ranking Based on Profit/Loss:\")\n",
        "for rank, (model, profit) in enumerate(sorted_models, start=1):\n",
        "    print(f\"{rank}. {model}: ${profit:.2f}\")\n",
        "\n",
        "#Select Winner and Plot Performance\n",
        "best_model_name = sorted_models[0][0]\n",
        "best_model_results = locals()[f\"{best_model_name.lower()}_results\"]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(best_model_results[1], label=f\"{best_model_name} Portfolio Value\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value ($)\")\n",
        "plt.title(f\"{best_model_name} Trading Model Performance\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BZC3HIhXjl_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "8e2cc2c9-0574-4ed5-d8d5-a9e08ea75c6b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'ppo_trading_model_v1.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-223f1a20bb56>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtd3_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTD3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"td3_trading_model_v1(((\"\\\\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mddpg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ddpg_trading_model_v1(((\"\\\\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mppo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppo_trading_model_v1(((\"\\\\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0ma2c_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA2C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a2c_trading_model_v1(((\"\\\\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mget_system_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         data, params, pytorch_variables = load_from_zip_file(\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mload_from_zip_file\u001b[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpytorch\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     (((\"\\\\"(((\"\\\\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r(((\"\\\\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zip(((\"\\\\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;31m# set device to cpu if cuda is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    907\u001b[0m                             '1 positional argument')\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mopen_path_str\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     (((\"\\\\"(((\"\\\\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen_path_pathlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m#   with corrections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen_path_pathlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r(((\"\\\\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb(((\"\\\\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(((\"\\\((\"\\\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"b(((\"\\\\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ppo_trading_model_v1.zip'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
