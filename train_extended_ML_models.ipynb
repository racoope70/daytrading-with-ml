{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNB2WK8CLR3GyZxcPLhguFz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoope70/daytrading-with-ml/blob/main/train_extended_ML_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra] gymnasium gym-anytrading yfinance xgboost joblib tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P3KXXKYsmib",
        "outputId": "be8e29bc-6751-4431-c28a-93470034c0b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Collecting gym-anytrading\n",
            "  Downloading gym_anytrading-2.0.0-py3-none-any.whl.metadata (292 bytes)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.54)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading gym_anytrading-2.0.0-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, gym-anytrading, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gym-anytrading-2.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y dask cudf-cu12 cuml-cu12 rapids-dask-dependency pylibraft-cu12 pylibcudf-cu12 numba stable-baselines3 gymnasium gym-anytrading"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIw-8ZUbkcWG",
        "outputId": "99285241-3618-40d5-f0e0-0de4a68c7dcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: dask 2024.11.2\n",
            "Uninstalling dask-2024.11.2:\n",
            "  Successfully uninstalled dask-2024.11.2\n",
            "Found existing installation: cudf-cu12 24.12.0\n",
            "Uninstalling cudf-cu12-24.12.0:\n",
            "  Successfully uninstalled cudf-cu12-24.12.0\n",
            "Found existing installation: cuml-cu12 24.12.0\n",
            "Uninstalling cuml-cu12-24.12.0:\n",
            "  Successfully uninstalled cuml-cu12-24.12.0\n",
            "Found existing installation: rapids-dask-dependency 24.12.0\n",
            "Uninstalling rapids-dask-dependency-24.12.0:\n",
            "  Successfully uninstalled rapids-dask-dependency-24.12.0\n",
            "Found existing installation: pylibraft-cu12 24.12.0\n",
            "Uninstalling pylibraft-cu12-24.12.0:\n",
            "  Successfully uninstalled pylibraft-cu12-24.12.0\n",
            "Found existing installation: pylibcudf-cu12 24.12.0\n",
            "Uninstalling pylibcudf-cu12-24.12.0:\n",
            "  Successfully uninstalled pylibcudf-cu12-24.12.0\n",
            "Found existing installation: numba 0.61.0\n",
            "Uninstalling numba-0.61.0:\n",
            "  Successfully uninstalled numba-0.61.0\n",
            "Found existing installation: stable_baselines3 2.5.0\n",
            "Uninstalling stable_baselines3-2.5.0:\n",
            "  Successfully uninstalled stable_baselines3-2.5.0\n",
            "Found existing installation: gymnasium 1.0.0\n",
            "Uninstalling gymnasium-1.0.0:\n",
            "  Successfully uninstalled gymnasium-1.0.0\n",
            "Found existing installation: gym-anytrading 2.0.0\n",
            "Uninstalling gym-anytrading-2.0.0:\n",
            "  Successfully uninstalled gym-anytrading-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall \\\n",
        "    dask==2024.11.2 \\\n",
        "    rapids-dask-dependency==24.12.0 \\\n",
        "    cudf-cu12==24.12.0 \\\n",
        "    cuml-cu12==24.12.0 \\\n",
        "    pylibraft-cu12==24.12.0 \\\n",
        "    pylibcudf-cu12==24.12.0 \\\n",
        "    numba==0.61.0 \\\n",
        "    stable-baselines3[extra] \\\n",
        "    gymnasium==0.29.1 \\\n",
        "    gym-anytrading==2.0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GLEB9M8WvZmC",
        "outputId": "c64a11d7-9b77-428f-be27-8f72a2dd3aab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dask==2024.11.2\n",
            "  Downloading dask-2024.11.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting rapids-dask-dependency==24.12.0\n",
            "  Downloading rapids_dask_dependency-24.12.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cudf-cu12==24.12.0\n",
            "  Downloading cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting cuml-cu12==24.12.0\n",
            "  Downloading cuml_cu12-24.12.0.tar.gz (2.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pylibraft-cu12==24.12.0\n",
            "  Downloading pylibraft_cu12-24.12.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pylibcudf-cu12==24.12.0\n",
            "  Downloading pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting numba==0.61.0\n",
            "  Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gym-anytrading==2.0.0\n",
            "  Using cached gym_anytrading-2.0.0-py3-none-any.whl.metadata (292 bytes)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Using cached stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting click>=8.1 (from dask==2024.11.2)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle>=3.0.0 (from dask==2024.11.2)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting fsspec>=2021.09.0 (from dask==2024.11.2)\n",
            "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting packaging>=20.0 (from dask==2024.11.2)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting partd>=1.4.0 (from dask==2024.11.2)\n",
            "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml>=5.3.1 (from dask==2024.11.2)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting toolz>=0.10.0 (from dask==2024.11.2)\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting importlib-metadata>=4.13.0 (from dask==2024.11.2)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting distributed==2024.11.2 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading distributed-2024.11.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting dask-expr==1.1.19 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pynvml<11.5.0a0,>=11.0.0 (from rapids-dask-dependency==24.12.0)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting cachetools (from cudf-cu12==24.12.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cuda-python<13.0a0,<=12.6.0,>=12.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting cupy-cuda12x>=12.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting libcudf-cu12==24.12.* (from cudf-cu12==24.12.0)\n",
            "  Downloading libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numba-cuda<0.0.18,>=0.0.13 (from cudf-cu12==24.12.0)\n",
            "  Downloading numba_cuda-0.0.17.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12==24.12.0)\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvtx>=0.2.1 (from cudf-cu12==24.12.0)\n",
            "  Downloading nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting pandas<2.2.4dev0,>=2.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow<19.0.0a0,>=14.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pynvjitlink-cu12 (from cudf-cu12==24.12.0)\n",
            "  Downloading pynvjitlink_cu12-0.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting rich (from cudf-cu12==24.12.0)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rmm-cu12==24.12.* (from cudf-cu12==24.12.0)\n",
            "  Downloading rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions>=4.0.0 (from cudf-cu12==24.12.0)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cuvs-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading cuvs_cu12-24.12.0.tar.gz (1.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dask-cuda==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading dask_cuda-24.12.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting dask-cudf-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading dask_cudf_cu12-24.12.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting joblib>=0.11 (from cuml-cu12==24.12.0)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.3.14-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.41-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.55-py3-none-manylinux_2_27_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.2.55-py3-none-manylinux_2_27_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12==24.12.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.7.53-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting raft-dask-cu12==24.12.* (from cuml-cu12==24.12.0)\n",
            "  Downloading raft_dask_cu12-24.12.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy>=1.8.0 (from cuml-cu12==24.12.0)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treelite==4.3.0 (from cuml-cu12==24.12.0)\n",
            "  Downloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.0)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0a0,>=1.23 (from cudf-cu12==24.12.0)\n",
            "  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farama-notifications>=0.0.1 (from gymnasium==0.29.1)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting matplotlib>=3.1.1 (from gym-anytrading==2.0.0)\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting zict>=2.0.0 (from dask-cuda==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting jinja2>=2.10.3 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting locket>=1.0.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting msgpack>=1.0.2 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting psutil>=5.8.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tornado>=6.2.0 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting urllib3>=1.26.5 (from distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting libkvikio-cu12==24.12.* (from libcudf-cu12==24.12.*->cudf-cu12==24.12.0)\n",
            "  Downloading libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting nvidia-nvcomp-cu12==4.1.0.6 (from libcudf-cu12==24.12.*->cudf-cu12==24.12.0)\n",
            "  Downloading nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl.metadata (862 bytes)\n",
            "Collecting distributed-ucxx-cu12==0.41.* (from raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading distributed_ucxx_cu12-0.41.0.tar.gz (991 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucx-py-cu12==0.41.* (from raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading ucx_py_cu12-0.41.0.tar.gz (1.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ucxx-cu12==0.41.* (from distributed-ucxx-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading ucxx_cu12-0.41.0.tar.gz (3.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting libucx-cu12<1.18,>=1.15.0 (from ucx-py-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading libucx_cu12-1.17.0.post1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting libucxx-cu12==0.41.* (from ucxx-cu12==0.41.*->distributed-ucxx-cu12==0.41.*->raft-dask-cu12==24.12.*->cuml-cu12==24.12.0)\n",
            "  Downloading libucxx_cu12-0.41.0.tar.gz (3.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch<3.0,>=2.3 (from stable-baselines3[extra])\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting opencv-python (from stable-baselines3[extra])\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pygame (from stable-baselines3[extra])\n",
            "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tqdm (from stable-baselines3[extra])\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
            "  Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting pillow (from stable-baselines3[extra])\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x>=12.0.0->cudf-cu12==24.12.0)\n",
            "  Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=4.13.0->dask==2024.11.2)\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=3.1.1->gym-anytrading==2.0.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.2.4dev0,>=2.0->cudf-cu12==24.12.0)\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.2.4dev0,>=2.0->cudf-cu12==24.12.0)\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting setuptools>=41.0.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading setuptools-75.8.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting six>1.9 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting filelock (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting networkx (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from cuml-cu12==24.12.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->cudf-cu12==24.12.0)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->cudf-cu12==24.12.0)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.10.3->distributed==2024.11.2->rapids-dask-dependency==24.12.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->cudf-cu12==24.12.0)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading dask-2024.11.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapids_dask_dependency-24.12.0-py3-none-any.whl (15 kB)\n",
            "Downloading cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached gym_anytrading-2.0.0-py3-none-any.whl (172 kB)\n",
            "Downloading dask_cuda-24.12.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_cudf_cu12-24.12.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_expr-1.1.19-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.5/244.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distributed-2024.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl (457.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.8/457.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl (915 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m916.0/916.0 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl (28.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.9/28.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba_cuda-0.0.17.1-py3-none-any.whl (424 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.7/424.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvtx-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvjitlink_cu12-0.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-75.8.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libucx_cu12-1.17.0.post1-py3-none-manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: cuml-cu12, pylibraft-cu12, cuvs-cu12, raft-dask-cu12, distributed-ucxx-cu12, ucx-py-cu12, ucxx-cu12, libucxx-cu12\n",
            "  Building wheel for cuml-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuml-cu12: filename=cuml_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=548018735 sha256=2418da8e8eb6e9e43ab4ef2a43b05eaec1b0e1c27f6eb93e9b390d625f87830d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/a8/b2/1b20fa5b8a53c9d3d5d0d9c5350683457c23d1f3e924beab41\n",
            "  Building wheel for pylibraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylibraft-cu12: filename=pylibraft_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=11802800 sha256=47d3915fd3cdf4022acbd0315f88b12155399ef0b0e77fcac050c459ab6b31b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/67/73/9252ad4b3876078a9bca569565977dd588cb54f66bd3bf2e0d\n",
            "  Building wheel for cuvs-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuvs-cu12: filename=cuvs_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=849668080 sha256=b19c011e0219334cf22fbb77768eec6798897afebdd4cbb48e6de156cfc3a1a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c8/33/82e634a5179b7034208bca3b0a465bde16e40d6212b63171b9\n",
            "  Building wheel for raft-dask-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for raft-dask-cu12: filename=raft_dask_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=196890281 sha256=22907cfcaf561dfe366b129021300168737a3cbad25812fd61819e1a9aeff4f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/14/3e/c40661899a098c7c99ae981bff10c67930615f082c0c886634\n",
            "  Building wheel for distributed-ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distributed-ucxx-cu12: filename=distributed_ucxx_cu12-0.41.0-py3-none-any.whl size=24803 sha256=73437e496b61b34a5f0f3d9e64c5873c1d176bf80379fa8318d1ebdd78fa560b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/9f/30/fc294cabfead20c6cd33ad49842809c23eb8cb9db2c857dd11\n",
            "  Building wheel for ucx-py-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucx-py-cu12: filename=ucx_py_cu12-0.41.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl size=2287997 sha256=ada163c63d31e19ff65ee1218448cea2de52e80797dca6a519a20d39fd09e2cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/e1/e6/87ca1ddc23cc8b9d857c9a0b1e8199b3ec60fe3f4efbbac3d5\n",
            "  Building wheel for ucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucxx-cu12: filename=ucxx_cu12-0.41.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl size=841184 sha256=d498bf3c805f799d4a6f7f69269169dc3c544bd30f3410a0f4876a33d2e21723\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/6f/9b/dfcf3e4fa6df3069345e6a0560c94b6f2a3161ab38904da670\n",
            "  Building wheel for libucxx-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libucxx-cu12: filename=libucxx_cu12-0.41.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl size=513262 sha256=9bd816b322e55d19230b8dda392da532e6b333e1d504c6576024dfcd78dd3177\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/04/a6/de68207e0e498ea1367f31a6e523e238e2b7afa9e31290d0cc\n",
            "Successfully built cuml-cu12 pylibraft-cu12 cuvs-cu12 raft-dask-cu12 distributed-ucxx-cu12 ucx-py-cu12 ucxx-cu12 libucxx-cu12\n",
            "Installing collected packages: triton, sortedcontainers, pytz, nvtx, nvidia-cusparselt-cu12, mpmath, libkvikio-cu12, fastrlock, farama-notifications, cuda-python, zipp, zict, urllib3, tzdata, typing_extensions, tqdm, tornado, toolz, tensorboard-data-server, tblib, sympy, six, setuptools, pyyaml, pyparsing, pynvml, pynvjitlink-cu12, pygments, pygame, pyarrow, psutil, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nvcomp-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, msgpack, mdurl, MarkupSafe, markdown, locket, llvmlite, libucx-cu12, kiwisolver, joblib, grpcio, fsspec, fonttools, filelock, cycler, cloudpickle, click, cachetools, absl-py, werkzeug, ucx-py-cu12, scipy, python-dateutil, partd, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, libucxx-cu12, libcudf-cu12, jinja2, importlib-metadata, gymnasium, cupy-cuda12x, contourpy, ale-py, treelite, tensorboard, rmm-cu12, rich, pandas, nvidia-cusolver-cu12, numba-cuda, matplotlib, dask, ucxx-cu12, torch, pylibraft-cu12, pylibcudf-cu12, gym-anytrading, distributed, dask-expr, stable-baselines3, rapids-dask-dependency, cuvs-cu12, cudf-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: nvtx\n",
            "    Found existing installation: nvtx 0.2.10\n",
            "    Uninstalling nvtx-0.2.10:\n",
            "      Successfully uninstalled nvtx-0.2.10\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: libkvikio-cu12\n",
            "    Found existing installation: libkvikio-cu12 24.12.1\n",
            "    Uninstalling libkvikio-cu12-24.12.1:\n",
            "      Successfully uninstalled libkvikio-cu12-24.12.1\n",
            "  Attempting uninstall: fastrlock\n",
            "    Found existing installation: fastrlock 0.8.3\n",
            "    Uninstalling fastrlock-0.8.3:\n",
            "      Successfully uninstalled fastrlock-0.8.3\n",
            "  Attempting uninstall: farama-notifications\n",
            "    Found existing installation: Farama-Notifications 0.0.4\n",
            "    Uninstalling Farama-Notifications-0.0.4:\n",
            "      Successfully uninstalled Farama-Notifications-0.0.4\n",
            "  Attempting uninstall: cuda-python\n",
            "    Found existing installation: cuda-python 12.6.0\n",
            "    Uninstalling cuda-python-12.6.0:\n",
            "      Successfully uninstalled cuda-python-12.6.0\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.21.0\n",
            "    Uninstalling zipp-3.21.0:\n",
            "      Successfully uninstalled zipp-3.21.0\n",
            "  Attempting uninstall: zict\n",
            "    Found existing installation: zict 3.0.0\n",
            "    Uninstalling zict-3.0.0:\n",
            "      Successfully uninstalled zict-3.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.4.2\n",
            "    Uninstalling tornado-6.4.2:\n",
            "      Successfully uninstalled tornado-6.4.2\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 0.12.1\n",
            "    Uninstalling toolz-0.12.1:\n",
            "      Successfully uninstalled toolz-0.12.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.1\n",
            "    Uninstalling pyparsing-3.2.1:\n",
            "      Successfully uninstalled pyparsing-3.2.1\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.4.1\n",
            "    Uninstalling pynvml-11.4.1:\n",
            "      Successfully uninstalled pynvml-11.4.1\n",
            "  Attempting uninstall: pynvjitlink-cu12\n",
            "    Found existing installation: pynvjitlink-cu12 0.5.0\n",
            "    Uninstalling pynvjitlink-cu12-0.5.0:\n",
            "      Successfully uninstalled pynvjitlink-cu12-0.5.0\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvcomp-cu12\n",
            "    Found existing installation: nvidia-nvcomp-cu12 4.1.0.6\n",
            "    Uninstalling nvidia-nvcomp-cu12-4.1.0.6:\n",
            "      Successfully uninstalled nvidia-nvcomp-cu12-4.1.0.6\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.7\n",
            "    Uninstalling Markdown-3.7:\n",
            "      Successfully uninstalled Markdown-3.7\n",
            "  Attempting uninstall: locket\n",
            "    Found existing installation: locket 1.0.0\n",
            "    Uninstalling locket-1.0.0:\n",
            "      Successfully uninstalled locket-1.0.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.44.0\n",
            "    Uninstalling llvmlite-0.44.0:\n",
            "      Successfully uninstalled llvmlite-0.44.0\n",
            "  Attempting uninstall: libucx-cu12\n",
            "    Found existing installation: libucx-cu12 1.17.0.post1\n",
            "    Uninstalling libucx-cu12-1.17.0.post1:\n",
            "      Successfully uninstalled libucx-cu12-1.17.0.post1\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.70.0\n",
            "    Uninstalling grpcio-1.70.0:\n",
            "      Successfully uninstalled grpcio-1.70.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.56.0\n",
            "    Uninstalling fonttools-4.56.0:\n",
            "      Successfully uninstalled fonttools-4.56.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.17.0\n",
            "    Uninstalling filelock-3.17.0:\n",
            "      Successfully uninstalled filelock-3.17.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: ucx-py-cu12\n",
            "    Found existing installation: ucx-py-cu12 0.41.0\n",
            "    Uninstalling ucx-py-cu12-0.41.0:\n",
            "      Successfully uninstalled ucx-py-cu12-0.41.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: partd\n",
            "    Found existing installation: partd 1.4.2\n",
            "    Uninstalling partd-1.4.2:\n",
            "      Successfully uninstalled partd-1.4.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: libucxx-cu12\n",
            "    Found existing installation: libucxx-cu12 0.41.0\n",
            "    Uninstalling libucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled libucxx-cu12-0.41.0\n",
            "  Attempting uninstall: libcudf-cu12\n",
            "    Found existing installation: libcudf-cu12 24.12.0\n",
            "    Uninstalling libcudf-cu12-24.12.0:\n",
            "      Successfully uninstalled libcudf-cu12-24.12.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.5\n",
            "    Uninstalling Jinja2-3.1.5:\n",
            "      Successfully uninstalled Jinja2-3.1.5\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: cupy-cuda12x\n",
            "    Found existing installation: cupy-cuda12x 13.3.0\n",
            "    Uninstalling cupy-cuda12x-13.3.0:\n",
            "      Successfully uninstalled cupy-cuda12x-13.3.0\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.10.2\n",
            "    Uninstalling ale-py-0.10.2:\n",
            "      Successfully uninstalled ale-py-0.10.2\n",
            "  Attempting uninstall: treelite\n",
            "    Found existing installation: treelite 4.3.0\n",
            "    Uninstalling treelite-4.3.0:\n",
            "      Successfully uninstalled treelite-4.3.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: rmm-cu12\n",
            "    Found existing installation: rmm-cu12 24.12.1\n",
            "    Uninstalling rmm-cu12-24.12.1:\n",
            "      Successfully uninstalled rmm-cu12-24.12.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: numba-cuda\n",
            "    Found existing installation: numba-cuda 0.0.17.1\n",
            "    Uninstalling numba-cuda-0.0.17.1:\n",
            "      Successfully uninstalled numba-cuda-0.0.17.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: ucxx-cu12\n",
            "    Found existing installation: ucxx-cu12 0.41.0\n",
            "    Uninstalling ucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled ucxx-cu12-0.41.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.11.2\n",
            "    Uninstalling distributed-2024.11.2:\n",
            "      Successfully uninstalled distributed-2024.11.2\n",
            "  Attempting uninstall: dask-expr\n",
            "    Found existing installation: dask-expr 1.1.19\n",
            "    Uninstalling dask-expr-1.1.19:\n",
            "      Successfully uninstalled dask-expr-1.1.19\n",
            "  Attempting uninstall: cuvs-cu12\n",
            "    Found existing installation: cuvs-cu12 24.12.0\n",
            "    Uninstalling cuvs-cu12-24.12.0:\n",
            "      Successfully uninstalled cuvs-cu12-24.12.0\n",
            "  Attempting uninstall: distributed-ucxx-cu12\n",
            "    Found existing installation: distributed-ucxx-cu12 0.41.0\n",
            "    Uninstalling distributed-ucxx-cu12-0.41.0:\n",
            "      Successfully uninstalled distributed-ucxx-cu12-0.41.0\n",
            "  Attempting uninstall: dask-cudf-cu12\n",
            "    Found existing installation: dask-cudf-cu12 24.12.0\n",
            "    Uninstalling dask-cudf-cu12-24.12.0:\n",
            "      Successfully uninstalled dask-cudf-cu12-24.12.0\n",
            "  Attempting uninstall: dask-cuda\n",
            "    Found existing installation: dask-cuda 24.12.0\n",
            "    Uninstalling dask-cuda-24.12.0:\n",
            "      Successfully uninstalled dask-cuda-24.12.0\n",
            "  Attempting uninstall: raft-dask-cu12\n",
            "    Found existing installation: raft-dask-cu12 24.12.0\n",
            "    Uninstalling raft-dask-cu12-24.12.0:\n",
            "      Successfully uninstalled raft-dask-cu12-24.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.2.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\n",
            "langchain 0.3.19 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
            "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.1.0 ale-py-0.10.2 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 contourpy-1.3.1 cuda-python-12.6.0 cudf-cu12-24.12.0 cuml-cu12-24.12.0 cupy-cuda12x-13.4.0 cuvs-cu12-24.12.0 cycler-0.12.1 dask-2024.11.2 dask-cuda-24.12.0 dask-cudf-cu12-24.12.0 dask-expr-1.1.19 distributed-2024.11.2 distributed-ucxx-cu12-0.41.0 farama-notifications-0.0.4 fastrlock-0.8.3 filelock-3.17.0 fonttools-4.56.0 fsspec-2025.2.0 grpcio-1.70.0 gym-anytrading-2.0.0 gymnasium-0.29.1 importlib-metadata-8.6.1 jinja2-3.1.5 joblib-1.4.2 kiwisolver-1.4.8 libcudf-cu12-24.12.0 libkvikio-cu12-24.12.1 libucx-cu12-1.17.0.post1 libucxx-cu12-0.41.0 llvmlite-0.44.0 locket-1.0.0 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.1.0 networkx-3.4.2 numba-0.61.0 numba-cuda-0.0.17.1 numpy-2.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvcomp-cu12-4.1.0.6 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 nvtx-0.2.11 opencv-python-4.11.0.86 packaging-24.2 pandas-2.2.3 partd-1.4.2 pillow-11.1.0 protobuf-5.29.3 psutil-7.0.0 pyarrow-18.1.0 pygame-2.6.1 pygments-2.19.1 pylibcudf-cu12-24.12.0 pylibraft-cu12-24.12.0 pynvjitlink-cu12-0.5.0 pynvml-11.4.1 pyparsing-3.2.1 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 raft-dask-cu12-24.12.0 rapids-dask-dependency-24.12.0 rich-13.9.4 rmm-cu12-24.12.1 scipy-1.15.2 setuptools-75.8.2 six-1.17.0 sortedcontainers-2.4.0 stable-baselines3-2.5.0 sympy-1.13.1 tblib-3.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 toolz-1.0.0 torch-2.6.0 tornado-6.4.2 tqdm-4.67.1 treelite-4.3.0 triton-3.2.0 typing_extensions-4.12.2 tzdata-2025.1 ucx-py-cu12-0.41.0 ucxx-cu12-0.41.0 urllib3-2.3.0 werkzeug-3.1.3 zict-3.0.0 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "cycler",
                  "dateutil",
                  "importlib_metadata",
                  "kiwisolver",
                  "psutil",
                  "rapids_dask_dependency",
                  "six",
                  "tornado",
                  "zipp"
                ]
              },
              "id": "da39ce7a07444f6ebb8e5a4137e9337c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cudf, cuml, dask, stable_baselines3, gymnasium\n",
        "import numba, pandas, numpy, scipy\n",
        "\n",
        "print(\"cuDF Version:\", cudf.__version__)\n",
        "print(\"cuML Version:\", cuml.__version__)\n",
        "print(\"Dask Version:\", dask.__version__)\n",
        "print(\"Stable Baselines3 Installed:\", stable_baselines3.__version__)\n",
        "print(\"Gymnasium Version:\", gymnasium.__version__)\n",
        "print(\"NumPy Version:\", numpy.__version__)\n",
        "print(\"SciPy Version:\", scipy.__version__)\n",
        "print(\"Pandas Version:\", pandas.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yHPEPTUoQHz",
        "outputId": "a040ecdd-4735-4934-ccc6-5fe34c53b5ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I] [14:54:23.109463] Import of umap.umap_.nearest_neighbors failed with: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/cuml/internals/safe_imports.py\", line 312, in safe_import_from\n",
            "    imported_module = importlib.import_module(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1126, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/umap/__init__.py\", line 7, in <module>\n",
            "    from .parametric_umap import ParametricUMAP, load_ParametricUMAP\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/umap/parametric_umap.py\", line 41, in <module>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  usort:skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\", line 163, in <module>\n",
            "    @torch.library.register_fake(\"torchvision::nms\")\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/library.py\", line 828, in register\n",
            "    use_lib._register_fake(op_name, func, _stacklevel=stacklevel + 1)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/library.py\", line 198, in _register_fake\n",
            "    handle = entry.fake_impl.register(func_to_register, source)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_library/fake_impl.py\", line 31, in register\n",
            "    if torch._C._dispatch_has_kernel_for_dispatch_key(self.qualname, \"Meta\"):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: operator torchvision::nms does not exist\n",
            "\n",
            "cuDF Version: 24.12.00\n",
            "cuML Version: 24.12.00\n",
            "Dask Version: 2024.11.2\n",
            "Stable Baselines3 Installed: 2.5.0\n",
            "Gymnasium Version: 0.29.1\n",
            "NumPy Version: 2.1.3\n",
            "SciPy Version: 1.15.2\n",
            "Pandas Version: 2.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51bQM7-vsYqa",
        "outputId": "c9b1383a-8fd3-4097-f216-cf3da6143e98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 28 14:54:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TF Version:\", tf.__version__)\n",
        "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTSo2PQ4spSE",
        "outputId": "6ce812ba-f991-4b4e-b617-dd8c0e1bd4ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Version: 2.18.0\n",
            "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Step 2: Set Environment Paths for CUDA 11.8\n",
        "import os\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-11.8'\n",
        "os.environ['PATH'] += ':/usr/local/cuda-11.8/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda-11.8/lib64'"
      ],
      "metadata": {
        "id": "Uf1Hc7Z1H0oz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    df = cudf.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})\n",
        "    print(\"cuDF is working and using GPU!\")\n",
        "except Exception as e:\n",
        "    print(f\" cuDF GPU check failed: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjLrSYVJs3vF",
        "outputId": "368f3bde-1c59-43ce-ee20-b072febea045"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuDF is working and using GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import yfinance as yf\n",
        "import gymnasium as gym  Use gymnasium instead of gym\n",
        "import gym_anytrading\n",
        "from gymnasium.envs.registration import registry, register\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Prevent cuDF from taking all GPU memory\n",
        "os.environ[\"RAPIDS_NO_INITIALIZE\"] = \"1\"\n",
        "\n",
        "RAPIDS & GPU-based Libraries (Try-Except to Avoid CPU Errors)\n",
        "try:\n",
        "    import cudf\n",
        "    import cuml\n",
        "    from cuml.ensemble import RandomForestClassifier\n",
        "    from cuml.metrics import accuracy_score\n",
        "    GPU_AVAILABLE = True\n",
        "    print(\"cuDF & cuML are available and running on GPU.\")\n",
        "except ImportError:\n",
        "    print(\" cuDF/cuML not available. Switching to CPU mode.\")\n",
        "    GPU_AVAILABLE = False\n",
        "\n",
        "Reinforcement Learning & Trading\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "TensorFlow & GPU Optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "Ensure TensorFlow GPU Memory Allocation is Configured\n",
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)  Prevents full allocation\n",
        "        print(\"TensorFlow GPU memory growth enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\" TensorFlow GPU memory issue: {e}\")\n",
        "\n",
        "Google Drive Access (for Colab)\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n-Y2MBWGTnZ",
        "outputId": "a0eb334d-759e-4ee4-c2cf-f4bda33e1ada"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuDF & cuML are available and running on GPU.\n",
            "TensorFlow GPU memory growth enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Step 6: Download Stock Data\n",
        "def download_stock_data(ticker, period=\"720d\", interval=\"1h\", max_retries=5):\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt}: Downloading {ticker} stock data...\")\n",
        "            df_live = yf.download(ticker, period=period, interval=interval)\n",
        "            if not df_live.empty:\n",
        "                print(\"Successfully downloaded stock data!\")\n",
        "                df_live.reset_index(inplace=True)\n",
        "                return df_live\n",
        "            raise ValueError(\"Downloaded data is empty. Retrying...\")\n",
        "        except Exception as e:\n",
        "            print(f\" Error: {e}. Retrying in {attempt * 5} seconds...\")\n",
        "            time.sleep(attempt * 5)\n",
        "    print(\" Failed to download stock data after multiple attempts.\")\n",
        "    return None\n",
        "\n",
        "df_live = download_stock_data(\"TSLA\")\n",
        "if df_live is None:\n",
        "    print(\" Using previously saved dataset instead.\")\n",
        "    file_path = '/content/drive/My Drive/teslafeature_engineered_dataset.csv'\n",
        "    df_live = pd.read_csv(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYPgHpYYHO_4",
        "outputId": "e8956cbc-a23b-4561-fa74-3f7d7c006b76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt 1: Downloading TSLA stock data...\n",
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded stock data!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Choose Dataset for Training\n",
        "df = df_live.copy()"
      ],
      "metadata": {
        "id": "md6lK5RVHYoh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Step 3: Fix Potential Multi-Index Issues (Optional Safety Check)\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)"
      ],
      "metadata": {
        "id": "69BiGQKbHc0D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Step 2: Feature Engineering\n",
        "=============================\n",
        "df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
        "df['STD_20'] = df['Close'].rolling(window=20).std()\n",
        "df['Upper_Band'] = df['SMA_20'] + 2 * df['STD_20']\n",
        "df['Lower_Band'] = df['SMA_20'] - 2 * df['STD_20']\n",
        "df['Lowest_Low'] = df['Low'].rolling(window=14).min()\n",
        "df['Highest_High'] = df['High'].rolling(window=14).max()\n",
        "df['Stoch'] = ((df['Close'] - df['Lowest_Low']) / (df['Highest_High'] - df['Lowest_Low'])) * 100\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "UPKFaDC2Hf4X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Create Trade Labels\n",
        "df['Future_Close'] = df['Close'].shift(-10)\n",
        "df['Price_Change'] = (df['Future_Close'] - df['Close']) / df['Close']\n",
        "df['Target'] = np.where(df['Price_Change'] > 0.03, 1, 0)\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "hpXyyFT1HiG0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Define Features & Target\n",
        "features = ['SMA_20', 'STD_20', 'Upper_Band', 'Lower_Band', 'Stoch']\n",
        "X = df[features]\n",
        "y = df['Target']\n",
        "\n",
        "Convert DataFrame to GPU (if available)\n",
        "if GPU_AVAILABLE:\n",
        "    try:\n",
        "        X = cudf.DataFrame.from_pandas(X)  Convert features to cuDF\n",
        "        y = cudf.Series(y.values)  Convert target to cuDF\n",
        "    except Exception as e:\n",
        "        print(f\" GPU Conversion Failed: {e}. Using CPU Instead.\")\n",
        "        X = X  Stay in Pandas format\n",
        "        y = y\n",
        "        GPU_AVAILABLE = False  Fallback to CPU\n",
        "\n",
        "Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n"
      ],
      "metadata": {
        "id": "W3WkeNWrHlqr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Define Feature Columns & Target Variable\n",
        "feature_columns = X_train.columns  Extract feature names from training set\n",
        "\n",
        "Train Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "Evaluate Accuracy\n",
        "rf_accuracy = accuracy_score(y_test, rf_model.predict(X_test))\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
        "\n",
        "Free Memory\n",
        "del X_train, X_test, y_train, y_test\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epm060jdzaVD",
        "outputId": "e53aa5a5-5cda-4113-9271-754c083706ed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:344: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
            "  return func(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n",
            "  ret = func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.7037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ensure df Contains Required Features\n",
        "missing_features = [col for col in feature_columns if col not in df.columns]\n",
        "if missing_features:\n",
        "    raise ValueError(f\" Missing features in df: {missing_features}\")\n",
        "\n",
        "Generate Trade Signals (BUY = 1, SELL = 0)\n",
        "df['Trade_Signal_RF'] = rf_model.predict(df[feature_columns])\n"
      ],
      "metadata": {
        "id": "QvIgn85qzedG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generate Trade Predictions (Avoid Lookahead Bias)\n",
        "df['Trade_Signal_RF'] = rf_model.predict(df[feature_columns].shift(1))  Shift by 1 to prevent lookahead bias\n",
        "\n",
        "Initialize Portfolio Metrics\n",
        "portfolio_values_rf = []\n",
        "capital_rf = 100000  Initial balance\n",
        "shares_rf = 0\n",
        "buy_price_rf = None\n",
        "max_portfolio_value_rf = capital_rf  Track peak value for max drawdown calculation\n",
        "\n",
        "Define Trade Size (Percentage of Capital Used per Trade)\n",
        "trade_size_rf = 0.05  Trade 5% of capital per trade\n",
        "\n",
        "Iterate Through Each Trade Signal\n",
        "for i, trade in enumerate(df['Trade_Signal_RF']):\n",
        "    price = df['Close'].iloc[i]\n",
        "\n",
        "    BUY Signal: Invest only a fraction of capital\n",
        "    if trade == 1 and capital_rf >= price and buy_price_rf is None:\n",
        "        trade_amount = capital_rf * trade_size_rf  Only invest a fraction\n",
        "        shares_rf = trade_amount // price\n",
        "\n",
        "        Ensure capital doesn't get negative before executing trade\n",
        "        if capital_rf - (shares_rf * price) < 0:\n",
        "            print(f\" Error: Overtrading detected at Step {i}, Capital=${capital_rf:,.2f}, Shares={shares_rf}\")\n",
        "            continue  Skip the trade to prevent negative balance\n",
        "\n",
        "        buy_price_rf = price\n",
        "        capital_rf -= shares_rf * price  Execute Buy Trade\n",
        "\n",
        "    SELL Signal: Sell only if shares are held\n",
        "    elif trade == 0 and shares_rf > 0:\n",
        "        capital_rf += shares_rf * price\n",
        "        shares_rf = 0\n",
        "        buy_price_rf = None\n",
        "\n",
        "    Track Portfolio Value\n",
        "    portfolio_value_rf = capital_rf + (shares_rf * price)\n",
        "    portfolio_values_rf.append(portfolio_value_rf)\n",
        "\n",
        "    Track Max Drawdown\n",
        "    max_portfolio_value_rf = max(max_portfolio_value_rf, portfolio_value_rf)\n",
        "\n",
        " Debugging: Detect Unrealistic Growth\n",
        "    if shares_rf == 0 and capital_rf > 150000:  Allow reasonable growth\n",
        "        print(f\" Unrealistic Growth Detected at Step {i}: Capital=${capital_rf:,.2f}, Shares={shares_rf}\")\n",
        "\n",
        "Convert Portfolio Values to DataFrame\n",
        "results_df_rf = pd.DataFrame({'Date': df.index, 'Portfolio Value': portfolio_values_rf})\n",
        "\n",
        "Compute Daily Returns\n",
        "results_df_rf['Daily Return'] = results_df_rf['Portfolio Value'].pct_change().fillna(0)\n",
        "\n",
        "Compute Performance Metrics\n",
        "rf_cumulative_return = ((results_df_rf['Portfolio Value'].iloc[-1] / 100000) - 1) * 100\n",
        "daily_return_mean_rf = results_df_rf['Daily Return'].mean()\n",
        "daily_return_std_rf = results_df_rf['Daily Return'].std()\n",
        "rf_sharpe_ratio = (daily_return_mean_rf / daily_return_std_rf) * np.sqrt(252) if daily_return_std_rf != 0 else 0\n",
        "drawdown_rf = (results_df_rf['Portfolio Value'].cummax() - results_df_rf['Portfolio Value']) / results_df_rf['Portfolio Value'].cummax()\n",
        "rf_max_drawdown = drawdown_rf.max() * 100  Convert to percentage\n",
        "\n",
        "Print Final Random Forest Performance\n",
        "print(\"\\n**Random Forest Portfolio Performance**\")\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"RF Final Portfolio Value: ${results_df_rf['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"RF Cumulative Return: {rf_cumulative_return:.2f}%\")\n",
        "print(f\"RF Sharpe Ratio: {rf_sharpe_ratio:.2f}\")\n",
        "print(f\"RF Max Drawdown: {rf_max_drawdown:.2f}%\")\n",
        "\n",
        "Free Memory\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgW5QhxOzfYf",
        "outputId": "66b689f0-1f11-491b-9776-4c46b7bc76d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Random Forest Portfolio Performance**\n",
            "Random Forest Accuracy: 0.7037\n",
            "RF Final Portfolio Value: $125,415.29\n",
            "RF Cumulative Return: 25.42%\n",
            "RF Sharpe Ratio: 2.11\n",
            "RF Max Drawdown: 0.48%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Choose Dataset for Training\n",
        "df = df_live.copy()\n",
        "\n",
        "Fix MultiIndex Issues (if applicable)\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "Remove Named Index (Fixes KeyError Issues)\n",
        "df.columns.name = None  Remove 'Price' as the column index name\n",
        "\n",
        "Ensure EMA_10 and EMA_50 exist before XGBoost training\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    print(\" 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\")\n",
        "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df.dropna(subset=['EMA_10', 'EMA_50'], inplace=True)  Drop NaNs from EMA calculations\n",
        "    print(\"EMAs computed successfully.\")\n",
        "\n",
        "Generate Trade Signals (BUY = 1, SELL = 0)\n",
        "df['Trade_Signal'] = 0  Default to SELL (0)\n",
        "\n",
        "Identify BUY signals (when EMA_10 crosses above EMA_50)\n",
        "df.loc[df['EMA_10'] > df['EMA_50'], 'Trade_Signal'] = 1\n",
        "\n",
        "Ensure Trade Signal Exists\n",
        "if 'Trade_Signal' not in df.columns or df['Trade_Signal'].isnull().all():\n",
        "    raise ValueError(\" Trade_Signal column is still missing or empty. Check feature calculations!\")\n",
        "\n",
        "print(\"Trade signals generated successfully!\")\n",
        "\n",
        "Define Feature Columns (Exclude Target Column)\n",
        "feature_columns = ['Close', 'EMA_10', 'EMA_50']\n",
        "target_column = 'Trade_Signal'\n",
        "\n",
        "Drop NaN Values (if any)\n",
        "df = df.dropna(subset=feature_columns + [target_column])\n",
        "\n",
        "Split Data into Train & Test Sets\n",
        "train_size = int(0.8 * len(df))  80% Training, 20% Testing\n",
        "X_train_xgb, y_train_xgb = df[feature_columns][:train_size], df[target_column][:train_size]\n",
        "X_test_xgb, y_test_xgb = df[feature_columns][train_size:], df[target_column][train_size:]\n",
        "\n",
        "Train XGBoost Model\n",
        "GPU_AVAILABLE = True  Set to False if no GPU is available\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist' if GPU_AVAILABLE else 'exact',\n",
        "    random_state=42\n",
        ")\n",
        "xgb_model.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "Compute Accuracy\n",
        "xgb_accuracy = accuracy_score(y_test_xgb, xgb_model.predict(X_test_xgb))\n",
        "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
        "\n",
        "Free Memory\n",
        "del X_train_xgb, y_train_xgb, X_test_xgb, y_test_xgb\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipl0B5BiJ21h",
        "outputId": "f694bbb4-22ca-45c9-bbfa-e43c189fd884"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\n",
            "EMAs computed successfully.\n",
            "Trade signals generated successfully!\n",
            "XGBoost Accuracy: 0.6836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Generate Trade Predictions for Portfolio Simulation\n",
        "df['Trade_Signal_XGB'] = xgb_model.predict(df[feature_columns])\n",
        "\n",
        "Portfolio Simulation for XGBoost Model\n",
        "portfolio_values_xgb = []\n",
        "capital_xgb = 100000\n",
        "shares_xgb = 0\n",
        "buy_price_xgb = None\n",
        "max_portfolio_value_xgb = capital_xgb\n",
        "\n",
        "for i, trade in enumerate(df['Trade_Signal_XGB']):\n",
        "    price = df['Close'].iloc[i]\n",
        "\n",
        "    if trade == 1 and capital_xgb >= price and buy_price_xgb is None:\n",
        "        shares_xgb = capital_xgb // price\n",
        "        buy_price_xgb = price\n",
        "        capital_xgb -= shares_xgb * price\n",
        "    elif trade == 0 and shares_xgb > 0:\n",
        "        capital_xgb += shares_xgb * price\n",
        "        shares_xgb = 0\n",
        "        buy_price_xgb = None\n",
        "\n",
        "    Update Portfolio Value\n",
        "    portfolio_value_xgb = capital_xgb + (shares_xgb * price)\n",
        "    portfolio_values_xgb.append(portfolio_value_xgb)\n",
        "\n",
        "    Track Max Drawdown\n",
        "    max_portfolio_value_xgb = max(max_portfolio_value_xgb, portfolio_value_xgb)\n",
        "\n",
        "Convert Portfolio Values to DataFrame\n",
        "results_df_xgb = pd.DataFrame({'Date': df.index, 'Portfolio Value': portfolio_values_xgb})\n",
        "\n",
        "Compute Performance Metrics for XGBoost\n",
        "results_df_xgb['Daily Return'] = results_df_xgb['Portfolio Value'].pct_change().fillna(0)\n",
        "xgb_cumulative_return = ((results_df_xgb['Portfolio Value'].iloc[-1] / 100000) - 1) * 100\n",
        "daily_return_mean_xgb = results_df_xgb['Daily Return'].mean()\n",
        "daily_return_std_xgb = results_df_xgb['Daily Return'].std()\n",
        "xgb_sharpe_ratio = (daily_return_mean_xgb / daily_return_std_xgb) * np.sqrt(252) if daily_return_std_xgb != 0 else 0\n",
        "drawdown_xgb = (results_df_xgb['Portfolio Value'].cummax() - results_df_xgb['Portfolio Value']) / results_df_xgb['Portfolio Value'].cummax()\n",
        "xgb_max_drawdown = drawdown_xgb.max() * 100\n",
        "\n",
        "Print Performance Metrics\n",
        "print(\"\\n**XGBoost Model Performance**\")\n",
        "print(f\"XGBoost Final Portfolio Value: ${results_df_xgb['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"XGBoost Cumulative Return: {xgb_cumulative_return:.2f}%\")\n",
        "print(f\"XGBoost Sharpe Ratio: {xgb_sharpe_ratio:.2f}\")\n",
        "print(f\"XGBoost Max Drawdown: {xgb_max_drawdown:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypeek3-43A2E",
        "outputId": "072ae04d-5556-4a37-c1bf-4f701f14b291"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**XGBoost Model Performance**\n",
            "XGBoost Final Portfolio Value: $240,328.61\n",
            "XGBoost Cumulative Return: 140.33%\n",
            "XGBoost Sharpe Ratio: 0.37\n",
            "XGBoost Max Drawdown: 32.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Choose Dataset for Training\n",
        "df = df_live.copy()\n",
        "\n",
        "Fix MultiIndex Issues (if applicable)\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "Remove Named Index (Fixes KeyError Issues)\n",
        "df.columns.name = None\n",
        "\n",
        "Ensure EMA_10 and EMA_50 exist before GBM training\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    print(\" 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\")\n",
        "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df.dropna(subset=['EMA_10', 'EMA_50'], inplace=True)\n",
        "    print(\"EMAs computed successfully.\")\n",
        "\n",
        "Generate Trade Signals (BUY = 1, SELL = 0)\n",
        "df['Trade_Signal'] = 0\n",
        "df.loc[df['EMA_10'] > df['EMA_50'], 'Trade_Signal'] = 1\n",
        "\n",
        "Ensure Trade Signal Exists\n",
        "if 'Trade_Signal' not in df.columns or df['Trade_Signal'].isnull().all():\n",
        "    raise ValueError(\" Trade_Signal column is still missing or empty. Check feature calculations!\")\n",
        "\n",
        "print(\"Trade signals generated successfully!\")\n",
        "\n",
        "Define Features and Target\n",
        "feature_columns = ['Close', 'EMA_10', 'EMA_50']\n",
        "target_column = 'Trade_Signal'\n",
        "\n",
        "Drop NaN Values\n",
        "df = df.dropna(subset=feature_columns + [target_column])\n",
        "\n",
        "Split Data into Train & Test Sets\n",
        "train_size = int(0.8 * len(df))\n",
        "X_train_gb, y_train_gb = df[feature_columns][:train_size], df[target_column][:train_size]\n",
        "X_test_gb, y_test_gb = df[feature_columns][train_size:], df[target_column][train_size:]\n",
        "\n",
        "Scale Features (Optional: Helps with Some Models)\n",
        "scaler = StandardScaler()\n",
        "X_train_gb = pd.DataFrame(scaler.fit_transform(X_train_gb), columns=feature_columns)\n",
        "X_test_gb = pd.DataFrame(scaler.transform(X_test_gb), columns=feature_columns)\n",
        "\n",
        "print(f\"Training Data Shape: {X_train_gb.shape}, {y_train_gb.shape}\")\n",
        "print(f\"Test Data Shape: {X_test_gb.shape}, {y_test_gb.shape}\")\n",
        "\n",
        "Train Gradient Boosting Model\n",
        "gb_model = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, random_state=42)\n",
        "gb_model.fit(X_train_gb, y_train_gb)\n",
        "\n",
        "Compute Accuracy\n",
        "gb_accuracy = accuracy_score(y_test_gb, gb_model.predict(X_test_gb))\n",
        "print(f\"Gradient Boosting Accuracy: {gb_accuracy:.4f}\")\n",
        "\n",
        "Free Memory\n",
        "del X_train_gb, X_test_gb, y_train_gb, y_test_gb\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGB9TCX46Vif",
        "outputId": "9f11ef34-4221-470b-d580-165c8e32004f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\n",
            "EMAs computed successfully.\n",
            "Trade signals generated successfully!\n",
            "Training Data Shape: (4008, 3), (4008,)\n",
            "Test Data Shape: (1002, 3), (1002,)\n",
            "Gradient Boosting Accuracy: 0.6537\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Trade_Signal_GB'] = gb_model.predict(df[feature_columns])\n",
        "\n",
        "Portfolio Simulation for Gradient Boosting Model\n",
        "portfolio_values_gb = []\n",
        "capital_gb = 100000\n",
        "shares_gb = 0\n",
        "buy_price_gb = None\n",
        "max_portfolio_value_gb = capital_gb\n",
        "\n",
        "for i, trade in enumerate(df['Trade_Signal_GB']):\n",
        "    price = df['Close'].iloc[i]\n",
        "\n",
        "    if trade == 1 and capital_gb >= price and buy_price_gb is None:\n",
        "        shares_gb = capital_gb // price\n",
        "        buy_price_gb = price\n",
        "        capital_gb -= shares_gb * price\n",
        "    elif trade == 0 and shares_gb > 0:\n",
        "        capital_gb += shares_gb * price\n",
        "        shares_gb = 0\n",
        "        buy_price_gb = None\n",
        "\n",
        "    Update Portfolio Value\n",
        "    portfolio_value_gb = capital_gb + (shares_gb * price)\n",
        "    portfolio_values_gb.append(portfolio_value_gb)\n",
        "\n",
        "    Track Max Drawdown\n",
        "    max_portfolio_value_gb = max(max_portfolio_value_gb, portfolio_value_gb)\n",
        "\n",
        "Convert Portfolio Values to DataFrame\n",
        "results_df_gb = pd.DataFrame({'Date': df.index, 'Portfolio Value': portfolio_values_gb})\n",
        "\n",
        "Compute Performance Metrics for Gradient Boosting\n",
        "results_df_gb['Daily Return'] = results_df_gb['Portfolio Value'].pct_change().fillna(0)\n",
        "gb_cumulative_return = ((results_df_gb['Portfolio Value'].iloc[-1] / 100000) - 1) * 100\n",
        "daily_return_mean_gb = results_df_gb['Daily Return'].mean()\n",
        "daily_return_std_gb = results_df_gb['Daily Return'].std()\n",
        "gb_sharpe_ratio = (daily_return_mean_gb / daily_return_std_gb) * np.sqrt(252) if daily_return_std_gb != 0 else 0\n",
        "drawdown_gb = (results_df_gb['Portfolio Value'].cummax() - results_df_gb['Portfolio Value']) / results_df_gb['Portfolio Value'].cummax()\n",
        "gb_max_drawdown = drawdown_gb.max() * 100\n",
        "\n",
        "Print Performance Metrics\n",
        "print(\"\\n**Gradient Boosting Model Performance**\")\n",
        "print(f\"Gradient Boosting Final Portfolio Value: ${results_df_gb['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"Gradient Boosting Cumulative Return: {gb_cumulative_return:.2f}%\")\n",
        "print(f\"Gradient Boosting Sharpe Ratio: {gb_sharpe_ratio:.2f}\")\n",
        "print(f\"Gradient Boosting Max Drawdown: {gb_max_drawdown:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRiYkegr63xD",
        "outputId": "20ed7098-9a42-49c9-b56f-ec8b9834499c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Gradient Boosting Model Performance**\n",
            "Gradient Boosting Final Portfolio Value: $84,693.72\n",
            "Gradient Boosting Cumulative Return: -15.31%\n",
            "Gradient Boosting Sharpe Ratio: 0.07\n",
            "Gradient Boosting Max Drawdown: 70.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ensure Column Names Are Flattened Correctly\n",
        "df.columns = df.columns.get_level_values(0) if isinstance(df.columns, pd.MultiIndex) else df.columns\n",
        "\n",
        "Remove Named Index (if exists)\n",
        "df.columns.name = None  Remove 'Price' as the column index name\n",
        "\n",
        "Verify Columns After Processing\n",
        "print(\"Final Columns in df:\", df.columns)\n",
        "\n",
        "Ensure 'Close' Exists Before Proceeding\n",
        "if 'Close' not in df.columns:\n",
        "    raise KeyError(\" Column 'Close' not found in the DataFrame after processing.\")\n",
        "\n",
        "Load Your Dataset\n",
        "data = df.copy()  Ensure 'df' is loaded before this step\n",
        "\n",
        "Add Technical Indicators (RSI & MACD)\n",
        "def compute_rsi(data, window=14):\n",
        "    delta = data['Close'].diff(1)\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "    rs = gain / loss\n",
        "    rsi = 100 - (100 / (1 + rs))  Compute RSI\n",
        "    return rsi  Return computed RSI values\n",
        "\n",
        "def compute_macd(data, short=12, long=26, signal=9):\n",
        "    short_ema = data['Close'].ewm(span=short, adjust=False).mean()\n",
        "    long_ema = data['Close'].ewm(span=long, adjust=False).mean()\n",
        "    data['MACD'] = short_ema - long_ema\n",
        "    data['MACD_Signal'] = data['MACD'].ewm(span=signal, adjust=False).mean()\n",
        "\n",
        "Apply Indicators to `data`\n",
        "data['RSI'] = compute_rsi(data)  Ensure RSI is assigned properly\n",
        "compute_macd(data)  Compute MACD in place\n",
        "\n",
        "Drop NaN values to avoid errors in training\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "Verify if 'RSI' column exists\n",
        "print(data.head())  Print first few rows to check if RSI is present\n",
        "\n",
        "Drop non-numeric columns before normalization (keep index intact)\n",
        "data_numeric = data.select_dtypes(include=[np.number])  Keep only numeric columns\n",
        "\n",
        "Normalize only numeric data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data_numeric)\n",
        "\n",
        "Convert back to DataFrame and retain the original index\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=data_numeric.columns, index=data.index)\n",
        "\n",
        "Check if the data looks correct\n",
        "print(scaled_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv3gU_ueKC9S",
        "outputId": "b5e038f4-0901-4d54-a36a-2b52ce40465b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Columns in df: Index(['Datetime', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_10',\n",
            "       'EMA_50', 'Trade_Signal', 'Trade_Signal_GB'],\n",
            "      dtype='object')\n",
            "                    Datetime       Close        High         Low        Open  \\\n",
            "13 2022-04-19 19:30:00+00:00  342.699982  343.010010  341.170013  342.609985   \n",
            "14 2022-04-20 13:30:00+00:00  331.940002  344.666656  330.456665  343.333344   \n",
            "15 2022-04-20 14:30:00+00:00  331.513336  335.666656  330.923340  331.943329   \n",
            "16 2022-04-20 15:30:00+00:00  326.666656  332.576660  326.000000  331.576660   \n",
            "17 2022-04-20 16:30:00+00:00  328.426666  330.100006  326.666656  326.666656   \n",
            "\n",
            "     Volume      EMA_10      EMA_50  Trade_Signal  Trade_Signal_GB        RSI  \\\n",
            "13  1593841  339.824290  336.244326             1                1  63.424303   \n",
            "14  6172282  338.390783  336.075529             1                1  46.388738   \n",
            "15  2927385  337.140338  335.896619             1                1  48.550202   \n",
            "16  2784664  335.236033  335.534660             0                1  46.652692   \n",
            "17  2131408  333.997966  335.255915             0                1  46.052234   \n",
            "\n",
            "        MACD  MACD_Signal  \n",
            "13  1.960822     1.132505  \n",
            "14  1.227258     1.151455  \n",
            "15  0.604507     1.042066  \n",
            "16 -0.276922     0.778268  \n",
            "17 -0.823945     0.457826  \n",
            "       Close      High       Low      Open    Volume    EMA_10    EMA_50  \\\n",
            "13  0.632797  0.619095  0.637664  0.634544  0.016799  0.632118  0.676165   \n",
            "14  0.604071  0.623431  0.609123  0.636464  0.065054  0.628180  0.675648   \n",
            "15  0.602932  0.599875  0.610367  0.606222  0.030854  0.624744  0.675100   \n",
            "16  0.589993  0.591788  0.597251  0.605248  0.029350  0.619512  0.673993   \n",
            "17  0.594692  0.585305  0.599027  0.592212  0.022464  0.616110  0.673139   \n",
            "\n",
            "    Trade_Signal  Trade_Signal_GB       RSI      MACD  MACD_Signal  \n",
            "13           1.0              0.0  0.635546  0.497430     0.461216  \n",
            "14           1.0              0.0  0.455878  0.475732     0.461837  \n",
            "15           1.0              0.0  0.478674  0.457311     0.458251  \n",
            "16           0.0              0.0  0.458661  0.431239     0.449602  \n",
            "17           0.0              0.0  0.452329  0.415058     0.439096  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "import gym_anytrading\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import gc\n",
        "\n",
        "Ensure GPU Availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "Load Dataset\n",
        "df = df_live.copy()\n",
        "\n",
        "Fix MultiIndex Issues (if applicable)\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "Remove Named Index (Fixes KeyError Issues)\n",
        "df.columns.name = None\n",
        "\n",
        "Ensure EMA Features Exist\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    print(\" 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\")\n",
        "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df.dropna(subset=['EMA_10', 'EMA_50'], inplace=True)\n",
        "    print(\"EMAs computed successfully.\")\n",
        "\n",
        "Verify Columns Before PPO Training\n",
        "print(\"  Final Columns Before PPO Training:\", df.columns)\n",
        "\n",
        "Split Data Into Training & Testing\n",
        "train_size = int(0.8 * len(df))\n",
        "df_train = df.iloc[:train_size]\n",
        "df_test = df.iloc[train_size:]\n",
        "\n",
        "Create Training Environment\n",
        "env_train = gym.make('stocks-v0', df=df_train, frame_bound=(10, len(df_train)), window_size=10)\n",
        "env_train = DummyVecEnv([lambda: env_train])\n",
        "\n",
        "Train PPO Model\n",
        "ppo_model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env_train,\n",
        "    verbose=1,\n",
        "    learning_rate=0.0001,\n",
        "    batch_size=512,\n",
        "    gamma=0.995,\n",
        "    n_steps=32768,\n",
        "    ent_coef=0.005,\n",
        "    vf_coef=0.8,\n",
        "    clip_range=0.2,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "ppo_model.learn(total_timesteps=500000)\n",
        "ppo_model.save(\"ppo_trading_model_v4\")\n",
        "gc.collect()\n",
        "\n",
        "Create Test Environment\n",
        "env_test = gym.make('stocks-v0', df=df_test, frame_bound=(10, len(df_test)), window_size=10)\n",
        "env_test = DummyVecEnv([lambda: env_test])\n",
        "obs = env_test.reset()\n",
        "\n",
        "PPO Backtesting with EMA Filtering\n",
        "trade_log_rl = []\n",
        "ppo_portfolio_values = []\n",
        "balance_ppo = 100000\n",
        "position = 0\n",
        "buy_price = None\n",
        "\n",
        "for i in range(len(df_test)):\n",
        "    action, _ = ppo_model.predict(obs)\n",
        "    price = df_test['Close'].iloc[i]\n",
        "\n",
        "    Convert PPO output to discrete BUY/SELL actions\n",
        "    if action < -0.3 and buy_price is not None:\n",
        "        trade_log_rl.append(\"SELL\")\n",
        "        balance_ppo = position * price\n",
        "        position = 0\n",
        "        buy_price = None\n",
        "    elif action > 0.3 and buy_price is None:\n",
        "        trade_log_rl.append(\"BUY\")\n",
        "        position = balance_ppo / price\n",
        "        balance_ppo = 0\n",
        "        buy_price = price\n",
        "    else:\n",
        "        trade_log_rl.append(\"HOLD\")\n",
        "\n",
        "    ppo_portfolio_values.append(balance_ppo if balance_ppo > 0 else position * price)\n",
        "\n",
        "Convert Portfolio Values to DataFrame\n",
        "results_df_ppo = pd.DataFrame({'Date': df_test.index, 'Portfolio Value': ppo_portfolio_values})\n",
        "\n",
        "Compute Daily Returns\n",
        "results_df_ppo['Daily Return'] = results_df_ppo['Portfolio Value'].pct_change().fillna(0)\n",
        "\n",
        "Compute Performance Metrics\n",
        "ppo_cumulative_return = ((results_df_ppo['Portfolio Value'].iloc[-1] / 100000) - 1) * 100\n",
        "daily_return_mean_ppo = results_df_ppo['Daily Return'].mean()\n",
        "daily_return_std_ppo = results_df_ppo['Daily Return'].std()\n",
        "ppo_sharpe_ratio = (daily_return_mean_ppo / daily_return_std_ppo) * np.sqrt(252) if daily_return_std_ppo != 0 else 0\n",
        "drawdown_ppo = (results_df_ppo['Portfolio Value'].cummax() - results_df_ppo['Portfolio Value']) / results_df_ppo['Portfolio Value'].cummax()\n",
        "ppo_max_drawdown = drawdown_ppo.max() * 100\n",
        "\n",
        "Buy & Hold Strategy for Comparison\n",
        "initial_balance = 100000\n",
        "shares_held = initial_balance // df_test['Close'].iloc[0]  Ensure whole number shares\n",
        "buy_hold_final_value = shares_held * df_test['Close'].iloc[-1]\n",
        "buy_hold_cumulative_return = ((buy_hold_final_value / initial_balance) - 1) * 100\n",
        "\n",
        "Print Final Performance\n",
        "print(\"\\nFINAL RESULTS COMPARISON:\")\n",
        "print(\"\\n**Reinforcement Learning (PPO)**\")\n",
        "print(f\"PPO Final Portfolio Value: ${results_df_ppo['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"PPO Cumulative Return: {ppo_cumulative_return:.2f}%\")\n",
        "print(f\"PPO Sharpe Ratio: {ppo_sharpe_ratio:.2f}\")\n",
        "print(f\"PPO Max Drawdown: {ppo_max_drawdown:.2f}%\")\n",
        "\n",
        "print(\"\\n**Buy & Hold Baseline**\")\n",
        "print(f\"Buy & Hold Final Portfolio Value: ${buy_hold_final_value:,.2f}\")\n",
        "print(f\"Buy & Hold Cumulative Return: {buy_hold_cumulative_return:.2f}%\")\n",
        "\n",
        "Declare Winner Based on Final Portfolio Value\n",
        "best_strategy = \"PPO\" if results_df_ppo['Portfolio Value'].iloc[-1] > buy_hold_final_value else \"Buy & Hold\"\n",
        "print(f\"\\n**Best Strategy Based on Final Portfolio Value: {best_strategy}!**\")\n",
        "\n",
        "Free Memory\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WXJWv8tL1Tq",
        "outputId": "10d9d39f-d7aa-47d1-d689-f0845657befe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            " 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\n",
            "EMAs computed successfully.\n",
            "  Final Columns Before PPO Training: Index(['Datetime', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_10',\n",
            "       'EMA_50'],\n",
            "      dtype='object')\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 654   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 50    |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 650         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019262888 |\n",
            "|    clip_fraction        | 0.0266      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.678      |\n",
            "|    explained_variance   | 0.000472    |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 42.2        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00191    |\n",
            "|    value_loss           | 46.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 650          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 151          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014518483 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.682       |\n",
            "|    explained_variance   | 0.00636      |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 23.6         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | 0.000133     |\n",
            "|    value_loss           | 34.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 649          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 201          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015003653 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.688       |\n",
            "|    explained_variance   | 0.00939      |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 26           |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.000112    |\n",
            "|    value_loss           | 38.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 650          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 251          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0120316185 |\n",
            "|    clip_fraction        | 0.00715      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.673       |\n",
            "|    explained_variance   | 0.0108       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 32.4         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00128     |\n",
            "|    value_loss           | 40.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 650         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 302         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009364889 |\n",
            "|    clip_fraction        | 0.0106      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.68       |\n",
            "|    explained_variance   | 0.0108      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 28.3        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00056    |\n",
            "|    value_loss           | 33.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 651          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 352          |\n",
            "|    total_timesteps      | 229376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061035194 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.688       |\n",
            "|    explained_variance   | 0.0168       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 30.4         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000292    |\n",
            "|    value_loss           | 38           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 651          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 402          |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020255775 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.691       |\n",
            "|    explained_variance   | 0.0203       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 34.8         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.000363    |\n",
            "|    value_loss           | 42.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 652         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 452         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005674814 |\n",
            "|    clip_fraction        | 0.000665    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.691      |\n",
            "|    explained_variance   | 0.0225      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 28.8        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.000379   |\n",
            "|    value_loss           | 42.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 652          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 502          |\n",
            "|    total_timesteps      | 327680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016108854 |\n",
            "|    clip_fraction        | 0.000781     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.692       |\n",
            "|    explained_variance   | 0.0341       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 40.1         |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.000338    |\n",
            "|    value_loss           | 47.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 652          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 552          |\n",
            "|    total_timesteps      | 360448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072092935 |\n",
            "|    clip_fraction        | 0.00448      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.689       |\n",
            "|    explained_variance   | 0.0293       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 37.7         |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.000555    |\n",
            "|    value_loss           | 47           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 652         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 602         |\n",
            "|    total_timesteps      | 393216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004803157 |\n",
            "|    clip_fraction        | 0.00187     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.685      |\n",
            "|    explained_variance   | 0.0256      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 33.6        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.000254   |\n",
            "|    value_loss           | 42.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 653          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 652          |\n",
            "|    total_timesteps      | 425984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048484737 |\n",
            "|    clip_fraction        | 0.0198       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.67        |\n",
            "|    explained_variance   | 0.0258       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 31.2         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00118     |\n",
            "|    value_loss           | 37.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 653          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 702          |\n",
            "|    total_timesteps      | 458752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013304839 |\n",
            "|    clip_fraction        | 0.00106      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.67        |\n",
            "|    explained_variance   | 0.0299       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 27.5         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | 1.28e-05     |\n",
            "|    value_loss           | 36.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 653         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 752         |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008774171 |\n",
            "|    clip_fraction        | 0.0143      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.654      |\n",
            "|    explained_variance   | 0.0218      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 25.3        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0012     |\n",
            "|    value_loss           | 33.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 653          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 802          |\n",
            "|    total_timesteps      | 524288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031912175 |\n",
            "|    clip_fraction        | 0.00514      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.63        |\n",
            "|    explained_variance   | 0.0212       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 23.7         |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000166    |\n",
            "|    value_loss           | 31.3         |\n",
            "------------------------------------------\n",
            "\n",
            "FINAL RESULTS COMPARISON:\n",
            "\n",
            "**Reinforcement Learning (PPO)**\n",
            "PPO Final Portfolio Value: $124,986.77\n",
            "PPO Cumulative Return: 24.99%\n",
            "PPO Sharpe Ratio: 0.35\n",
            "PPO Max Drawdown: 41.29%\n",
            "\n",
            "**Buy & Hold Baseline**\n",
            "Buy & Hold Final Portfolio Value: $121,892.10\n",
            "Buy & Hold Cumulative Return: 21.89%\n",
            "\n",
            "**Best Strategy Based on Final Portfolio Value: PPO!**\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "packages = [\n",
        "    \"stable-baselines3[extra]\",\n",
        "    \"gymnasium\",\n",
        "    \"gym-anytrading\",\n",
        "    \"numpy\",\n",
        "    \"pandas\",\n",
        "    \"matplotlib\"\n",
        "]\n",
        "\n",
        "for pkg in packages:\n",
        "    subprocess.run([\"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", pkg])\n"
      ],
      "metadata": {
        "id": "q8GVyHUAKNVp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import gymnasium as gym\n",
        "import gym_anytrading\n",
        "import torch\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "Load & Preprocess Data\n",
        "df = df_live.copy()\n",
        "\n",
        "Fix MultiIndex Issues (if applicable)\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "Remove Named Index (Fixes KeyError Issues)\n",
        "df.columns.name = None\n",
        "\n",
        "Ensure Essential Columns Exist\n",
        "required_cols = {'Close', 'High', 'Low', 'Open', 'Volume'}\n",
        "missing_cols = required_cols - set(df.columns)\n",
        "if missing_cols:\n",
        "    raise ValueError(f\" Missing required columns: {missing_cols}\")\n",
        "\n",
        "Compute EMAs if missing\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    print(\" 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\")\n",
        "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df.dropna(subset=['EMA_10', 'EMA_50'], inplace=True)\n",
        "    print(\"EMAs computed successfully.\")\n",
        "\n",
        "Confirm EMA columns before Training\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    raise KeyError(\" EMA columns are still missing after recomputation!\")\n",
        "\n",
        "Final Data Check\n",
        "print(\"  Final Columns Before Training:\", df.columns)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "Enable GPU Acceleration (if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "Create Trading Environment\n",
        "env = gym.make('stocks-v0', df=df, frame_bound=(10, len(df) - 1), window_size=10)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "Define SARSA Agent with Portfolio Tracking\n",
        "class SARSAAgent:\n",
        "    def __init__(self, state_size, action_size, alpha=0.1, gamma=0.95, epsilon=1.0, epsilon_decay=0.995, min_epsilon=0.01):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.q_table = np.zeros((state_size, action_size))\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.portfolio_values = []  Track Portfolio Values\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.array([np.random.choice(self.action_size)])  Return as array (Fix)\n",
        "        return np.array([np.argmax(self.q_table[state])])  Return as array (Fix)\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state, next_action):\n",
        "        predict = self.q_table[state, action[0]]  Extract int from action array\n",
        "        target = reward + self.gamma * self.q_table[next_state, next_action[0]]\n",
        "        self.q_table[state, action[0]] += self.alpha * (target - predict)\n",
        "\n",
        "    def train(self, env, episodes=500, initial_balance=10000):\n",
        "        for episode in range(episodes):\n",
        "            reset_result = env.reset()\n",
        "            state = reset_result[0] if isinstance(reset_result, tuple) else reset_result  Fix reset return issue\n",
        "            state = self.discretize_state(state)\n",
        "            action = self.choose_action(state)\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "            balance = initial_balance  Initialize Portfolio Balance\n",
        "\n",
        "            while not done:\n",
        "                step_result = env.step(action)\n",
        "                if isinstance(step_result, tuple) and len(step_result) == 4:  Fix Unpacking Issue\n",
        "                    next_state, reward, done, _ = step_result\n",
        "                else:\n",
        "                    next_state, reward, done = step_result\n",
        "\n",
        "                next_state = self.discretize_state(next_state)\n",
        "                next_action = self.choose_action(next_state)\n",
        "                self.update_q_table(state, action, reward, next_state, next_action)\n",
        "\n",
        "                Update Portfolio Value (Simulating Balance)\n",
        "                balance += reward\n",
        "                self.portfolio_values.append(balance)  Store Portfolio Value\n",
        "\n",
        "                state, action = next_state, next_action\n",
        "                total_reward += reward\n",
        "\n",
        "            self.epsilon = max(self.epsilon * self.epsilon_decay, self.min_epsilon)\n",
        "            print(f\"Episode {episode + 1}, Total Reward: {total_reward}, Final Balance: {balance}\")\n",
        "\n",
        "    def discretize_state(self, state):\n",
        "        \"\"\"Convert continuous states into discrete bins for Q-learning.\"\"\"\n",
        "        return int(state.mean() * self.state_size) % self.state_size\n",
        "\n",
        "Initialize and Train SARSA\n",
        "state_size = 100\n",
        "action_size = env.action_space.n\n",
        "sarsa_agent = SARSAAgent(state_size, action_size)\n",
        "sarsa_agent.train(env, episodes=500)  Now it will store portfolio values!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uIIkC9TNZEj",
        "outputId": "ec4cf182-e2ff-4b83-bed9-c6ee4f061aa4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\n",
            "EMAs computed successfully.\n",
            "  Final Columns Before Training: Index(['Datetime', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_10',\n",
            "       'EMA_50'],\n",
            "      dtype='object')\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-aa44d7d3f5df>:70: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.q_table[state, action[0]] += self.alpha * (target - predict)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1, Total Reward: [40.291916], Final Balance: [10040.279]\n",
            "Episode 2, Total Reward: [216.2799], Final Balance: [10216.283]\n",
            "Episode 3, Total Reward: [-183.64351], Final Balance: [9816.346]\n",
            "Episode 4, Total Reward: [3.2637177], Final Balance: [10003.277]\n",
            "Episode 5, Total Reward: [73.92941], Final Balance: [10073.947]\n",
            "Episode 6, Total Reward: [-64.172516], Final Balance: [9935.816]\n",
            "Episode 7, Total Reward: [3.5623627], Final Balance: [10003.56]\n",
            "Episode 8, Total Reward: [64.95842], Final Balance: [10064.968]\n",
            "Episode 9, Total Reward: [-48.361572], Final Balance: [9951.642]\n",
            "Episode 10, Total Reward: [150.83846], Final Balance: [10150.839]\n",
            "Episode 11, Total Reward: [70.806854], Final Balance: [10070.793]\n",
            "Episode 12, Total Reward: [-33.9823], Final Balance: [9966.021]\n",
            "Episode 13, Total Reward: [-235.16293], Final Balance: [9764.815]\n",
            "Episode 14, Total Reward: [-143.86656], Final Balance: [9856.119]\n",
            "Episode 15, Total Reward: [59.815353], Final Balance: [10059.811]\n",
            "Episode 16, Total Reward: [-247.7611], Final Balance: [9752.224]\n",
            "Episode 17, Total Reward: [61.175568], Final Balance: [10061.177]\n",
            "Episode 18, Total Reward: [-76.63898], Final Balance: [9923.354]\n",
            "Episode 19, Total Reward: [5.549736], Final Balance: [10005.557]\n",
            "Episode 20, Total Reward: [-30.471756], Final Balance: [9969.537]\n",
            "Episode 21, Total Reward: [-183.59181], Final Balance: [9816.391]\n",
            "Episode 22, Total Reward: [0.34968567], Final Balance: [10000.337]\n",
            "Episode 23, Total Reward: [-147.0448], Final Balance: [9852.942]\n",
            "Episode 24, Total Reward: [-58.706512], Final Balance: [9941.293]\n",
            "Episode 25, Total Reward: [-29.907578], Final Balance: [9970.093]\n",
            "Episode 26, Total Reward: [114.46567], Final Balance: [10114.471]\n",
            "Episode 27, Total Reward: [-264.61188], Final Balance: [9735.387]\n",
            "Episode 28, Total Reward: [-42.904694], Final Balance: [9957.09]\n",
            "Episode 29, Total Reward: [24.45111], Final Balance: [10024.46]\n",
            "Episode 30, Total Reward: [-202.67188], Final Balance: [9797.319]\n",
            "Episode 31, Total Reward: [-35.31067], Final Balance: [9964.6875]\n",
            "Episode 32, Total Reward: [-161.5243], Final Balance: [9838.485]\n",
            "Episode 33, Total Reward: [157.37283], Final Balance: [10157.363]\n",
            "Episode 34, Total Reward: [-103.466415], Final Balance: [9896.537]\n",
            "Episode 35, Total Reward: [161.86362], Final Balance: [10161.877]\n",
            "Episode 36, Total Reward: [256.98785], Final Balance: [10256.98]\n",
            "Episode 37, Total Reward: [9.629753], Final Balance: [10009.643]\n",
            "Episode 38, Total Reward: [-18.64708], Final Balance: [9981.343]\n",
            "Episode 39, Total Reward: [27.220566], Final Balance: [10027.218]\n",
            "Episode 40, Total Reward: [119.36664], Final Balance: [10119.351]\n",
            "Episode 41, Total Reward: [-50.64637], Final Balance: [9949.3545]\n",
            "Episode 42, Total Reward: [123.49457], Final Balance: [10123.49]\n",
            "Episode 43, Total Reward: [-130.59914], Final Balance: [9869.373]\n",
            "Episode 44, Total Reward: [-78.1735], Final Balance: [9921.821]\n",
            "Episode 45, Total Reward: [-200.0402], Final Balance: [9799.94]\n",
            "Episode 46, Total Reward: [18.102173], Final Balance: [10018.11]\n",
            "Episode 47, Total Reward: [24.225616], Final Balance: [10024.218]\n",
            "Episode 48, Total Reward: [-95.63727], Final Balance: [9904.361]\n",
            "Episode 49, Total Reward: [63.072113], Final Balance: [10063.071]\n",
            "Episode 50, Total Reward: [-91.074875], Final Balance: [9908.927]\n",
            "Episode 51, Total Reward: [-48.449356], Final Balance: [9951.543]\n",
            "Episode 52, Total Reward: [-38.277588], Final Balance: [9961.716]\n",
            "Episode 53, Total Reward: [19.852661], Final Balance: [10019.855]\n",
            "Episode 54, Total Reward: [83.601166], Final Balance: [10083.594]\n",
            "Episode 55, Total Reward: [-234.94637], Final Balance: [9765.044]\n",
            "Episode 56, Total Reward: [-103.4993], Final Balance: [9896.483]\n",
            "Episode 57, Total Reward: [-5.2545776], Final Balance: [9994.738]\n",
            "Episode 58, Total Reward: [-39.319748], Final Balance: [9960.673]\n",
            "Episode 59, Total Reward: [-45.886612], Final Balance: [9954.127]\n",
            "Episode 60, Total Reward: [-96.66264], Final Balance: [9903.335]\n",
            "Episode 61, Total Reward: [54.627625], Final Balance: [10054.615]\n",
            "Episode 62, Total Reward: [-282.93903], Final Balance: [9717.028]\n",
            "Episode 63, Total Reward: [67.11072], Final Balance: [10067.104]\n",
            "Episode 64, Total Reward: [103.34088], Final Balance: [10103.339]\n",
            "Episode 65, Total Reward: [-121.85199], Final Balance: [9878.147]\n",
            "Episode 66, Total Reward: [-24.929604], Final Balance: [9975.053]\n",
            "Episode 67, Total Reward: [70.72781], Final Balance: [10070.7295]\n",
            "Episode 68, Total Reward: [-31.544281], Final Balance: [9968.458]\n",
            "Episode 69, Total Reward: [-89.77567], Final Balance: [9910.213]\n",
            "Episode 70, Total Reward: [-19.60112], Final Balance: [9980.395]\n",
            "Episode 71, Total Reward: [-18.937668], Final Balance: [9981.046]\n",
            "Episode 72, Total Reward: [-40.726585], Final Balance: [9959.264]\n",
            "Episode 73, Total Reward: [-28.355057], Final Balance: [9971.649]\n",
            "Episode 74, Total Reward: [161.59412], Final Balance: [10161.59]\n",
            "Episode 75, Total Reward: [-149.30086], Final Balance: [9850.706]\n",
            "Episode 76, Total Reward: [113.55429], Final Balance: [10113.547]\n",
            "Episode 77, Total Reward: [28.55928], Final Balance: [10028.536]\n",
            "Episode 78, Total Reward: [-350.67947], Final Balance: [9649.32]\n",
            "Episode 79, Total Reward: [-157.5686], Final Balance: [9842.437]\n",
            "Episode 80, Total Reward: [-309.48056], Final Balance: [9690.505]\n",
            "Episode 81, Total Reward: [-22.94429], Final Balance: [9977.056]\n",
            "Episode 82, Total Reward: [-148.38625], Final Balance: [9851.63]\n",
            "Episode 83, Total Reward: [-63.28646], Final Balance: [9936.717]\n",
            "Episode 84, Total Reward: [11.775391], Final Balance: [10011.758]\n",
            "Episode 85, Total Reward: [-318.8689], Final Balance: [9681.133]\n",
            "Episode 86, Total Reward: [56.35325], Final Balance: [10056.338]\n",
            "Episode 87, Total Reward: [-71.01889], Final Balance: [9928.956]\n",
            "Episode 88, Total Reward: [-41.067963], Final Balance: [9958.928]\n",
            "Episode 89, Total Reward: [-18.501404], Final Balance: [9981.504]\n",
            "Episode 90, Total Reward: [-364.98624], Final Balance: [9635.011]\n",
            "Episode 91, Total Reward: [-40.902054], Final Balance: [9959.097]\n",
            "Episode 92, Total Reward: [-191.58737], Final Balance: [9808.408]\n",
            "Episode 93, Total Reward: [155.2203], Final Balance: [10155.216]\n",
            "Episode 94, Total Reward: [-102.275696], Final Balance: [9897.708]\n",
            "Episode 95, Total Reward: [-211.67389], Final Balance: [9788.319]\n",
            "Episode 96, Total Reward: [-21.797012], Final Balance: [9978.189]\n",
            "Episode 97, Total Reward: [123.45175], Final Balance: [10123.453]\n",
            "Episode 98, Total Reward: [165.40506], Final Balance: [10165.3955]\n",
            "Episode 99, Total Reward: [206.23746], Final Balance: [10206.239]\n",
            "Episode 100, Total Reward: [-15.177841], Final Balance: [9984.837]\n",
            "Episode 101, Total Reward: [101.15195], Final Balance: [10101.166]\n",
            "Episode 102, Total Reward: [22.354279], Final Balance: [10022.352]\n",
            "Episode 103, Total Reward: [-295.58456], Final Balance: [9704.411]\n",
            "Episode 104, Total Reward: [-102.013016], Final Balance: [9897.9795]\n",
            "Episode 105, Total Reward: [258.05316], Final Balance: [10258.044]\n",
            "Episode 106, Total Reward: [135.51044], Final Balance: [10135.506]\n",
            "Episode 107, Total Reward: [-11.882065], Final Balance: [9988.121]\n",
            "Episode 108, Total Reward: [38.95067], Final Balance: [10038.934]\n",
            "Episode 109, Total Reward: [144.66595], Final Balance: [10144.664]\n",
            "Episode 110, Total Reward: [74.08029], Final Balance: [10074.048]\n",
            "Episode 111, Total Reward: [28.77182], Final Balance: [10028.755]\n",
            "Episode 112, Total Reward: [-126.936935], Final Balance: [9873.056]\n",
            "Episode 113, Total Reward: [40.495132], Final Balance: [10040.485]\n",
            "Episode 114, Total Reward: [-72.756134], Final Balance: [9927.244]\n",
            "Episode 115, Total Reward: [-103.81206], Final Balance: [9896.189]\n",
            "Episode 116, Total Reward: [126.12044], Final Balance: [10126.116]\n",
            "Episode 117, Total Reward: [-260.733], Final Balance: [9739.258]\n",
            "Episode 118, Total Reward: [-100.50577], Final Balance: [9899.485]\n",
            "Episode 119, Total Reward: [-189.81744], Final Balance: [9810.193]\n",
            "Episode 120, Total Reward: [-159.83054], Final Balance: [9840.159]\n",
            "Episode 121, Total Reward: [-10.665237], Final Balance: [9989.344]\n",
            "Episode 122, Total Reward: [83.03107], Final Balance: [10083.006]\n",
            "Episode 123, Total Reward: [-3.8897095], Final Balance: [9996.104]\n",
            "Episode 124, Total Reward: [-199.56667], Final Balance: [9800.435]\n",
            "Episode 125, Total Reward: [-51.65149], Final Balance: [9948.352]\n",
            "Episode 126, Total Reward: [187.93881], Final Balance: [10187.906]\n",
            "Episode 127, Total Reward: [-165.16783], Final Balance: [9834.821]\n",
            "Episode 128, Total Reward: [-193.4633], Final Balance: [9806.525]\n",
            "Episode 129, Total Reward: [96.78999], Final Balance: [10096.796]\n",
            "Episode 130, Total Reward: [50.47425], Final Balance: [10050.459]\n",
            "Episode 131, Total Reward: [-224.72531], Final Balance: [9775.277]\n",
            "Episode 132, Total Reward: [151.46317], Final Balance: [10151.481]\n",
            "Episode 133, Total Reward: [135.25879], Final Balance: [10135.236]\n",
            "Episode 134, Total Reward: [-244.04254], Final Balance: [9755.951]\n",
            "Episode 135, Total Reward: [-53.647263], Final Balance: [9946.35]\n",
            "Episode 136, Total Reward: [-20.60614], Final Balance: [9979.365]\n",
            "Episode 137, Total Reward: [-121.34285], Final Balance: [9878.647]\n",
            "Episode 138, Total Reward: [43.21974], Final Balance: [10043.217]\n",
            "Episode 139, Total Reward: [19.117447], Final Balance: [10019.122]\n",
            "Episode 140, Total Reward: [90.46283], Final Balance: [10090.462]\n",
            "Episode 141, Total Reward: [145.77658], Final Balance: [10145.78]\n",
            "Episode 142, Total Reward: [-88.784225], Final Balance: [9911.196]\n",
            "Episode 143, Total Reward: [119.749146], Final Balance: [10119.751]\n",
            "Episode 144, Total Reward: [13.088516], Final Balance: [10013.086]\n",
            "Episode 145, Total Reward: [28.316254], Final Balance: [10028.311]\n",
            "Episode 146, Total Reward: [51.05974], Final Balance: [10051.069]\n",
            "Episode 147, Total Reward: [-143.99265], Final Balance: [9856.007]\n",
            "Episode 148, Total Reward: [-60.41147], Final Balance: [9939.576]\n",
            "Episode 149, Total Reward: [-22.987762], Final Balance: [9977.014]\n",
            "Episode 150, Total Reward: [189.55106], Final Balance: [10189.546]\n",
            "Episode 151, Total Reward: [-69.49314], Final Balance: [9930.508]\n",
            "Episode 152, Total Reward: [-86.71585], Final Balance: [9913.276]\n",
            "Episode 153, Total Reward: [6.9671173], Final Balance: [10006.974]\n",
            "Episode 154, Total Reward: [28.053253], Final Balance: [10028.06]\n",
            "Episode 155, Total Reward: [-34.441467], Final Balance: [9965.563]\n",
            "Episode 156, Total Reward: [53.954132], Final Balance: [10053.942]\n",
            "Episode 157, Total Reward: [-125.83496], Final Balance: [9874.162]\n",
            "Episode 158, Total Reward: [128.72269], Final Balance: [10128.725]\n",
            "Episode 159, Total Reward: [10.721817], Final Balance: [10010.735]\n",
            "Episode 160, Total Reward: [-104.468796], Final Balance: [9895.522]\n",
            "Episode 161, Total Reward: [-253.52185], Final Balance: [9746.462]\n",
            "Episode 162, Total Reward: [-114.137344], Final Balance: [9885.855]\n",
            "Episode 163, Total Reward: [-153.84839], Final Balance: [9846.169]\n",
            "Episode 164, Total Reward: [-65.69289], Final Balance: [9934.299]\n",
            "Episode 165, Total Reward: [40.938812], Final Balance: [10040.942]\n",
            "Episode 166, Total Reward: [-180.24786], Final Balance: [9819.742]\n",
            "Episode 167, Total Reward: [-69.921326], Final Balance: [9930.064]\n",
            "Episode 168, Total Reward: [-191.75928], Final Balance: [9808.221]\n",
            "Episode 169, Total Reward: [-57.351593], Final Balance: [9942.6455]\n",
            "Episode 170, Total Reward: [-6.550461], Final Balance: [9993.451]\n",
            "Episode 171, Total Reward: [149.83028], Final Balance: [10149.817]\n",
            "Episode 172, Total Reward: [-96.63484], Final Balance: [9903.348]\n",
            "Episode 173, Total Reward: [-216.80023], Final Balance: [9783.205]\n",
            "Episode 174, Total Reward: [118.004456], Final Balance: [10117.988]\n",
            "Episode 175, Total Reward: [-20.952835], Final Balance: [9979.044]\n",
            "Episode 176, Total Reward: [-49.413895], Final Balance: [9950.58]\n",
            "Episode 177, Total Reward: [127.667694], Final Balance: [10127.655]\n",
            "Episode 178, Total Reward: [-41.190033], Final Balance: [9958.785]\n",
            "Episode 179, Total Reward: [-54.585526], Final Balance: [9945.423]\n",
            "Episode 180, Total Reward: [-228.4862], Final Balance: [9771.51]\n",
            "Episode 181, Total Reward: [-8.552658], Final Balance: [9991.434]\n",
            "Episode 182, Total Reward: [40.794495], Final Balance: [10040.812]\n",
            "Episode 183, Total Reward: [62.80844], Final Balance: [10062.814]\n",
            "Episode 184, Total Reward: [-60.367126], Final Balance: [9939.653]\n",
            "Episode 185, Total Reward: [-114.27927], Final Balance: [9885.718]\n",
            "Episode 186, Total Reward: [-241.05217], Final Balance: [9758.947]\n",
            "Episode 187, Total Reward: [-298.1252], Final Balance: [9701.869]\n",
            "Episode 188, Total Reward: [-129.57451], Final Balance: [9870.421]\n",
            "Episode 189, Total Reward: [114.18237], Final Balance: [10114.169]\n",
            "Episode 190, Total Reward: [146.30203], Final Balance: [10146.29]\n",
            "Episode 191, Total Reward: [97.4178], Final Balance: [10097.404]\n",
            "Episode 192, Total Reward: [-243.34837], Final Balance: [9756.635]\n",
            "Episode 193, Total Reward: [13.15332], Final Balance: [10013.15]\n",
            "Episode 194, Total Reward: [-39.89154], Final Balance: [9960.088]\n",
            "Episode 195, Total Reward: [128.06854], Final Balance: [10128.061]\n",
            "Episode 196, Total Reward: [21.182007], Final Balance: [10021.183]\n",
            "Episode 197, Total Reward: [37.4142], Final Balance: [10037.419]\n",
            "Episode 198, Total Reward: [30.46318], Final Balance: [10030.454]\n",
            "Episode 199, Total Reward: [-110.94203], Final Balance: [9889.042]\n",
            "Episode 200, Total Reward: [-113.51697], Final Balance: [9886.461]\n",
            "Episode 201, Total Reward: [6.8667755], Final Balance: [10006.836]\n",
            "Episode 202, Total Reward: [-105.04561], Final Balance: [9894.956]\n",
            "Episode 203, Total Reward: [-139.35838], Final Balance: [9860.64]\n",
            "Episode 204, Total Reward: [162.95444], Final Balance: [10162.952]\n",
            "Episode 205, Total Reward: [-40.783417], Final Balance: [9959.193]\n",
            "Episode 206, Total Reward: [-3.2748566], Final Balance: [9996.715]\n",
            "Episode 207, Total Reward: [26.128815], Final Balance: [10026.133]\n",
            "Episode 208, Total Reward: [-20.249115], Final Balance: [9979.742]\n",
            "Episode 209, Total Reward: [-2.0416107], Final Balance: [9997.971]\n",
            "Episode 210, Total Reward: [100.543655], Final Balance: [10100.52]\n",
            "Episode 211, Total Reward: [-15.035645], Final Balance: [9984.974]\n",
            "Episode 212, Total Reward: [53.162506], Final Balance: [10053.168]\n",
            "Episode 213, Total Reward: [18.393402], Final Balance: [10018.385]\n",
            "Episode 214, Total Reward: [61.936493], Final Balance: [10061.941]\n",
            "Episode 215, Total Reward: [-41.94803], Final Balance: [9958.049]\n",
            "Episode 216, Total Reward: [-94.973724], Final Balance: [9905.027]\n",
            "Episode 217, Total Reward: [-35.93866], Final Balance: [9964.061]\n",
            "Episode 218, Total Reward: [-15.376587], Final Balance: [9984.615]\n",
            "Episode 219, Total Reward: [2.3507385], Final Balance: [10002.355]\n",
            "Episode 220, Total Reward: [-213.39346], Final Balance: [9786.604]\n",
            "Episode 221, Total Reward: [-37.56456], Final Balance: [9962.435]\n",
            "Episode 222, Total Reward: [-232.14813], Final Balance: [9767.856]\n",
            "Episode 223, Total Reward: [-21.532532], Final Balance: [9978.465]\n",
            "Episode 224, Total Reward: [30.566528], Final Balance: [10030.565]\n",
            "Episode 225, Total Reward: [-92.16829], Final Balance: [9907.827]\n",
            "Episode 226, Total Reward: [-83.32565], Final Balance: [9916.669]\n",
            "Episode 227, Total Reward: [-69.258194], Final Balance: [9930.742]\n",
            "Episode 228, Total Reward: [124.86386], Final Balance: [10124.86]\n",
            "Episode 229, Total Reward: [55.602478], Final Balance: [10055.596]\n",
            "Episode 230, Total Reward: [99.0264], Final Balance: [10099.031]\n",
            "Episode 231, Total Reward: [117.46567], Final Balance: [10117.447]\n",
            "Episode 232, Total Reward: [-54.60073], Final Balance: [9945.388]\n",
            "Episode 233, Total Reward: [26.041412], Final Balance: [10026.04]\n",
            "Episode 234, Total Reward: [-144.86153], Final Balance: [9855.146]\n",
            "Episode 235, Total Reward: [72.16254], Final Balance: [10072.164]\n",
            "Episode 236, Total Reward: [5.3757324], Final Balance: [10005.374]\n",
            "Episode 237, Total Reward: [230.83517], Final Balance: [10230.836]\n",
            "Episode 238, Total Reward: [178.79117], Final Balance: [10178.781]\n",
            "Episode 239, Total Reward: [71.25981], Final Balance: [10071.261]\n",
            "Episode 240, Total Reward: [-166.08963], Final Balance: [9833.902]\n",
            "Episode 241, Total Reward: [11.020157], Final Balance: [10011.014]\n",
            "Episode 242, Total Reward: [-182.67262], Final Balance: [9817.334]\n",
            "Episode 243, Total Reward: [-146.88234], Final Balance: [9853.11]\n",
            "Episode 244, Total Reward: [-99.56793], Final Balance: [9900.437]\n",
            "Episode 245, Total Reward: [118.339874], Final Balance: [10118.334]\n",
            "Episode 246, Total Reward: [0.5792999], Final Balance: [10000.577]\n",
            "Episode 247, Total Reward: [-27.678543], Final Balance: [9972.32]\n",
            "Episode 248, Total Reward: [-29.150833], Final Balance: [9970.842]\n",
            "Episode 249, Total Reward: [95.25406], Final Balance: [10095.257]\n",
            "Episode 250, Total Reward: [-13.758255], Final Balance: [9986.256]\n",
            "Episode 251, Total Reward: [16.490417], Final Balance: [10016.488]\n",
            "Episode 252, Total Reward: [34.114014], Final Balance: [10034.108]\n",
            "Episode 253, Total Reward: [98.644226], Final Balance: [10098.649]\n",
            "Episode 254, Total Reward: [11.830963], Final Balance: [10011.823]\n",
            "Episode 255, Total Reward: [149.44376], Final Balance: [10149.435]\n",
            "Episode 256, Total Reward: [9.16716], Final Balance: [10009.169]\n",
            "Episode 257, Total Reward: [46.11789], Final Balance: [10046.116]\n",
            "Episode 258, Total Reward: [-4.229431], Final Balance: [9995.765]\n",
            "Episode 259, Total Reward: [68.91913], Final Balance: [10068.926]\n",
            "Episode 260, Total Reward: [-134.40903], Final Balance: [9865.593]\n",
            "Episode 261, Total Reward: [-115.84561], Final Balance: [9884.16]\n",
            "Episode 262, Total Reward: [-74.495316], Final Balance: [9925.494]\n",
            "Episode 263, Total Reward: [-54.674606], Final Balance: [9945.312]\n",
            "Episode 264, Total Reward: [137.95038], Final Balance: [10137.951]\n",
            "Episode 265, Total Reward: [-168.28966], Final Balance: [9831.726]\n",
            "Episode 266, Total Reward: [-57.616867], Final Balance: [9942.3955]\n",
            "Episode 267, Total Reward: [-89.976974], Final Balance: [9910.017]\n",
            "Episode 268, Total Reward: [-96.451996], Final Balance: [9903.545]\n",
            "Episode 269, Total Reward: [47.16194], Final Balance: [10047.171]\n",
            "Episode 270, Total Reward: [137.43436], Final Balance: [10137.449]\n",
            "Episode 271, Total Reward: [1.0531311], Final Balance: [10001.053]\n",
            "Episode 272, Total Reward: [98.87088], Final Balance: [10098.872]\n",
            "Episode 273, Total Reward: [-66.05182], Final Balance: [9933.95]\n",
            "Episode 274, Total Reward: [-4.761078], Final Balance: [9995.247]\n",
            "Episode 275, Total Reward: [-78.44655], Final Balance: [9921.56]\n",
            "Episode 276, Total Reward: [-120.22002], Final Balance: [9879.787]\n",
            "Episode 277, Total Reward: [64.41931], Final Balance: [10064.414]\n",
            "Episode 278, Total Reward: [-140.63153], Final Balance: [9859.374]\n",
            "Episode 279, Total Reward: [0.08166504], Final Balance: [10000.058]\n",
            "Episode 280, Total Reward: [-92.090225], Final Balance: [9907.904]\n",
            "Episode 281, Total Reward: [-119.83557], Final Balance: [9880.156]\n",
            "Episode 282, Total Reward: [152.03561], Final Balance: [10152.051]\n",
            "Episode 283, Total Reward: [-9.449249], Final Balance: [9990.531]\n",
            "Episode 284, Total Reward: [119.97728], Final Balance: [10119.96]\n",
            "Episode 285, Total Reward: [61.091446], Final Balance: [10061.089]\n",
            "Episode 286, Total Reward: [27.75969], Final Balance: [10027.749]\n",
            "Episode 287, Total Reward: [-9.606873], Final Balance: [9990.396]\n",
            "Episode 288, Total Reward: [3.725586], Final Balance: [10003.72]\n",
            "Episode 289, Total Reward: [192.52759], Final Balance: [10192.525]\n",
            "Episode 290, Total Reward: [65.66382], Final Balance: [10065.655]\n",
            "Episode 291, Total Reward: [75.68013], Final Balance: [10075.684]\n",
            "Episode 292, Total Reward: [35.010742], Final Balance: [10035.006]\n",
            "Episode 293, Total Reward: [-114.158676], Final Balance: [9885.846]\n",
            "Episode 294, Total Reward: [-13.941177], Final Balance: [9986.058]\n",
            "Episode 295, Total Reward: [40.20436], Final Balance: [10040.193]\n",
            "Episode 296, Total Reward: [-128.06157], Final Balance: [9871.936]\n",
            "Episode 297, Total Reward: [71.95355], Final Balance: [10071.948]\n",
            "Episode 298, Total Reward: [-60.849213], Final Balance: [9939.156]\n",
            "Episode 299, Total Reward: [4.5492554], Final Balance: [10004.527]\n",
            "Episode 300, Total Reward: [292.7455], Final Balance: [10292.748]\n",
            "Episode 301, Total Reward: [-118.189514], Final Balance: [9881.816]\n",
            "Episode 302, Total Reward: [163.05676], Final Balance: [10163.062]\n",
            "Episode 303, Total Reward: [100.733], Final Balance: [10100.726]\n",
            "Episode 304, Total Reward: [54.33835], Final Balance: [10054.341]\n",
            "Episode 305, Total Reward: [-85.78897], Final Balance: [9914.205]\n",
            "Episode 306, Total Reward: [-147.31589], Final Balance: [9852.68]\n",
            "Episode 307, Total Reward: [44.307037], Final Balance: [10044.301]\n",
            "Episode 308, Total Reward: [-74.39371], Final Balance: [9925.607]\n",
            "Episode 309, Total Reward: [-184.22368], Final Balance: [9815.784]\n",
            "Episode 310, Total Reward: [15.645493], Final Balance: [10015.647]\n",
            "Episode 311, Total Reward: [68.58066], Final Balance: [10068.592]\n",
            "Episode 312, Total Reward: [-6.334198], Final Balance: [9993.662]\n",
            "Episode 313, Total Reward: [-135.33833], Final Balance: [9864.663]\n",
            "Episode 314, Total Reward: [8.157196], Final Balance: [10008.161]\n",
            "Episode 315, Total Reward: [61.76883], Final Balance: [10061.768]\n",
            "Episode 316, Total Reward: [-27.549622], Final Balance: [9972.432]\n",
            "Episode 317, Total Reward: [94.63815], Final Balance: [10094.646]\n",
            "Episode 318, Total Reward: [-51.7816], Final Balance: [9948.213]\n",
            "Episode 319, Total Reward: [-13.671967], Final Balance: [9986.337]\n",
            "Episode 320, Total Reward: [-115.23784], Final Balance: [9884.756]\n",
            "Episode 321, Total Reward: [-117.66695], Final Balance: [9882.34]\n",
            "Episode 322, Total Reward: [150.95996], Final Balance: [10150.959]\n",
            "Episode 323, Total Reward: [129.54724], Final Balance: [10129.547]\n",
            "Episode 324, Total Reward: [-65.91266], Final Balance: [9934.083]\n",
            "Episode 325, Total Reward: [98.86716], Final Balance: [10098.871]\n",
            "Episode 326, Total Reward: [54.154068], Final Balance: [10054.151]\n",
            "Episode 327, Total Reward: [-64.750565], Final Balance: [9935.25]\n",
            "Episode 328, Total Reward: [87.19011], Final Balance: [10087.197]\n",
            "Episode 329, Total Reward: [-28.623291], Final Balance: [9971.374]\n",
            "Episode 330, Total Reward: [-80.561005], Final Balance: [9919.437]\n",
            "Episode 331, Total Reward: [-142.79681], Final Balance: [9857.21]\n",
            "Episode 332, Total Reward: [-22.946167], Final Balance: [9977.056]\n",
            "Episode 333, Total Reward: [13.877792], Final Balance: [10013.871]\n",
            "Episode 334, Total Reward: [-55.95778], Final Balance: [9944.042]\n",
            "Episode 335, Total Reward: [76.95181], Final Balance: [10076.961]\n",
            "Episode 336, Total Reward: [-135.31564], Final Balance: [9864.705]\n",
            "Episode 337, Total Reward: [-86.667], Final Balance: [9913.348]\n",
            "Episode 338, Total Reward: [-2.1398773], Final Balance: [9997.866]\n",
            "Episode 339, Total Reward: [-292.46658], Final Balance: [9707.529]\n",
            "Episode 340, Total Reward: [-156.24759], Final Balance: [9843.753]\n",
            "Episode 341, Total Reward: [207.57004], Final Balance: [10207.568]\n",
            "Episode 342, Total Reward: [178.22156], Final Balance: [10178.222]\n",
            "Episode 343, Total Reward: [21.965225], Final Balance: [10021.965]\n",
            "Episode 344, Total Reward: [-118.5672], Final Balance: [9881.424]\n",
            "Episode 345, Total Reward: [-164.8953], Final Balance: [9835.101]\n",
            "Episode 346, Total Reward: [-110.70093], Final Balance: [9889.304]\n",
            "Episode 347, Total Reward: [11.258804], Final Balance: [10011.244]\n",
            "Episode 348, Total Reward: [22.812927], Final Balance: [10022.8]\n",
            "Episode 349, Total Reward: [-64.91597], Final Balance: [9935.083]\n",
            "Episode 350, Total Reward: [-88.00313], Final Balance: [9912.004]\n",
            "Episode 351, Total Reward: [-32.54509], Final Balance: [9967.455]\n",
            "Episode 352, Total Reward: [-39.129776], Final Balance: [9960.87]\n",
            "Episode 353, Total Reward: [-56.43901], Final Balance: [9943.556]\n",
            "Episode 354, Total Reward: [1.321167], Final Balance: [10001.318]\n",
            "Episode 355, Total Reward: [-74.49422], Final Balance: [9925.499]\n",
            "Episode 356, Total Reward: [-86.38083], Final Balance: [9913.613]\n",
            "Episode 357, Total Reward: [84.92529], Final Balance: [10084.919]\n",
            "Episode 358, Total Reward: [138.13474], Final Balance: [10138.136]\n",
            "Episode 359, Total Reward: [33.48047], Final Balance: [10033.467]\n",
            "Episode 360, Total Reward: [144.6607], Final Balance: [10144.647]\n",
            "Episode 361, Total Reward: [-27.52887], Final Balance: [9972.463]\n",
            "Episode 362, Total Reward: [-43.031967], Final Balance: [9956.968]\n",
            "Episode 363, Total Reward: [-61.466904], Final Balance: [9938.53]\n",
            "Episode 364, Total Reward: [-121.19179], Final Balance: [9878.813]\n",
            "Episode 365, Total Reward: [0.12466431], Final Balance: [10000.118]\n",
            "Episode 366, Total Reward: [-144.49753], Final Balance: [9855.496]\n",
            "Episode 367, Total Reward: [4.114975], Final Balance: [10004.123]\n",
            "Episode 368, Total Reward: [-66.40433], Final Balance: [9933.593]\n",
            "Episode 369, Total Reward: [-41.81009], Final Balance: [9958.193]\n",
            "Episode 370, Total Reward: [-117.60715], Final Balance: [9882.396]\n",
            "Episode 371, Total Reward: [113.75397], Final Balance: [10113.767]\n",
            "Episode 372, Total Reward: [-88.11435], Final Balance: [9911.863]\n",
            "Episode 373, Total Reward: [2.7799225], Final Balance: [10002.782]\n",
            "Episode 374, Total Reward: [-25.860687], Final Balance: [9974.145]\n",
            "Episode 375, Total Reward: [40.641693], Final Balance: [10040.634]\n",
            "Episode 376, Total Reward: [-111.227615], Final Balance: [9888.771]\n",
            "Episode 377, Total Reward: [127.8714], Final Balance: [10127.871]\n",
            "Episode 378, Total Reward: [-95.23068], Final Balance: [9904.773]\n",
            "Episode 379, Total Reward: [-24.121292], Final Balance: [9975.886]\n",
            "Episode 380, Total Reward: [-12.368317], Final Balance: [9987.635]\n",
            "Episode 381, Total Reward: [42.00598], Final Balance: [10041.995]\n",
            "Episode 382, Total Reward: [80.45712], Final Balance: [10080.442]\n",
            "Episode 383, Total Reward: [55.26645], Final Balance: [10055.256]\n",
            "Episode 384, Total Reward: [68.965], Final Balance: [10068.961]\n",
            "Episode 385, Total Reward: [9.89711], Final Balance: [10009.894]\n",
            "Episode 386, Total Reward: [136.66656], Final Balance: [10136.675]\n",
            "Episode 387, Total Reward: [19.060654], Final Balance: [10019.05]\n",
            "Episode 388, Total Reward: [-13.40329], Final Balance: [9986.594]\n",
            "Episode 389, Total Reward: [-50.91646], Final Balance: [9949.085]\n",
            "Episode 390, Total Reward: [116.57385], Final Balance: [10116.565]\n",
            "Episode 391, Total Reward: [96.42789], Final Balance: [10096.429]\n",
            "Episode 392, Total Reward: [-72.75328], Final Balance: [9927.25]\n",
            "Episode 393, Total Reward: [146.37274], Final Balance: [10146.372]\n",
            "Episode 394, Total Reward: [-67.43977], Final Balance: [9932.545]\n",
            "Episode 395, Total Reward: [-79.307846], Final Balance: [9920.7]\n",
            "Episode 396, Total Reward: [-135.98633], Final Balance: [9864.016]\n",
            "Episode 397, Total Reward: [-19.703506], Final Balance: [9980.285]\n",
            "Episode 398, Total Reward: [-63.34221], Final Balance: [9936.656]\n",
            "Episode 399, Total Reward: [-125.6268], Final Balance: [9874.373]\n",
            "Episode 400, Total Reward: [-124.45581], Final Balance: [9875.542]\n",
            "Episode 401, Total Reward: [-194.2195], Final Balance: [9805.772]\n",
            "Episode 402, Total Reward: [-28.834503], Final Balance: [9971.172]\n",
            "Episode 403, Total Reward: [-12.874359], Final Balance: [9987.132]\n",
            "Episode 404, Total Reward: [-59.1653], Final Balance: [9940.841]\n",
            "Episode 405, Total Reward: [-7.0575714], Final Balance: [9992.948]\n",
            "Episode 406, Total Reward: [-81.7964], Final Balance: [9918.197]\n",
            "Episode 407, Total Reward: [-55.89122], Final Balance: [9944.113]\n",
            "Episode 408, Total Reward: [-18.4729], Final Balance: [9981.523]\n",
            "Episode 409, Total Reward: [86.74249], Final Balance: [10086.737]\n",
            "Episode 410, Total Reward: [67.592545], Final Balance: [10067.6]\n",
            "Episode 411, Total Reward: [-109.123], Final Balance: [9890.873]\n",
            "Episode 412, Total Reward: [-87.03157], Final Balance: [9912.968]\n",
            "Episode 413, Total Reward: [78.34624], Final Balance: [10078.354]\n",
            "Episode 414, Total Reward: [-82.556625], Final Balance: [9917.439]\n",
            "Episode 415, Total Reward: [41.99518], Final Balance: [10041.997]\n",
            "Episode 416, Total Reward: [50.21576], Final Balance: [10050.213]\n",
            "Episode 417, Total Reward: [18.637268], Final Balance: [10018.648]\n",
            "Episode 418, Total Reward: [-66.0851], Final Balance: [9933.908]\n",
            "Episode 419, Total Reward: [-36.38324], Final Balance: [9963.607]\n",
            "Episode 420, Total Reward: [-1.0439148], Final Balance: [9998.955]\n",
            "Episode 421, Total Reward: [-28.859436], Final Balance: [9971.136]\n",
            "Episode 422, Total Reward: [123.52237], Final Balance: [10123.519]\n",
            "Episode 423, Total Reward: [-151.1948], Final Balance: [9848.797]\n",
            "Episode 424, Total Reward: [-114.16513], Final Balance: [9885.838]\n",
            "Episode 425, Total Reward: [67.258316], Final Balance: [10067.263]\n",
            "Episode 426, Total Reward: [209.70462], Final Balance: [10209.696]\n",
            "Episode 427, Total Reward: [97.145935], Final Balance: [10097.141]\n",
            "Episode 428, Total Reward: [-75.35356], Final Balance: [9924.65]\n",
            "Episode 429, Total Reward: [-62.187622], Final Balance: [9937.804]\n",
            "Episode 430, Total Reward: [-14.75206], Final Balance: [9985.244]\n",
            "Episode 431, Total Reward: [-44.758453], Final Balance: [9955.234]\n",
            "Episode 432, Total Reward: [-25.876389], Final Balance: [9974.117]\n",
            "Episode 433, Total Reward: [-6.69751], Final Balance: [9993.292]\n",
            "Episode 434, Total Reward: [3.2471466], Final Balance: [10003.239]\n",
            "Episode 435, Total Reward: [-8.932404], Final Balance: [9991.076]\n",
            "Episode 436, Total Reward: [-60.308838], Final Balance: [9939.694]\n",
            "Episode 437, Total Reward: [161.39337], Final Balance: [10161.398]\n",
            "Episode 438, Total Reward: [101.63501], Final Balance: [10101.639]\n",
            "Episode 439, Total Reward: [-144.28545], Final Balance: [9855.708]\n",
            "Episode 440, Total Reward: [-22.470932], Final Balance: [9977.522]\n",
            "Episode 441, Total Reward: [21.77716], Final Balance: [10021.787]\n",
            "Episode 442, Total Reward: [-96.1539], Final Balance: [9903.844]\n",
            "Episode 443, Total Reward: [2.37529], Final Balance: [10002.384]\n",
            "Episode 444, Total Reward: [-16.675125], Final Balance: [9983.319]\n",
            "Episode 445, Total Reward: [-178.39418], Final Balance: [9821.597]\n",
            "Episode 446, Total Reward: [-71.974], Final Balance: [9928.033]\n",
            "Episode 447, Total Reward: [-25.062263], Final Balance: [9974.939]\n",
            "Episode 448, Total Reward: [3.664093], Final Balance: [10003.665]\n",
            "Episode 449, Total Reward: [-311.69492], Final Balance: [9688.305]\n",
            "Episode 450, Total Reward: [-33.98784], Final Balance: [9966.017]\n",
            "Episode 451, Total Reward: [-46.4402], Final Balance: [9953.559]\n",
            "Episode 452, Total Reward: [-29.474747], Final Balance: [9970.5205]\n",
            "Episode 453, Total Reward: [46.958054], Final Balance: [10046.958]\n",
            "Episode 454, Total Reward: [29.77304], Final Balance: [10029.768]\n",
            "Episode 455, Total Reward: [8.930054], Final Balance: [10008.936]\n",
            "Episode 456, Total Reward: [65.457306], Final Balance: [10065.44]\n",
            "Episode 457, Total Reward: [-6.6172485], Final Balance: [9993.38]\n",
            "Episode 458, Total Reward: [-5.115799], Final Balance: [9994.891]\n",
            "Episode 459, Total Reward: [70.26114], Final Balance: [10070.252]\n",
            "Episode 460, Total Reward: [-11.652115], Final Balance: [9988.3545]\n",
            "Episode 461, Total Reward: [3.0064697], Final Balance: [10003.01]\n",
            "Episode 462, Total Reward: [-67.58928], Final Balance: [9932.41]\n",
            "Episode 463, Total Reward: [-101.13034], Final Balance: [9898.876]\n",
            "Episode 464, Total Reward: [18.100098], Final Balance: [10018.098]\n",
            "Episode 465, Total Reward: [12.76149], Final Balance: [10012.768]\n",
            "Episode 466, Total Reward: [-125.24458], Final Balance: [9874.755]\n",
            "Episode 467, Total Reward: [-55.28296], Final Balance: [9944.715]\n",
            "Episode 468, Total Reward: [11.089279], Final Balance: [10011.093]\n",
            "Episode 469, Total Reward: [89.346695], Final Balance: [10089.339]\n",
            "Episode 470, Total Reward: [-117.937225], Final Balance: [9882.071]\n",
            "Episode 471, Total Reward: [-13.115341], Final Balance: [9986.886]\n",
            "Episode 472, Total Reward: [17.359695], Final Balance: [10017.356]\n",
            "Episode 473, Total Reward: [133.85155], Final Balance: [10133.843]\n",
            "Episode 474, Total Reward: [128.26013], Final Balance: [10128.26]\n",
            "Episode 475, Total Reward: [-14.995369], Final Balance: [9985.004]\n",
            "Episode 476, Total Reward: [128.31783], Final Balance: [10128.301]\n",
            "Episode 477, Total Reward: [54.84645], Final Balance: [10054.844]\n",
            "Episode 478, Total Reward: [26.600784], Final Balance: [10026.603]\n",
            "Episode 479, Total Reward: [-1.9433746], Final Balance: [9998.052]\n",
            "Episode 480, Total Reward: [-2.9408264], Final Balance: [9997.059]\n",
            "Episode 481, Total Reward: [14.130417], Final Balance: [10014.131]\n",
            "Episode 482, Total Reward: [-26.715439], Final Balance: [9973.289]\n",
            "Episode 483, Total Reward: [18.210999], Final Balance: [10018.212]\n",
            "Episode 484, Total Reward: [44.55742], Final Balance: [10044.553]\n",
            "Episode 485, Total Reward: [15.926971], Final Balance: [10015.916]\n",
            "Episode 486, Total Reward: [32.737686], Final Balance: [10032.736]\n",
            "Episode 487, Total Reward: [-45.67453], Final Balance: [9954.3125]\n",
            "Episode 488, Total Reward: [-86.63255], Final Balance: [9913.369]\n",
            "Episode 489, Total Reward: [43.300842], Final Balance: [10043.303]\n",
            "Episode 490, Total Reward: [22.573196], Final Balance: [10022.588]\n",
            "Episode 491, Total Reward: [82.058365], Final Balance: [10082.053]\n",
            "Episode 492, Total Reward: [-27.774933], Final Balance: [9972.234]\n",
            "Episode 493, Total Reward: [38.401764], Final Balance: [10038.392]\n",
            "Episode 494, Total Reward: [-68.15143], Final Balance: [9931.845]\n",
            "Episode 495, Total Reward: [-42.200195], Final Balance: [9957.794]\n",
            "Episode 496, Total Reward: [-47.2164], Final Balance: [9952.782]\n",
            "Episode 497, Total Reward: [-34.755768], Final Balance: [9965.237]\n",
            "Episode 498, Total Reward: [28.122543], Final Balance: [10028.125]\n",
            "Episode 499, Total Reward: [-10.200943], Final Balance: [9989.804]\n",
            "Episode 500, Total Reward: [-86.4881], Final Balance: [9913.511]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "Ensure SARSA Stores Portfolio Values\n",
        "if not hasattr(sarsa_agent, 'portfolio_values') or not sarsa_agent.portfolio_values:\n",
        "    raise ValueError(\" Error: `sarsa_portfolio_values` is missing or empty. Check if SARSA training stored portfolio values correctly.\")\n",
        "\n",
        "Convert SARSA Portfolio Values to NumPy Array & Flatten\n",
        "sarsa_portfolio_values = np.array([val.squeeze() for val in sarsa_agent.portfolio_values], dtype=float)\n",
        "\n",
        "Ensure DataFrame and Portfolio Length Match\n",
        "min_length = min(len(df), len(sarsa_portfolio_values))\n",
        "df = df.iloc[:min_length]  Trim DataFrame to match portfolio values length\n",
        "sarsa_portfolio_values = sarsa_portfolio_values[:min_length]  Trim SARSA portfolio values\n",
        "\n",
        "Debugging Print\n",
        "print(f\"Data Length: {len(df)}, SARSA Portfolio Length: {len(sarsa_portfolio_values)}\")\n",
        "\n",
        "Convert SARSA Portfolio Values to DataFrame\n",
        "results_df_sarsa = pd.DataFrame({\n",
        "    'Date': df.index[:min_length],\n",
        "    'Portfolio Value': sarsa_portfolio_values\n",
        "})\n",
        "\n",
        "Compute Daily Returns (Fix Array Issue)\n",
        "results_df_sarsa['Daily Return'] = results_df_sarsa['Portfolio Value'].pct_change().fillna(0)\n",
        "\n",
        "Compute SARSA Performance Metrics\n",
        "if len(results_df_sarsa) < 2:\n",
        "    raise ValueError(\" Error: Not enough data points to compute cumulative return.\")\n",
        "\n",
        "sarsa_cumulative_return = ((results_df_sarsa['Portfolio Value'].iloc[-1] / results_df_sarsa['Portfolio Value'].iloc[0]) - 1) * 100\n",
        "daily_return_mean_sarsa = results_df_sarsa['Daily Return'].mean()\n",
        "daily_return_std_sarsa = results_df_sarsa['Daily Return'].std()\n",
        "sarsa_sharpe_ratio = (daily_return_mean_sarsa / daily_return_std_sarsa) * np.sqrt(252) if daily_return_std_sarsa != 0 else 0\n",
        "drawdown_sarsa = (results_df_sarsa['Portfolio Value'].cummax() - results_df_sarsa['Portfolio Value']) / results_df_sarsa['Portfolio Value'].cummax()\n",
        "sarsa_max_drawdown = drawdown_sarsa.max() * 100\n",
        "\n",
        "Print Final Results\n",
        "print(\"\\n**Reinforcement Learning (SARSA)**\")\n",
        "print(f\"SARSA Final Portfolio Value: ${sarsa_portfolio_values[-1]:,.2f}\")\n",
        "print(f\"SARSA Cumulative Return: {sarsa_cumulative_return:.2f}%\")\n",
        "print(f\"SARSA Sharpe Ratio: {sarsa_sharpe_ratio:.2f}\")\n",
        "print(f\"SARSA Max Drawdown: {sarsa_max_drawdown:.2f}%\")\n",
        "\n",
        "Free Memory\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ryjVcsHWFkt",
        "outputId": "02038464-dc07-454f-f81c-0efa0e8b7b40"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Length: 5010, SARSA Portfolio Length: 5010\n",
            "\n",
            "**Reinforcement Learning (SARSA)**\n",
            "SARSA Final Portfolio Value: $10,216.28\n",
            "SARSA Cumulative Return: 1.75%\n",
            "SARSA Sharpe Ratio: 0.22\n",
            "SARSA Max Drawdown: 0.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "import gym_anytrading\n",
        "from stable_baselines3 import DDPG\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from gymnasium.spaces import Box\n",
        "from gym_anytrading.envs import StocksEnv\n",
        "\n",
        "Choose Dataset for Training\n",
        "df = df_live.copy()\n",
        "\n",
        "Fix MultiIndex Issues (if applicable)\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "Remove Named Index (Fixes KeyError Issues)\n",
        "df.columns.name = None\n",
        "\n",
        "Ensure EMA_10 and EMA_50 exist before DDPG training\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    print(\" 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\")\n",
        "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df.dropna(subset=['EMA_10', 'EMA_50'], inplace=True)\n",
        "    print(\"EMAs computed successfully.\")\n",
        "\n",
        "Confirm EMA columns before DDPG Training\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    raise KeyError(\" EMA columns are still missing after recomputation!\")\n",
        "\n",
        "print(\"  Final Columns Before Training:\", df.columns)\n",
        "\n",
        "Enable GPU Acceleration for DDPG (if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "Modify the Trading Environment for Continuous Actions\n",
        "class ContinuousTradingEnv(StocksEnv):\n",
        "    def __init__(self, df, frame_bound, window_size):\n",
        "        super().__init__(df=df, frame_bound=frame_bound, window_size=window_size)\n",
        "        self.action_space = Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        Convert continuous action (-1 to 1) to a discrete action (BUY, SELL, HOLD)\n",
        "        if action < -0.3:\n",
        "            discrete_action = 0  SELL\n",
        "        elif action > 0.3:\n",
        "            discrete_action = 1  BUY\n",
        "        else:\n",
        "            discrete_action = 2  HOLD\n",
        "\n",
        "        return super().step(discrete_action)\n",
        "\n",
        "Initialize the Custom Environment\n",
        "env = ContinuousTradingEnv(df=df, frame_bound=(10, len(df)), window_size=10)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "Define Action Noise for DDPG\n",
        "n_actions = env.action_space.shape[-1]\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "\n",
        "Train DDPG Model with Optimized Settings\n",
        "ddpg_model = DDPG(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    action_noise=action_noise,\n",
        "    verbose=1,\n",
        "    learning_rate=0.0001,\n",
        "    batch_size=128, Reduced batch size for faster training\n",
        "    gamma=0.99,\n",
        "    tau=0.01, Faster target updates\n",
        "    gradient_steps=2, More updates per step\n",
        "    tensorboard_log=\"./ddpg_tensorboard/\", Track progress\n",
        "    device=device,  Use GPU if available\n",
        ")\n",
        "\n",
        "Train with Reduced Timesteps (100,000 instead of 500,000)\n",
        "ddpg_model.learn(total_timesteps=100000)\n",
        "ddpg_model.save(\"ddpg_trading_model_v1\")\n",
        "\n",
        "Run DDPG Trading Strategy\n",
        "obs = env.reset()\n",
        "trade_log_ddpg = []\n",
        "buy_price = None\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if i == 0:\n",
        "        trade_log_ddpg.append(\"HOLD\")\n",
        "        continue\n",
        "\n",
        "    action, _ = ddpg_model.predict(obs)\n",
        "\n",
        "    if action < -0.3 and buy_price is not None:\n",
        "        trade_log_ddpg.append(\"SELL\")\n",
        "        buy_price = None\n",
        "    elif action > 0.3 and buy_price is None:\n",
        "        trade_log_ddpg.append(\"BUY\")\n",
        "        buy_price = df['Close'].iloc[i]\n",
        "    else:\n",
        "        trade_log_ddpg.append(\"HOLD\")\n",
        "\n",
        "df[\"DDPG_Trade_Signal\"] = trade_log_ddpg\n",
        "\n",
        "Run Backtesting\n",
        "initial_balance = 100000\n",
        "shares_held = initial_balance / df['Close'].iloc[0]\n",
        "final_balance_hold = shares_held * df['Close'].iloc[-1]\n",
        "\n",
        "balance_ddpg = 100000\n",
        "position = 0\n",
        "portfolio_values_ddpg = []\n",
        "\n",
        "for i, trade in enumerate(trade_log_ddpg):\n",
        "    price = df['Close'].iloc[i]\n",
        "\n",
        "    if trade == \"BUY\" and position == 0:\n",
        "        position = balance_ddpg / price\n",
        "        balance_ddpg = 0\n",
        "    elif trade == \"SELL\" and position > 0:\n",
        "        balance_ddpg = position * price\n",
        "        position = 0\n",
        "\n",
        "    portfolio_values_ddpg.append(balance_ddpg if balance_ddpg > 0 else position * price)\n",
        "\n",
        "final_balance_ddpg = portfolio_values_ddpg[-1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J-AyQlHR8vl",
        "outputId": "7776da8f-283d-4c92-a678-1fd3e5060c53"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\n",
            "EMAs computed successfully.\n",
            "  Final Columns Before Training: Index(['Datetime', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_10',\n",
            "       'EMA_50'],\n",
            "      dtype='object')\n",
            "Using device: cuda\n",
            "Using cuda device\n",
            "Logging to ./ddpg_tensorboard/DDPG_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 70       |\n",
            "|    time_elapsed    | 282      |\n",
            "|    total_timesteps | 19996    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.608   |\n",
            "|    critic_loss     | 0.00249  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 39790    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 555      |\n",
            "|    total_timesteps | 39992    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.5     |\n",
            "|    critic_loss     | 0.000664 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 79782    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 833      |\n",
            "|    total_timesteps | 59988    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.329   |\n",
            "|    critic_loss     | 0.000291 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 119774   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1107     |\n",
            "|    total_timesteps | 79984    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.379   |\n",
            "|    critic_loss     | 0.000274 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 159766   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1398     |\n",
            "|    total_timesteps | 99980    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.455   |\n",
            "|    critic_loss     | 0.000264 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 199758   |\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Compute Performance Metrics for DDPG\n",
        "results_df_ddpg = pd.DataFrame({'Date': df.index, 'Portfolio Value': portfolio_values_ddpg})\n",
        "results_df_ddpg['Daily Return'] = results_df_ddpg['Portfolio Value'].pct_change().fillna(0)\n",
        "\n",
        "ddpg_cumulative_return = ((results_df_ddpg['Portfolio Value'].iloc[-1] / initial_balance) - 1) * 100\n",
        "ddpg_sharpe_ratio = (results_df_ddpg['Daily Return'].mean() / results_df_ddpg['Daily Return'].std()) * np.sqrt(252) if results_df_ddpg['Daily Return'].std() != 0 else 0\n",
        "ddpg_max_drawdown = ((results_df_ddpg['Portfolio Value'].cummax() - results_df_ddpg['Portfolio Value']) / results_df_ddpg['Portfolio Value'].cummax()).max() * 100\n",
        "\n",
        "Final Results Summary\n",
        "print(\"\\nFINAL RESULTS COMPARISON:\")\n",
        "\n",
        "print(\"**Reinforcement Learning (DDPG)**\")\n",
        "print(f\"DDPG Final Portfolio Value: ${final_balance_ddpg:,.2f}\")\n",
        "print(f\"DDPG Cumulative Return: {ddpg_cumulative_return:.2f}%\")\n",
        "print(f\"DDPG Sharpe Ratio: {ddpg_sharpe_ratio:.2f}\")\n",
        "print(f\"DDPG Max Drawdown: {ddpg_max_drawdown:.2f}%\")\n",
        "print(f\"DDPG Trade Log (First 10): {trade_log_ddpg[:10]} ...\")\n",
        "\n",
        "print(\"\\n**Buy & Hold Baseline**\")\n",
        "print(f\"Buy & Hold Final Portfolio Value: ${final_balance_hold:,.2f}\")\n",
        "\n",
        "Declare Winner Based on Portfolio Performance\n",
        "winner = \"DDPG\" if final_balance_ddpg > final_balance_hold else \"Buy & Hold\"\n",
        "print(f\"\\n**Best Strategy Based on Final Portfolio Value: {winner}!**\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-KyViZ3c6t3",
        "outputId": "4d7f5a8b-da9a-4314-b0de-dce418928878"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL RESULTS COMPARISON:\n",
            "**Reinforcement Learning (DDPG)**\n",
            "DDPG Final Portfolio Value: $85,222.56\n",
            "DDPG Cumulative Return: -14.78%\n",
            "DDPG Sharpe Ratio: 0.07\n",
            "DDPG Max Drawdown: 70.22%\n",
            "DDPG Trade Log (First 10): ['HOLD', 'BUY', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD', 'HOLD'] ...\n",
            "\n",
            "**Buy & Hold Baseline**\n",
            "Buy & Hold Final Portfolio Value: $84,660.03\n",
            "\n",
            "**Best Strategy Based on Final Portfolio Value: DDPG!**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from gymnasium import spaces\n",
        "\n",
        "Load dataset (Assuming df_live contains market data)\n",
        "df = df_live.copy()\n",
        "\n",
        "Ensure Data is in Proper Format\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "df.columns.name = None\n",
        "\n",
        "Compute EMA if Missing\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    print(\" 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\")\n",
        "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df.dropna(subset=['EMA_10', 'EMA_50'], inplace=True)\n",
        "    print(\"EMAs computed successfully.\")\n",
        "\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    raise KeyError(\" EMA columns are still missing after recomputation!\")\n",
        "\n",
        "Define a Custom Gymnasium Environment for A2C\n",
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, data):\n",
        "        super(TradingEnv, self).__init__()\n",
        "\n",
        "        self.data = data[['Close', 'EMA_10', 'EMA_50']].values\n",
        "        self.current_step = 0\n",
        "\n",
        "        Define Action and Observation Spaces\n",
        "        self.action_space = spaces.Discrete(2)  0 = Hold, 1 = Trade\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-float(\"inf\"), high=float(\"inf\"), shape=(3,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        self.current_step = 0\n",
        "        return self.data[self.current_step], {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "\n",
        "        if self.current_step >= len(self.data):\n",
        "            done = True\n",
        "            reward = 0  No more data\n",
        "            obs = self.data[-1]\n",
        "        else:\n",
        "            done = False\n",
        "            obs = self.data[self.current_step]\n",
        "\n",
        "            Reward System: Reward correct trades\n",
        "            if action == 1 and self.data[self.current_step - 1][1] < self.data[self.current_step - 1][2] and obs[1] >= obs[2]:\n",
        "                reward = 1  Buy on EMA_10 crossing EMA_50 upwards\n",
        "            elif action == 0 and self.data[self.current_step - 1][1] > self.data[self.current_step - 1][2] and obs[1] <= obs[2]:\n",
        "                reward = 1  Hold when EMA_10 is below EMA_50\n",
        "            else:\n",
        "                reward = -1  Penalize incorrect trades\n",
        "\n",
        "        return obs, reward, done, False, {}\n",
        "\n",
        "Create and Wrap Gymnasium Environment\n",
        "env = DummyVecEnv([lambda: TradingEnv(df)])\n",
        "\n",
        "Train A2C Model\n",
        "model = A2C(\"MlpPolicy\", env, verbose=1, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "Save Model\n",
        "model.save(\"a2c_trading_model\")\n",
        "\n",
        "print(\"A2C Training Completed and Model Saved!\")\n"
      ],
      "metadata": {
        "id": "fVL27j1L0_Kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ac1e8d-bdc7-42fc-f5fc-acdbff07d095"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\n",
            "EMAs computed successfully.\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 426      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | 1.79e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -1.74    |\n",
            "|    value_loss         | 7.66     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 432      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.683   |\n",
            "|    explained_variance | 1.09e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -1.5     |\n",
            "|    value_loss         | 6.73     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 436      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.667   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -1.56    |\n",
            "|    value_loss         | 5.94     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 438       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.659    |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -1.47     |\n",
            "|    value_loss         | 5.23      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 425      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.666   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -0.54    |\n",
            "|    value_loss         | 0.813    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 410      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.626   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -0.879   |\n",
            "|    value_loss         | 3.98     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 415      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.617   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -1.16    |\n",
            "|    value_loss         | 3.41     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 419      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -1.11    |\n",
            "|    value_loss         | 2.93     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 422      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.512   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.333   |\n",
            "|    value_loss         | 2.46     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 424      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.346   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -1.04    |\n",
            "|    value_loss         | 2.03     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 426      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.484   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -0.244   |\n",
            "|    value_loss         | 1.67     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 425       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.507    |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -0.711    |\n",
            "|    value_loss         | 1.32      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 426      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.535   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.528    |\n",
            "|    value_loss         | 1.31     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 427      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.438   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.223   |\n",
            "|    value_loss         | 0.741    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 424      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.614   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.236   |\n",
            "|    value_loss         | 0.52     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 418      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.676   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -0.335   |\n",
            "|    value_loss         | 0.353    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 419      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.561   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.243   |\n",
            "|    value_loss         | 0.214    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 420      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.587   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -0.179   |\n",
            "|    value_loss         | 0.115    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 422      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.321   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.0638   |\n",
            "|    value_loss         | 1.2      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 423      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.469   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -0.0125  |\n",
            "|    value_loss         | 0.00492  |\n",
            "------------------------------------\n",
            "A2C Training Completed and Model Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from gymnasium import spaces\n",
        "\n",
        "Load dataset\n",
        "df = df_live.copy()\n",
        "\n",
        "Ensure Data is in Proper Format\n",
        "if isinstance(df.columns, pd.MultiIndex):\n",
        "    df.columns = df.columns.get_level_values(0)\n",
        "df.columns.name = None  Remove unwanted index names\n",
        "\n",
        "Compute EMA if Missing\n",
        "if 'EMA_10' not in df.columns or 'EMA_50' not in df.columns:\n",
        "    print(\" 'EMA_10' or 'EMA_50' missing. Recomputing EMAs...\")\n",
        "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df.dropna(subset=['EMA_10', 'EMA_50'], inplace=True)\n",
        "    print(\"EMAs computed successfully.\")\n",
        "\n",
        "Define Custom Reward Function\n",
        "def reward_function(action, price, last_price):\n",
        "    \"\"\"Dynamic reward function based on market conditions.\"\"\"\n",
        "    profit = price - last_price if action == 1 else last_price - price\n",
        "    return profit * 10 if profit > 0 else profit * 5  Reward for profits, penalty for losses\n",
        "\n",
        "Define Custom Trading Environment for A2C\n",
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, data):\n",
        "        super(TradingEnv, self).__init__()\n",
        "\n",
        "        self.data = data[['Close', 'EMA_10', 'EMA_50']].values\n",
        "        self.current_step = 0\n",
        "        self.last_price = self.data[0][0]  Track last price\n",
        "\n",
        "        Define Action and Observation Spaces\n",
        "        self.action_space = spaces.Discrete(2)  0 = Hold, 1 = Trade\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-float(\"inf\"), high=float(\"inf\"), shape=(3,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        self.current_step = 0\n",
        "        self.last_price = self.data[0][0]  Reset last price\n",
        "        return self.data[self.current_step], {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "\n",
        "        if self.current_step >= len(self.data):\n",
        "            done = True\n",
        "            reward = 0  No more data\n",
        "            obs = self.data[-1]\n",
        "        else:\n",
        "            done = False\n",
        "            obs = self.data[self.current_step]\n",
        "\n",
        "            Apply Reward Function\n",
        "            reward = reward_function(action, obs[0], self.last_price)\n",
        "            self.last_price = obs[0]  Update last price\n",
        "\n",
        "        return obs, reward, done, False, {}\n",
        "\n",
        "Create & Wrap Trading Environment\n",
        "env = DummyVecEnv([lambda: TradingEnv(df)])\n",
        "\n",
        "Train A2C Model with Updated Hyperparameters\n",
        "model = A2C(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    learning_rate=0.0003,  Increased learning rate\n",
        "    gamma=0.99,  Higher discount factor for long-term rewards\n",
        "    n_steps=10,  More frequent updates for stability\n",
        "    ent_coef=0.01,  Reduce exploration\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "Increase Training Timesteps\n",
        "model.learn(total_timesteps=200000)  Increased from 10,000 to 200,000\n",
        "\n",
        "Save Model\n",
        "model.save(\"a2c_trading_model_v2\")\n",
        "print(\"A2C Model Training Completed!\")\n",
        "\n",
        "Evaluate A2C Performance\n",
        "obs = env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "a2c_portfolio_values = []\n",
        "initial_balance = 10000  Assume starting with $10,000\n",
        "\n",
        "while not done:\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "\n",
        "    Ensure reward is a scalar value (Extract from array if necessary)\n",
        "    if isinstance(reward, np.ndarray):\n",
        "        reward = reward.item()  Convert NumPy array to scalar\n",
        "\n",
        "    total_reward += reward\n",
        "    initial_balance += reward  Simulating portfolio value\n",
        "    a2c_portfolio_values.append(initial_balance)\n",
        "\n",
        "Convert Portfolio Values to DataFrame\n",
        "min_length = min(len(df), len(a2c_portfolio_values))\n",
        "df = df.iloc[:min_length]  Trim DataFrame to match portfolio values length\n",
        "a2c_portfolio_values = a2c_portfolio_values[:min_length]  Trim A2C portfolio values\n",
        "\n",
        "results_df_a2c = pd.DataFrame({'Date': df.index, 'Portfolio Value': a2c_portfolio_values})\n",
        "\n",
        "Compute Daily Returns\n",
        "results_df_a2c['Daily Return'] = results_df_a2c['Portfolio Value'].pct_change().fillna(0)\n",
        "\n",
        "Ensure all values are numeric before calculations\n",
        "results_df_a2c['Daily Return'] = pd.to_numeric(results_df_a2c['Daily Return'], errors='coerce')\n",
        "\n",
        "Compute Cumulative Return\n",
        "a2c_cumulative_return = ((results_df_a2c['Portfolio Value'].iloc[-1] / results_df_a2c['Portfolio Value'].iloc[0]) - 1) * 100\n",
        "\n",
        "Compute Sharpe Ratio (Annualized)\n",
        "daily_return_mean_a2c = results_df_a2c['Daily Return'].mean()\n",
        "daily_return_std_a2c = results_df_a2c['Daily Return'].std()\n",
        "\n",
        "Ensure standard deviation is not zero\n",
        "a2c_sharpe_ratio = (daily_return_mean_a2c / daily_return_std_a2c) * np.sqrt(252) if daily_return_std_a2c != 0 else 0\n",
        "\n",
        "Compute Max Drawdown\n",
        "drawdown_a2c = (results_df_a2c['Portfolio Value'].cummax() - results_df_a2c['Portfolio Value']) / results_df_a2c['Portfolio Value'].cummax()\n",
        "a2c_max_drawdown = drawdown_a2c.max() * 100  Convert to percentage\n",
        "\n",
        "Print A2C Model Performance\n",
        "print(\"\\n**Reinforcement Learning (A2C) Performance**\")\n",
        "print(f\"A2C Final Portfolio Value: ${results_df_a2c['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"A2C Cumulative Return: {a2c_cumulative_return:.2f}%\")\n",
        "print(f\"A2C Sharpe Ratio: {a2c_sharpe_ratio:.2f}\")\n",
        "print(f\"A2C Max Drawdown: {a2c_max_drawdown:.2f}%\")\n",
        "\n",
        "Free Memory\n",
        "import gc\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJjnBF3bVWiU",
        "outputId": "87394ca7-5d8e-41ca-bdf8-65792c3c3ed1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2C Cumulative Return: -48.86%\n",
            "A2C Sharpe Ratio: -52.41\n",
            "A2C Max Drawdown: 48.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "Compute Buy & Hold Performance\n",
        "initial_balance = 100000  Starting portfolio value\n",
        "buy_price = df['Close'].iloc[0]  Buy at the first available price\n",
        "sell_price = df['Close'].iloc[-1]  Sell at the last available price\n",
        "\n",
        "shares_held = initial_balance / buy_price\n",
        "buy_hold_final_value = shares_held * sell_price  Final portfolio value\n",
        "\n",
        "Compute Buy & Hold Metrics\n",
        "buy_hold_cumulative_return = ((buy_hold_final_value / initial_balance) - 1) * 100\n",
        "\n",
        "print(\"\\n**Buy & Hold Baseline**\")\n",
        "print(f\"Buy & Hold Final Portfolio Value: ${buy_hold_final_value:,.2f}\")\n",
        "print(f\"Buy & Hold Cumulative Return: {buy_hold_cumulative_return:.2f}%\")\n",
        "\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHOSlU_nwzZR",
        "outputId": "5636e25e-696d-4698-dbbe-1fcad36e835e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Buy & Hold Baseline**\n",
            "Buy & Hold Final Portfolio Value: $84,660.03\n",
            "Buy & Hold Cumulative Return: -15.34%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FINAL RESULTS COMPARISON\n",
        "print(\"\\nFINAL RESULTS COMPARISON:\")\n",
        "\n",
        "Reinforcement Learning Models\n",
        "print(\"\\n**Reinforcement Learning (A2C)**\")\n",
        "print(f\"A2C Final Portfolio Value: ${results_df_a2c['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"A2C Cumulative Return: {a2c_cumulative_return:.2f}%\")\n",
        "print(f\"A2C Sharpe Ratio: {a2c_sharpe_ratio:.2f}\")\n",
        "print(f\"A2C Max Drawdown: {a2c_max_drawdown:.2f}%\")\n",
        "\n",
        "print(\"\\n**Reinforcement Learning (PPO)**\")\n",
        "print(f\"PPO Final Portfolio Value: ${results_df_ppo['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"PPO Cumulative Return: {ppo_cumulative_return:.2f}%\")\n",
        "print(f\"PPO Sharpe Ratio: {ppo_sharpe_ratio:.2f}\")\n",
        "print(f\"PPO Max Drawdown: {ppo_max_drawdown:.2f}%\")\n",
        "\n",
        "print(\"\\n**Reinforcement Learning (DDPG)**\")\n",
        "print(f\"DDPG Final Portfolio Value: ${results_df_ddpg['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"DDPG Cumulative Return: {ddpg_cumulative_return:.2f}%\")\n",
        "print(f\"DDPG Sharpe Ratio: {ddpg_sharpe_ratio:.2f}\")\n",
        "print(f\"DDPG Max Drawdown: {ddpg_max_drawdown:.2f}%\")\n",
        "\n",
        "Buy & Hold Strategy\n",
        "print(\"\\n**Buy & Hold Baseline**\")\n",
        "print(f\"Buy & Hold Final Portfolio Value: ${buy_hold_final_value:,.2f}\")\n",
        "print(f\"Buy & Hold Cumulative Return: {buy_hold_cumulative_return:.2f}%\")\n",
        "\n",
        "Machine Learning Models (Portfolio Performance + Accuracy)\n",
        "print(\"\\n**Machine Learning Models (Portfolio Performance)**\")\n",
        "\n",
        "Random Forest\n",
        "print(f\"\\n**Random Forest**\")\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Random Forest Final Portfolio Value: ${results_df_rf['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"Random Forest Cumulative Return: {rf_cumulative_return:.2f}%\")\n",
        "\n",
        "Gradient Boosting\n",
        "print(f\"\\n**Gradient Boosting**\")\n",
        "print(f\"Gradient Boosting Accuracy: {gb_accuracy:.4f}\")\n",
        "print(f\"Gradient Boosting Final Portfolio Value: ${results_df_gb['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"Gradient Boosting Cumulative Return: {gb_cumulative_return:.2f}%\")\n",
        "\n",
        "XGBoost\n",
        "print(f\"\\n**XGBoost**\")\n",
        "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"XGBoost Final Portfolio Value: ${results_df_xgb['Portfolio Value'].iloc[-1]:,.2f}\")\n",
        "print(f\"XGBoost Cumulative Return: {xgb_cumulative_return:.2f}%\")\n",
        "\n",
        "Determine Best Trading Strategy (Based on Portfolio Value)\n",
        "strategy_results = {\n",
        "    \"A2C\": results_df_a2c['Portfolio Value'].iloc[-1],\n",
        "    \"PPO\": results_df_ppo['Portfolio Value'].iloc[-1],\n",
        "    \"DDPG\": results_df_ddpg['Portfolio Value'].iloc[-1],\n",
        "    \"Random Forest\": results_df_rf['Portfolio Value'].iloc[-1],\n",
        "    \"Gradient Boosting\": results_df_gb['Portfolio Value'].iloc[-1],\n",
        "    \"XGBoost\": results_df_xgb['Portfolio Value'].iloc[-1],\n",
        "    \"Buy & Hold\": buy_hold_final_value\n",
        "}\n",
        "\n",
        "best_strategy = max(strategy_results, key=strategy_results.get)\n",
        "\n",
        "Print Best Performing Strategy\n",
        "print(f\"\\n**Best Strategy Based on Final Portfolio Value: {best_strategy}!**\")\n",
        "\n",
        "Clean up memory\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkNnSSLOSQEw",
        "outputId": "260d9f39-9bee-4b8c-bbb3-457845a335df"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL RESULTS COMPARISON:\n",
            "\n",
            "**Reinforcement Learning (A2C)**\n",
            "A2C Final Portfolio Value: $5,113.00\n",
            "A2C Cumulative Return: -48.86%\n",
            "A2C Sharpe Ratio: -52.41\n",
            "A2C Max Drawdown: 48.86%\n",
            "\n",
            "**Reinforcement Learning (PPO)**\n",
            "PPO Final Portfolio Value: $124,986.77\n",
            "PPO Cumulative Return: 24.99%\n",
            "PPO Sharpe Ratio: 0.35\n",
            "PPO Max Drawdown: 41.29%\n",
            "\n",
            "**Reinforcement Learning (DDPG)**\n",
            "DDPG Final Portfolio Value: $85,222.56\n",
            "DDPG Cumulative Return: -14.78%\n",
            "DDPG Sharpe Ratio: 0.07\n",
            "DDPG Max Drawdown: 70.22%\n",
            "\n",
            "**Buy & Hold Baseline**\n",
            "Buy & Hold Final Portfolio Value: $84,660.03\n",
            "Buy & Hold Cumulative Return: -15.34%\n",
            "\n",
            "**Machine Learning Models (Portfolio Performance)**\n",
            "\n",
            "**Random Forest**\n",
            "Random Forest Accuracy: 0.7037\n",
            "Random Forest Final Portfolio Value: $125,415.29\n",
            "Random Forest Cumulative Return: 25.42%\n",
            "\n",
            "**Gradient Boosting**\n",
            "Gradient Boosting Accuracy: 0.6537\n",
            "Gradient Boosting Final Portfolio Value: $84,693.72\n",
            "Gradient Boosting Cumulative Return: -15.31%\n",
            "\n",
            "**XGBoost**\n",
            "XGBoost Accuracy: 0.6836\n",
            "XGBoost Final Portfolio Value: $240,328.61\n",
            "XGBoost Cumulative Return: 140.33%\n",
            "\n",
            "**Best Strategy Based on Final Portfolio Value: XGBoost!**\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}
